# Script dir = /Users/lmthang/nmt.matlab/scripts
cd /Users/lmthang/nmt.matlab/scripts/../code

## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 104, individual sizes:  W_src{1}=32 W_tgt{1}=48 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 1
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 104
  src input 1: y y x y
  src mask: 1  1  1  1
  tgt input 1: <s> a b a
  tgt output 1: a b a </s>
  tgt mask: 1  1  1  1
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=4.12108e-12
 -0.000000	 -0.000000	diff=2.62038e-13
 -0.000000	 -0.000000	diff=2.29777e-11
  0.000000	  0.000000	diff=5.08694e-12
 -0.000000	 -0.000000	diff=1.41871e-15
  0.000000	  0.000000	diff=3.76824e-13
 -0.000082	 -0.000082	diff=1.41073e-08
 -0.000429	 -0.000429	diff=5.82613e-09
 -0.000005	 -0.000005	diff=3.85284e-12
 -0.000002	 -0.000002	diff=1.41833e-11
 -0.000000	 -0.000000	diff=2.35784e-10
 -0.000000	 -0.000000	diff=4.20775e-12
  0.000000	  0.000000	diff=6.37582e-13
  0.000000	  0.000000	diff=1.55415e-14
 -0.001714	 -0.001714	diff=7.79316e-08
  0.000583	  0.000583	diff=1.44267e-08
 -0.000000	 -0.000000	diff=2.43737e-13
 -0.000000	 -0.000000	diff=2.62419e-13
 -0.000000	 -0.000000	diff=6.7098e-14
 -0.000000	 -0.000000	diff=2.40209e-13
  0.000000	  0.000000	diff=5.89005e-13
  0.000000	  0.000000	diff=5.07916e-13
 -0.000000	 -0.000000	diff=7.77005e-09
  0.000015	  0.000015	diff=1.10464e-10
  0.000000	  0.000000	diff=1.4889e-13
  0.000000	  0.000000	diff=4.96042e-13
  0.000000	  0.000000	diff=2.62731e-13
  0.000000	  0.000000	diff=4.80863e-14
 -0.000000	 -0.000000	diff=1.41999e-13
 -0.000000	 -0.000000	diff=1.99158e-13
 -0.000001	 -0.000001	diff=3.78879e-10
 -0.000010	 -0.000010	diff=1.80099e-08
  local_diff=1.38856e-07
# W_tgt{1}, [8 6]
 -0.000048	 -0.000048	diff=6.23528e-11
  0.000003	  0.000003	diff=4.21402e-12
  0.000008	  0.000008	diff=1.3699e-09
  0.000001	  0.000001	diff=1.52867e-10
 -0.000028	 -0.000028	diff=4.10949e-11
  0.000002	  0.000002	diff=6.22244e-13
 -0.000583	 -0.000584	diff=1.97963e-07
 -0.001178	 -0.001178	diff=2.08685e-08
 -0.000029	 -0.000029	diff=6.80607e-11
  0.000006	  0.000006	diff=8.83643e-12
 -0.000004	 -0.000004	diff=2.98218e-09
 -0.000003	 -0.000003	diff=3.50223e-10
 -0.000025	 -0.000025	diff=4.80695e-11
  0.000001	  0.000001	diff=2.12906e-11
 -0.012451	 -0.012452	diff=3.70661e-07
  0.000339	  0.000339	diff=3.0649e-09
  0.000000	  0.000000	diff=2.24188e-13
 -0.000000	 -0.000000	diff=2.90945e-14
 -0.000000	 -0.000000	diff=7.64907e-13
  0.000000	  0.000000	diff=7.07533e-13
 -0.000000	 -0.000000	diff=6.45375e-13
 -0.000000	 -0.000000	diff=3.09982e-13
 -0.000066	 -0.000066	diff=1.06522e-07
 -0.000001	 -0.000001	diff=2.34566e-11
 -0.000000	 -0.000000	diff=1.38788e-13
  0.000000	  0.000000	diff=1.30415e-13
  0.000000	  0.000000	diff=1.30545e-13
 -0.000000	 -0.000000	diff=3.6064e-13
 -0.000000	 -0.000000	diff=1.65886e-13
 -0.000000	 -0.000000	diff=2.34762e-13
 -0.000009	 -0.000009	diff=3.86424e-10
 -0.000000	 -0.000000	diff=7.96309e-09
  0.000000	  0.000000	diff=1.69923e-12
 -0.000000	 -0.000000	diff=8.78881e-14
 -0.000000	 -0.000000	diff=2.87261e-13
  0.000000	  0.000000	diff=3.92753e-13
 -0.000000	 -0.000000	diff=6.74556e-13
 -0.000000	 -0.000000	diff=6.85968e-13
 -0.000118	 -0.000118	diff=7.09232e-07
  0.000028	  0.000028	diff=2.59377e-09
 -0.000000	 -0.000000	diff=3.74429e-14
 -0.000000	 -0.000000	diff=7.93994e-13
  0.000000	  0.000000	diff=5.56238e-13
  0.000000	  0.000000	diff=2.52151e-13
 -0.000000	 -0.000000	diff=2.31236e-14
  0.000000	  0.000000	diff=4.54346e-13
  0.000054	  0.000054	diff=4.45869e-09
 -0.000023	 -0.000023	diff=8.81102e-08
  local_diff=1.51697e-06
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000825	  0.000825	diff=2.58159e-07
 -0.001517	 -0.001516	diff=6.64834e-07
  0.000079	  0.000079	diff=1.31214e-08
 -0.000444	 -0.000444	diff=2.36816e-07
  local_diff=1.17293e-06
# W_emb_tgt, [2 4]
 -0.003297	 -0.003296	diff=1.38301e-06
 -0.000952	 -0.000951	diff=3.06922e-07
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.008593	 -0.008592	diff=5.44548e-07
 -0.003148	 -0.003147	diff=3.60548e-07
 -0.003640	 -0.003640	diff=3.84628e-07
 -0.001405	 -0.001405	diff=2.02457e-07
  local_diff=3.18211e-06
# W_soft, [4 2]
  0.001906	  0.001906	diff=4.54324e-08
 -0.001267	 -0.001267	diff=4.54347e-08
  0.002200	  0.002200	diff=4.54334e-08
 -0.002838	 -0.002838	diff=4.54343e-08
 -0.000094	 -0.000094	diff=1.8145e-08
  0.000714	  0.000714	diff=1.81449e-08
 -0.002257	 -0.002257	diff=1.81447e-08
  0.001638	  0.001638	diff=1.81453e-08
  local_diff=2.54315e-07
# Num params=104, abs_diff=6.26517e-06
Elapsed time is 0.691633 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s> x y y
  src mask: 0  1  1  1
  tgt input 1: <s> b b </s> </s>
  tgt output 1: b b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=1.87871e-13
  0.000000	  0.000000	diff=4.75103e-15
 -0.000000	 -0.000000	diff=1.17588e-12
  0.000000	  0.000000	diff=5.47156e-13
 -0.000000	 -0.000000	diff=8.1325e-15
 -0.000000	 -0.000000	diff=8.36079e-13
  0.000078	  0.000078	diff=1.29093e-10
  0.000029	  0.000029	diff=2.99692e-10
  0.000000	  0.000000	diff=1.38588e-12
 -0.000000	 -0.000000	diff=1.45782e-12
  0.000000	  0.000000	diff=5.29089e-12
 -0.000000	 -0.000000	diff=1.9633e-12
  0.000000	  0.000000	diff=1.88295e-12
  0.000000	  0.000000	diff=1.46083e-12
 -0.000146	 -0.000146	diff=3.69597e-10
 -0.000050	 -0.000050	diff=7.14102e-10
  0.000000	  0.000000	diff=1.7042e-13
 -0.000000	 -0.000000	diff=2.19934e-13
  0.000000	  0.000000	diff=6.20103e-13
 -0.000000	 -0.000000	diff=8.92369e-15
  0.000000	  0.000000	diff=3.33915e-13
  0.000000	  0.000000	diff=4.07054e-13
 -0.000002	 -0.000002	diff=2.7209e-09
 -0.000001	 -0.000001	diff=5.82579e-12
 -0.000000	 -0.000000	diff=3.72225e-13
  0.000000	  0.000000	diff=9.99215e-14
 -0.000000	 -0.000000	diff=3.81436e-13
  0.000000	  0.000000	diff=9.86182e-13
 -0.000000	 -0.000000	diff=1.6738e-13
 -0.000000	 -0.000000	diff=4.96972e-13
  0.000002	  0.000002	diff=1.37024e-11
  0.000001	  0.000001	diff=1.14097e-09
  local_diff=5.41436e-09
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=4.53474e-13
  0.000000	  0.000000	diff=1.34504e-13
  0.000000	  0.000000	diff=6.23959e-13
  0.000000	  0.000000	diff=7.88075e-13
 -0.000000	 -0.000000	diff=2.74073e-13
  0.000000	  0.000000	diff=4.31215e-13
 -0.000013	 -0.000013	diff=1.16015e-12
  0.000125	  0.000125	diff=3.2989e-11
 -0.000000	 -0.000000	diff=6.34955e-13
 -0.000000	 -0.000000	diff=3.00408e-13
 -0.000000	 -0.000000	diff=4.77675e-13
 -0.000000	 -0.000000	diff=5.29321e-14
  0.000000	  0.000000	diff=1.84297e-13
 -0.000000	 -0.000000	diff=1.00939e-12
  0.000011	  0.000011	diff=4.28623e-13
 -0.000110	 -0.000110	diff=2.32604e-11
  0.000000	  0.000000	diff=3.06914e-13
  0.000000	  0.000000	diff=1.83441e-13
  0.000000	  0.000000	diff=3.043e-13
  0.000000	  0.000000	diff=9.44611e-14
  0.000000	  0.000000	diff=2.75684e-14
 -0.000000	 -0.000000	diff=1.15939e-12
 -0.000000	 -0.000000	diff=3.36492e-10
  0.000002	  0.000002	diff=9.28825e-13
 -0.000000	 -0.000000	diff=3.50341e-13
 -0.000000	 -0.000000	diff=7.52409e-14
 -0.000000	 -0.000000	diff=1.74739e-14
 -0.000000	 -0.000000	diff=4.63679e-13
  0.000000	 -0.000000	diff=1.00198e-14
  0.000000	  0.000000	diff=3.02766e-13
  0.000000	  0.000000	diff=2.75185e-13
 -0.000003	 -0.000003	diff=3.49534e-09
  local_diff=3.89953e-09
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=5.17737e-13
 -0.000000	 -0.000000	diff=1.38985e-12
  0.000000	  0.000000	diff=5.08026e-13
  0.000000	  0.000000	diff=1.20726e-11
  0.000000	  0.000000	diff=8.89307e-13
  0.000000	  0.000000	diff=1.65113e-12
 -0.000015	 -0.000015	diff=2.60037e-13
  0.000062	  0.000062	diff=9.26206e-10
 -0.000000	 -0.000000	diff=9.67936e-14
  0.000000	  0.000000	diff=1.41854e-12
 -0.000000	 -0.000000	diff=4.95997e-12
 -0.000000	 -0.000000	diff=1.86669e-11
 -0.000000	 -0.000000	diff=3.67983e-13
  0.000000	  0.000000	diff=1.24693e-12
  0.000039	  0.000039	diff=2.08119e-10
 -0.000246	 -0.000246	diff=1.15356e-09
 -0.000000	 -0.000000	diff=2.74914e-13
  0.000000	  0.000000	diff=8.15147e-13
 -0.000000	 -0.000000	diff=2.62175e-13
  0.000000	  0.000000	diff=7.42665e-13
 -0.000000	 -0.000000	diff=7.93994e-13
  0.000000	  0.000000	diff=3.29668e-13
  0.000000	  0.000000	diff=6.85349e-13
 -0.000000	 -0.000000	diff=3.92488e-13
 -0.000000	 -0.000000	diff=1.55321e-13
  0.000000	  0.000000	diff=4.17505e-13
 -0.000000	 -0.000000	diff=9.98782e-14
  0.000000	  0.000000	diff=4.81805e-13
 -0.000000	 -0.000000	diff=4.44256e-14
  0.000000	  0.000000	diff=3.88969e-13
 -0.000000	 -0.000000	diff=1.24565e-13
 -0.000000	 -0.000000	diff=4.05286e-12
 -0.000000	 -0.000000	diff=1.28261e-12
  0.000000	  0.000000	diff=1.38249e-13
 -0.000000	 -0.000000	diff=2.33193e-13
 -0.000000	 -0.000000	diff=1.12589e-12
 -0.000000	 -0.000000	diff=3.66089e-13
 -0.000000	 -0.000000	diff=7.37407e-13
  0.000001	  0.000001	diff=2.31297e-10
 -0.000003	 -0.000003	diff=1.38626e-10
  0.000000	  0.000000	diff=3.22522e-13
 -0.000000	 -0.000000	diff=7.6103e-14
  0.000000	  0.000000	diff=2.80737e-13
  0.000000	  0.000000	diff=3.54845e-13
  0.000000	  0.000000	diff=1.37503e-13
 -0.000000	 -0.000000	diff=9.48806e-13
 -0.000001	 -0.000001	diff=8.0484e-12
  0.000005	  0.000005	diff=4.11802e-09
  local_diff=6.84399e-09
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=2.01666e-13
 -0.000000	 -0.000000	diff=3.55836e-13
  0.000000	  0.000000	diff=4.33285e-13
  0.000000	  0.000000	diff=3.49945e-13
  0.000000	  0.000000	diff=1.01009e-13
  0.000000	  0.000000	diff=5.52553e-13
 -0.000017	 -0.000017	diff=3.8587e-11
  0.000075	  0.000075	diff=1.12985e-09
  0.000000	  0.000000	diff=5.65055e-13
 -0.000000	 -0.000000	diff=3.45518e-13
  0.000000	  0.000000	diff=5.41945e-13
 -0.000000	 -0.000000	diff=2.11951e-13
  0.000000	  0.000000	diff=1.72483e-13
 -0.000000	 -0.000000	diff=3.24814e-14
 -0.000007	 -0.000007	diff=8.52036e-10
 -0.000017	 -0.000017	diff=5.05571e-09
 -0.000000	 -0.000000	diff=3.91826e-13
  0.000000	  0.000000	diff=3.82185e-13
  0.000000	  0.000000	diff=8.93196e-13
  0.000000	  0.000000	diff=1.01494e-13
  0.000000	  0.000000	diff=3.42643e-13
  0.000000	  0.000000	diff=7.43071e-13
 -0.000001	 -0.000001	diff=2.26882e-09
  0.000008	  0.000008	diff=1.23334e-10
  0.000000	  0.000000	diff=7.85061e-13
  0.000000	  0.000000	diff=3.95749e-13
 -0.000000	 -0.000000	diff=5.20942e-13
 -0.000000	 -0.000000	diff=4.53371e-13
 -0.000000	 -0.000000	diff=1.25216e-12
 -0.000000	 -0.000000	diff=5.07102e-13
  0.000001	  0.000001	diff=3.17078e-12
 -0.000007	 -0.000007	diff=2.27645e-10
  local_diff=9.70978e-09
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000068	 -0.000068	diff=1.93566e-08
  0.000063	  0.000063	diff=5.08945e-08
 -0.000052	 -0.000052	diff=1.84554e-08
  0.000041	  0.000041	diff=4.53804e-08
  local_diff=1.34087e-07
# W_emb_tgt, [2 4]
 -0.000158	 -0.000158	diff=2.67855e-08
  0.000016	  0.000016	diff=6.77983e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000030	 -0.000030	diff=4.72495e-11
  0.000007	  0.000007	diff=4.74812e-09
  0.000048	  0.000048	diff=1.06678e-08
 -0.000004	 -0.000004	diff=1.79221e-09
  local_diff=5.08208e-08
# W_soft, [4 2]
  0.000042	  0.000042	diff=1.4367e-11
 -0.000201	 -0.000201	diff=1.39263e-11
  0.000111	  0.000111	diff=1.47236e-11
  0.000048	  0.000048	diff=1.45372e-11
  0.000418	  0.000418	diff=8.29578e-11
 -0.000214	 -0.000214	diff=8.33051e-11
 -0.000266	 -0.000266	diff=8.36797e-11
  0.000062	  0.000062	diff=8.33019e-11
  local_diff=3.90799e-10
# Num params=168, abs_diff=2.11166e-07
Elapsed time is 1.526120 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s> x y y
  src mask: 0  1  1  1
  tgt input 1: <s> b b </s> </s>
  tgt output 1: b b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=1.09364e-12
  0.000000	  0.000000	diff=9.80612e-13
 -0.000000	 -0.000000	diff=2.95292e-12
  0.000000	  0.000000	diff=8.52952e-13
 -0.000000	 -0.000000	diff=1.13293e-12
 -0.000000	 -0.000000	diff=4.50829e-13
  0.000108	  0.000108	diff=1.9171e-10
  0.000037	  0.000037	diff=4.68442e-10
  0.000001	  0.000001	diff=2.80729e-12
 -0.000000	 -0.000000	diff=9.33952e-13
  0.000000	  0.000000	diff=1.06795e-11
 -0.000000	 -0.000000	diff=4.98434e-12
  0.000001	  0.000001	diff=2.87542e-12
  0.000000	  0.000000	diff=1.92008e-13
 -0.000174	 -0.000174	diff=6.12174e-10
 -0.000068	 -0.000068	diff=1.11872e-09
  0.000000	  0.000000	diff=2.52429e-13
 -0.000000	 -0.000000	diff=8.25308e-13
  0.000000	  0.000000	diff=2.05444e-13
 -0.000000	 -0.000000	diff=6.31417e-14
  0.000000	  0.000000	diff=4.44248e-13
  0.000000	  0.000000	diff=4.17173e-13
 -0.000003	 -0.000003	diff=3.14552e-09
 -0.000001	 -0.000001	diff=6.44732e-12
 -0.000000	 -0.000000	diff=1.65474e-13
  0.000000	  0.000000	diff=3.48623e-13
 -0.000000	 -0.000000	diff=9.29333e-14
  0.000000	  0.000000	diff=5.59084e-13
 -0.000000	 -0.000000	diff=3.0615e-13
 -0.000000	 -0.000000	diff=6.59088e-13
  0.000003	  0.000003	diff=1.35491e-11
  0.000001	  0.000001	diff=1.51822e-09
  local_diff=7.10905e-09
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=5.50563e-13
  0.000000	  0.000000	diff=1.22676e-13
  0.000000	  0.000000	diff=1.91327e-13
  0.000000	  0.000000	diff=1.45279e-13
  0.000000	  0.000000	diff=2.66669e-13
 -0.000000	 -0.000000	diff=1.17497e-12
 -0.000007	 -0.000007	diff=1.82884e-12
  0.000161	  0.000161	diff=6.668e-11
 -0.000000	 -0.000000	diff=8.28265e-13
 -0.000000	 -0.000000	diff=3.25382e-15
 -0.000000	 -0.000000	diff=2.74441e-13
 -0.000000	 -0.000000	diff=8.13436e-13
 -0.000000	 -0.000000	diff=2.21267e-14
  0.000000	  0.000000	diff=4.63295e-13
  0.000005	  0.000005	diff=4.63231e-13
 -0.000135	 -0.000135	diff=4.89445e-11
  0.000000	  0.000000	diff=5.53561e-13
  0.000000	  0.000000	diff=8.26172e-13
  0.000000	  0.000000	diff=5.89552e-13
  0.000000	  0.000000	diff=5.68236e-13
  0.000000	  0.000000	diff=6.84781e-13
 -0.000000	 -0.000000	diff=5.87344e-14
 -0.000000	 -0.000000	diff=2.32642e-10
  0.000003	  0.000003	diff=2.15876e-13
 -0.000000	 -0.000000	diff=8.66625e-13
 -0.000000	 -0.000000	diff=5.98642e-13
 -0.000000	 -0.000000	diff=9.46902e-14
 -0.000000	 -0.000000	diff=3.99087e-13
 -0.000000	 -0.000000	diff=3.03796e-13
  0.000000	  0.000000	diff=5.1609e-13
  0.000000	  0.000000	diff=5.39588e-13
 -0.000004	 -0.000004	diff=4.05826e-09
  local_diff=4.42049e-09
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=1.7816e-13
 -0.000000	 -0.000000	diff=2.8465e-12
  0.000000	  0.000000	diff=1.92235e-12
  0.000000	  0.000000	diff=3.1677e-11
  0.000000	  0.000000	diff=1.00932e-12
  0.000000	  0.000000	diff=2.36142e-12
 -0.000020	 -0.000020	diff=1.29066e-10
  0.000115	  0.000115	diff=1.38437e-09
 -0.000000	 -0.000000	diff=2.41373e-13
  0.000001	  0.000001	diff=1.48548e-12
 -0.000000	 -0.000000	diff=7.13818e-12
 -0.000000	 -0.000000	diff=3.64973e-11
 -0.000000	 -0.000000	diff=5.47413e-13
  0.000000	  0.000000	diff=6.64778e-13
  0.000022	  0.000022	diff=1.91815e-11
 -0.000201	 -0.000201	diff=2.07743e-09
 -0.000000	 -0.000000	diff=1.49093e-12
  0.000000	  0.000000	diff=9.12218e-14
 -0.000000	 -0.000000	diff=2.26095e-14
  0.000000	  0.000000	diff=1.17987e-13
 -0.000000	 -0.000000	diff=5.62661e-13
  0.000000	  0.000000	diff=6.83768e-13
  0.000000	  0.000000	diff=3.83518e-13
 -0.000000	 -0.000000	diff=4.67511e-13
 -0.000000	 -0.000000	diff=4.66735e-13
  0.000000	  0.000000	diff=2.78207e-13
 -0.000000	 -0.000000	diff=4.97995e-13
  0.000000	  0.000000	diff=4.71402e-13
  0.000000	  0.000000	diff=3.22534e-13
  0.000000	  0.000000	diff=4.02284e-13
  0.000000	  0.000000	diff=5.58212e-13
 -0.000000	 -0.000000	diff=4.76981e-12
 -0.000000	 -0.000000	diff=3.22877e-13
  0.000000	  0.000000	diff=7.48947e-13
 -0.000000	 -0.000000	diff=4.89491e-13
 -0.000000	 -0.000000	diff=5.9079e-13
 -0.000000	 -0.000000	diff=4.52118e-13
 -0.000000	 -0.000000	diff=5.36659e-13
  0.000001	  0.000001	diff=2.55753e-10
 -0.000005	 -0.000005	diff=1.76365e-10
  0.000000	  0.000000	diff=3.53711e-13
 -0.000000	 -0.000000	diff=2.12685e-14
  0.000000	  0.000000	diff=4.32161e-13
  0.000000	  0.000000	diff=4.9507e-13
  0.000000	  0.000000	diff=2.67875e-13
 -0.000000	 -0.000000	diff=1.02391e-13
 -0.000001	 -0.000001	diff=6.3292e-12
  0.000006	  0.000006	diff=6.28238e-09
  local_diff=1.04338e-08
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=1.02928e-12
 -0.000000	 -0.000000	diff=1.70213e-13
  0.000000	  0.000000	diff=7.19194e-13
  0.000000	  0.000000	diff=2.93348e-14
  0.000000	  0.000000	diff=4.01891e-13
  0.000000	  0.000000	diff=2.24166e-13
 -0.000025	 -0.000025	diff=2.19886e-10
  0.000184	  0.000184	diff=3.15538e-09
 -0.000000	 -0.000000	diff=3.3341e-15
 -0.000000	 -0.000000	diff=1.1556e-13
  0.000000	  0.000000	diff=2.3503e-13
 -0.000000	 -0.000000	diff=4.497e-13
  0.000000	  0.000000	diff=1.26662e-13
 -0.000000	 -0.000000	diff=7.56155e-13
 -0.000010	 -0.000010	diff=1.40094e-09
  0.000006	  0.000006	diff=3.61153e-09
 -0.000000	 -0.000000	diff=3.25059e-13
  0.000000	  0.000000	diff=1.93779e-13
  0.000000	  0.000000	diff=6.82007e-13
  0.000000	  0.000000	diff=1.46005e-13
 -0.000000	 -0.000000	diff=6.81174e-13
  0.000000	  0.000000	diff=5.09287e-13
 -0.000001	 -0.000001	diff=2.44011e-09
  0.000010	  0.000010	diff=1.44717e-10
  0.000000	  0.000000	diff=2.12523e-13
  0.000000	  0.000000	diff=2.90598e-13
 -0.000000	 -0.000000	diff=5.47854e-13
 -0.000000	 -0.000000	diff=3.97262e-13
  0.000000	  0.000000	diff=3.83309e-13
 -0.000000	 -0.000000	diff=2.3611e-13
  0.000001	  0.000001	diff=1.9942e-12
 -0.000010	 -0.000010	diff=3.88842e-09
  local_diff=1.48718e-08
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000069	 -0.000069	diff=2.71427e-08
  0.000052	  0.000052	diff=5.86418e-08
 -0.000077	 -0.000077	diff=3.39724e-08
  0.000055	  0.000055	diff=7.00118e-08
  local_diff=1.89769e-07
# W_emb_tgt, [2 4]
 -0.000194	 -0.000194	diff=4.48346e-08
  0.000009	  0.000009	diff=3.76697e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000066	 -0.000066	diff=1.23607e-09
  0.000005	  0.000005	diff=3.73416e-09
  0.000047	  0.000047	diff=1.31973e-08
 -0.000003	 -0.000003	diff=2.08585e-09
  local_diff=6.8855e-08
# W_soft, [4 2]
  0.000076	  0.000076	diff=3.22358e-11
 -0.000222	 -0.000222	diff=3.22656e-11
  0.000120	  0.000120	diff=3.27771e-11
  0.000025	  0.000025	diff=3.27508e-11
  0.000468	  0.000468	diff=1.4538e-10
 -0.000177	 -0.000177	diff=1.4486e-10
 -0.000386	 -0.000386	diff=1.45896e-10
  0.000095	  0.000095	diff=1.45087e-10
  local_diff=7.11253e-10
# Num params=168, abs_diff=2.9617e-07
Elapsed time is 1.422960 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 176, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 176
  src input 1: <s> y x x
  src mask: 0  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=3.2965e-13
  0.000000	  0.000000	diff=7.12138e-13
 -0.000000	 -0.000000	diff=1.97651e-13
  0.000000	  0.000000	diff=1.04118e-12
 -0.000000	 -0.000000	diff=1.27162e-12
 -0.000000	 -0.000000	diff=4.32033e-13
  0.000003	  0.000003	diff=1.86687e-11
  0.000002	  0.000002	diff=2.2171e-11
  0.000000	  0.000000	diff=1.12766e-12
 -0.000000	 -0.000000	diff=6.67334e-13
  0.000000	  0.000000	diff=1.12551e-12
 -0.000000	 -0.000000	diff=8.48588e-15
  0.000000	  0.000000	diff=4.10143e-13
  0.000000	  0.000000	diff=1.35247e-13
 -0.000006	 -0.000006	diff=8.70011e-11
 -0.000004	 -0.000004	diff=6.36233e-11
  0.000000	  0.000000	diff=1.66134e-13
 -0.000000	 -0.000000	diff=8.52312e-13
  0.000000	  0.000000	diff=5.15942e-14
 -0.000000	 -0.000000	diff=4.04008e-13
  0.000000	  0.000000	diff=6.76142e-13
  0.000000	  0.000000	diff=1.69425e-13
 -0.000000	 -0.000000	diff=1.14682e-10
 -0.000000	 -0.000000	diff=6.96233e-14
 -0.000000	 -0.000000	diff=1.39121e-12
  0.000000	  0.000000	diff=4.66441e-13
 -0.000000	 -0.000000	diff=1.11037e-12
  0.000000	  0.000000	diff=6.57036e-14
 -0.000000	 -0.000000	diff=1.08041e-12
 -0.000000	 -0.000000	diff=9.28536e-14
  0.000000	  0.000000	diff=2.60077e-14
  0.000000	  0.000000	diff=4.98597e-11
  local_diff=3.70086e-10
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=5.74578e-13
  0.000000	  0.000000	diff=8.80815e-13
  0.000000	  0.000000	diff=4.65577e-13
  0.000000	  0.000000	diff=1.10136e-12
  0.000000	  0.000000	diff=1.85604e-12
 -0.000000	 -0.000000	diff=7.78986e-13
 -0.000002	 -0.000002	diff=6.26917e-13
  0.000004	  0.000004	diff=5.65538e-12
 -0.000000	 -0.000000	diff=4.1652e-13
 -0.000000	 -0.000000	diff=5.34292e-15
 -0.000000	 -0.000000	diff=1.64527e-13
 -0.000000	 -0.000000	diff=4.99913e-13
 -0.000000	 -0.000000	diff=4.77374e-13
  0.000000	  0.000000	diff=5.44519e-13
  0.000001	  0.000001	diff=3.76301e-13
 -0.000003	 -0.000003	diff=4.57409e-12
  0.000000	  0.000000	diff=5.60096e-13
  0.000000	  0.000000	diff=8.90438e-13
  0.000000	  0.000000	diff=8.04132e-13
  0.000000	  0.000000	diff=3.17729e-13
  0.000000	  0.000000	diff=2.73779e-13
 -0.000000	 -0.000000	diff=5.46029e-13
 -0.000000	 -0.000000	diff=1.36016e-11
  0.000000	  0.000000	diff=4.47956e-13
 -0.000000	 -0.000000	diff=4.0977e-13
 -0.000000	 -0.000000	diff=2.759e-13
 -0.000000	 -0.000000	diff=4.33386e-13
 -0.000000	 -0.000000	diff=1.32425e-13
 -0.000000	 -0.000000	diff=9.47494e-13
  0.000000	  0.000000	diff=6.62898e-13
  0.000000	  0.000000	diff=6.03045e-13
 -0.000000	 -0.000000	diff=1.41899e-10
  local_diff=1.81804e-10
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=9.08303e-13
  0.000000	  0.000000	diff=2.92735e-13
  0.000000	  0.000000	diff=5.10214e-13
  0.000000	  0.000000	diff=1.4162e-12
  0.000000	  0.000000	diff=5.39393e-13
  0.000000	  0.000000	diff=1.14e-13
 -0.000001	 -0.000001	diff=2.09133e-11
 -0.000001	 -0.000001	diff=6.95669e-12
  0.000000	  0.000000	diff=5.9304e-13
 -0.000000	 -0.000000	diff=1.0049e-13
 -0.000000	 -0.000000	diff=1.00333e-12
 -0.000000	 -0.000000	diff=2.45925e-12
 -0.000000	 -0.000000	diff=1.16578e-12
 -0.000000	 -0.000000	diff=1.32972e-12
  0.000001	  0.000001	diff=1.28788e-11
 -0.000004	 -0.000004	diff=1.04733e-10
 -0.000000	  0.000000	diff=7.24181e-13
  0.000000	  0.000000	diff=6.54956e-14
 -0.000000	 -0.000000	diff=7.09276e-13
 -0.000000	 -0.000000	diff=6.97976e-13
 -0.000000	  0.000000	diff=7.1477e-13
  0.000000	  0.000000	diff=8.15942e-14
 -0.000000	 -0.000000	diff=2.47567e-13
 -0.000000	 -0.000000	diff=1.90431e-13
  0.000000	 -0.000000	diff=1.80093e-15
  0.000000	  0.000000	diff=2.09289e-13
  0.000000	 -0.000000	diff=6.77123e-15
  0.000000	  0.000000	diff=4.3077e-14
  0.000000	 -0.000000	diff=1.14006e-14
 -0.000000	  0.000000	diff=9.44019e-13
 -0.000000	 -0.000000	diff=1.08135e-12
 -0.000000	 -0.000000	diff=1.77677e-13
 -0.000000	 -0.000000	diff=9.95793e-13
  0.000000	  0.000000	diff=3.68679e-13
 -0.000000	 -0.000000	diff=1.16424e-12
 -0.000000	 -0.000000	diff=5.33128e-13
 -0.000000	 -0.000000	diff=2.46199e-13
 -0.000000	 -0.000000	diff=7.36933e-13
  0.000000	  0.000000	diff=1.36178e-11
 -0.000000	 -0.000000	diff=3.88981e-12
 -0.000000	 -0.000000	diff=8.87389e-13
 -0.000000	 -0.000000	diff=1.14106e-13
 -0.000000	 -0.000000	diff=1.0964e-12
  0.000000	  0.000000	diff=1.1347e-12
 -0.000000	 -0.000000	diff=8.42824e-13
  0.000000	  0.000000	diff=1.72391e-12
  0.000000	  0.000000	diff=3.36239e-13
  0.000000	  0.000000	diff=2.92498e-10
  local_diff=4.82006e-10
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=1.3294e-12
 -0.000000	 -0.000000	diff=2.75226e-14
 -0.000000	 -0.000000	diff=7.05726e-13
  0.000000	  0.000000	diff=1.48057e-12
  0.000000	  0.000000	diff=7.8082e-13
  0.000000	  0.000000	diff=1.14096e-12
  0.000001	  0.000001	diff=4.21917e-13
  0.000023	  0.000023	diff=5.17121e-11
  0.000000	  0.000000	diff=2.45468e-13
 -0.000000	 -0.000000	diff=2.92155e-13
  0.000000	  0.000000	diff=1.35844e-12
 -0.000000	 -0.000000	diff=8.42123e-14
  0.000000	  0.000000	diff=7.96005e-13
 -0.000000	 -0.000000	diff=9.26576e-14
 -0.000000	 -0.000000	diff=4.85996e-13
 -0.000005	 -0.000005	diff=6.7674e-12
  0.000000	  0.000000	diff=4.8598e-14
 -0.000000	 -0.000000	diff=1.31257e-12
 -0.000000	 -0.000000	diff=7.00526e-13
  0.000000	  0.000000	diff=7.01765e-13
 -0.000000	 -0.000000	diff=5.54098e-14
  0.000000	  0.000000	diff=9.73242e-13
  0.000000	  0.000000	diff=5.71334e-12
  0.000000	  0.000000	diff=1.97919e-12
 -0.000000	 -0.000000	diff=3.31356e-13
  0.000000	  0.000000	diff=8.94313e-13
  0.000000	  0.000000	diff=9.99289e-14
 -0.000000	 -0.000000	diff=2.99627e-13
  0.000000	  0.000000	diff=5.20958e-13
 -0.000000	 -0.000000	diff=1.34272e-13
 -0.000000	 -0.000000	diff=1.71622e-12
 -0.000000	 -0.000000	diff=3.69546e-10
  local_diff=4.52749e-10
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000004	 -0.000004	diff=1.57778e-09
  0.000002	  0.000002	diff=2.14775e-09
 -0.000001	 -0.000001	diff=6.94524e-10
  0.000000	  0.000000	diff=1.26903e-09
  local_diff=5.68908e-09
# W_emb_tgt, [2 4]
 -0.000004	 -0.000004	diff=3.21835e-10
  0.000001	  0.000001	diff=4.44303e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000004	  0.000004	diff=2.41819e-11
 -0.000000	 -0.000000	diff=7.3905e-11
  0.000001	  0.000001	diff=2.56938e-10
  0.000000	  0.000000	diff=8.19036e-11
  local_diff=1.20307e-09
# W_h, [2 4]
 -0.000003	 -0.000003	diff=7.73707e-13
  0.000014	  0.000014	diff=8.08309e-13
  0.000004	  0.000004	diff=5.18853e-13
 -0.000017	 -0.000017	diff=1.8697e-13
  0.000011	  0.000011	diff=1.00476e-11
 -0.000010	 -0.000010	diff=1.89821e-12
  0.000008	  0.000008	diff=6.83052e-11
 -0.000018	 -0.000018	diff=7.83269e-11
  local_diff=1.60866e-10
# W_soft, [4 2]
  0.000011	  0.000011	diff=3.2259e-15
 -0.000007	 -0.000007	diff=1.27227e-13
  0.000000	  0.000000	diff=1.36648e-12
 -0.000004	 -0.000004	diff=1.35169e-12
  0.000005	  0.000005	diff=6.21382e-13
 -0.000006	 -0.000006	diff=6.0263e-13
  0.000001	  0.000001	diff=1.15134e-12
 -0.000000	 -0.000000	diff=4.66816e-13
  local_diff=5.69079e-12
# Num params=176, abs_diff=8.54535e-09
Elapsed time is 2.062545 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 4, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_pos=4 v_pos=2 W_h=8 W_soft=8
# assert = 0
# attnFunc = 4
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# distSigma = 0.5
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=2.71687e-13
  0.000000	  0.000000	diff=8.28964e-14
 -0.000000	 -0.000000	diff=1.7857e-13
  0.000000	  0.000000	diff=1.90113e-13
 -0.000000	 -0.000000	diff=6.89225e-14
 -0.000000	 -0.000000	diff=3.57871e-13
  0.000004	  0.000004	diff=1.07605e-11
  0.000003	  0.000003	diff=2.93421e-11
  0.000000	  0.000000	diff=5.04435e-13
 -0.000000	 -0.000000	diff=8.58211e-13
  0.000000	  0.000000	diff=1.39824e-12
 -0.000000	 -0.000000	diff=8.29743e-13
  0.000000	  0.000000	diff=3.15718e-13
  0.000000	  0.000000	diff=6.72157e-13
 -0.000008	 -0.000008	diff=2.33623e-11
 -0.000010	 -0.000010	diff=1.26155e-10
  0.000000	  0.000000	diff=6.78227e-13
 -0.000000	 -0.000000	diff=1.4656e-13
  0.000000	  0.000000	diff=5.10438e-13
 -0.000000	 -0.000000	diff=1.23407e-12
  0.000000	  0.000000	diff=8.56847e-13
  0.000000	  0.000000	diff=4.39557e-13
 -0.000000	 -0.000000	diff=2.07915e-10
 -0.000000	 -0.000000	diff=5.17253e-13
 -0.000000	 -0.000000	diff=7.17614e-13
  0.000000	  0.000000	diff=7.58801e-13
 -0.000000	 -0.000000	diff=6.36763e-13
  0.000000	  0.000000	diff=1.01506e-12
 -0.000000	 -0.000000	diff=1.93524e-13
 -0.000000	 -0.000000	diff=3.61677e-13
  0.000000	  0.000000	diff=8.23499e-13
  0.000000	  0.000000	diff=1.08666e-10
  local_diff=5.2082e-10
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=1.02347e-12
  0.000000	  0.000000	diff=9.18735e-13
  0.000000	  0.000000	diff=2.30604e-13
  0.000000	  0.000000	diff=2.9795e-13
  0.000000	  0.000000	diff=9.87274e-13
 -0.000000	 -0.000000	diff=7.04221e-13
 -0.000006	 -0.000006	diff=2.10753e-12
  0.000003	  0.000003	diff=3.81267e-12
 -0.000000	 -0.000000	diff=5.63104e-14
 -0.000000	 -0.000000	diff=3.55146e-13
 -0.000000	 -0.000000	diff=3.27472e-13
 -0.000000	 -0.000000	diff=7.98446e-13
 -0.000000	 -0.000000	diff=1.22075e-12
  0.000000	  0.000000	diff=1.3376e-12
  0.000005	  0.000005	diff=1.24932e-12
 -0.000006	 -0.000006	diff=4.86803e-12
  0.000000	  0.000000	diff=3.39893e-13
  0.000000	  0.000000	diff=5.03933e-13
  0.000000	  0.000000	diff=3.75673e-13
  0.000000	  0.000000	diff=5.35814e-14
  0.000000	  0.000000	diff=6.8374e-13
 -0.000000	 -0.000000	diff=5.44613e-13
 -0.000000	 -0.000000	diff=7.73482e-11
  0.000000	  0.000000	diff=4.1021e-13
 -0.000000	 -0.000000	diff=2.98706e-13
 -0.000000	 -0.000000	diff=1.58369e-13
 -0.000000	 -0.000000	diff=2.97308e-14
 -0.000000	 -0.000000	diff=1.61023e-13
 -0.000000	 -0.000000	diff=1.15282e-13
  0.000000	  0.000000	diff=3.35517e-13
  0.000000	  0.000000	diff=3.19622e-13
 -0.000000	 -0.000000	diff=2.45057e-10
  local_diff=3.47031e-10
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=5.03167e-13
 -0.000000	 -0.000000	diff=5.74068e-13
  0.000000	  0.000000	diff=2.455e-12
 -0.000000	 -0.000000	diff=1.20897e-12
  0.000000	  0.000000	diff=9.82009e-14
 -0.000000	 -0.000000	diff=9.87182e-14
 -0.000007	 -0.000007	diff=1.22237e-10
  0.000032	  0.000032	diff=2.39761e-10
  0.000000	  0.000000	diff=3.2665e-13
  0.000000	  0.000000	diff=3.49818e-13
 -0.000000	 -0.000000	diff=1.13498e-12
 -0.000000	 -0.000000	diff=2.27461e-12
  0.000000	  0.000000	diff=1.49257e-12
  0.000000	  0.000000	diff=2.8442e-13
  0.000004	  0.000004	diff=3.88136e-11
 -0.000031	 -0.000031	diff=3.71834e-10
 -0.000000	 -0.000000	diff=1.04728e-12
  0.000000	  0.000000	diff=7.14618e-13
 -0.000000	 -0.000000	diff=1.14585e-12
  0.000000	  0.000000	diff=9.14845e-14
 -0.000000	 -0.000000	diff=9.37029e-13
  0.000000	  0.000000	diff=5.66958e-13
  0.000000	  0.000000	diff=1.33375e-13
 -0.000000	 -0.000000	diff=4.97554e-14
  0.000000	  0.000000	diff=3.71943e-13
 -0.000000	 -0.000000	diff=8.14965e-13
 -0.000000	  0.000000	diff=1.62818e-12
 -0.000000	 -0.000000	diff=1.04998e-12
  0.000000	  0.000000	diff=4.93835e-13
 -0.000000	 -0.000000	diff=9.78392e-13
 -0.000000	 -0.000000	diff=6.6155e-13
  0.000000	  0.000000	diff=1.07926e-12
 -0.000000	 -0.000000	diff=1.89555e-13
  0.000000	  0.000000	diff=4.25635e-13
 -0.000000	 -0.000000	diff=2.53682e-13
 -0.000000	 -0.000000	diff=1.61235e-13
 -0.000000	 -0.000000	diff=5.27782e-14
  0.000000	  0.000000	diff=2.48394e-13
  0.000000	  0.000000	diff=5.81092e-10
 -0.000001	 -0.000001	diff=2.48722e-11
 -0.000000	 -0.000000	diff=6.65829e-14
  0.000000	  0.000000	diff=6.93715e-13
  0.000000	  0.000000	diff=7.15414e-14
  0.000000	  0.000000	diff=9.46472e-13
 -0.000000	 -0.000000	diff=4.11023e-13
  0.000000	  0.000000	diff=3.49565e-13
 -0.000000	 -0.000000	diff=5.31746e-12
  0.000000	  0.000000	diff=7.79432e-10
  local_diff=2.18979e-09
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=1.09465e-12
  0.000000	  0.000000	diff=8.29531e-13
  0.000000	  0.000000	diff=3.57942e-13
  0.000000	  0.000000	diff=7.25626e-13
 -0.000000	 -0.000000	diff=3.35214e-13
  0.000000	  0.000000	diff=3.91768e-13
 -0.000014	 -0.000014	diff=5.96309e-12
  0.000019	  0.000019	diff=2.20487e-11
 -0.000000	 -0.000000	diff=2.22214e-13
  0.000000	  0.000000	diff=8.71873e-14
 -0.000000	 -0.000000	diff=5.05379e-14
  0.000000	  0.000000	diff=2.12022e-14
 -0.000000	 -0.000000	diff=4.02202e-13
  0.000000	  0.000000	diff=2.03783e-14
 -0.000018	 -0.000018	diff=4.47466e-11
  0.000021	  0.000021	diff=7.15971e-11
 -0.000000	 -0.000000	diff=5.55991e-13
 -0.000000	 -0.000000	diff=2.31795e-13
  0.000000	  0.000000	diff=5.1202e-13
  0.000000	  0.000000	diff=1.36825e-12
  0.000000	  0.000000	diff=5.01908e-13
  0.000000	  0.000000	diff=7.04833e-13
 -0.000000	 -0.000000	diff=8.09976e-10
  0.000000	  0.000000	diff=2.16895e-11
  0.000000	  0.000000	diff=2.93865e-13
 -0.000000	 -0.000000	diff=7.35344e-13
 -0.000000	 -0.000000	diff=1.16281e-12
 -0.000000	 -0.000000	diff=3.36868e-13
  0.000000	  0.000000	diff=4.6684e-13
 -0.000000	 -0.000000	diff=5.03331e-13
  0.000001	  0.000001	diff=3.81398e-12
 -0.000001	 -0.000001	diff=1.90861e-09
  local_diff=2.90036e-09
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000005	 -0.000005	diff=1.70782e-09
 -0.000001	 -0.000001	diff=5.15328e-10
 -0.000003	 -0.000003	diff=1.28676e-09
 -0.000003	 -0.000003	diff=2.31388e-10
  local_diff=3.7413e-09
# W_emb_tgt, [2 4]
 -0.000016	 -0.000016	diff=4.41144e-09
  0.000002	  0.000002	diff=1.08393e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000014	 -0.000014	diff=5.36535e-09
  0.000002	  0.000002	diff=1.10428e-09
 -0.000005	 -0.000005	diff=2.92347e-09
  0.000002	  0.000002	diff=1.17225e-09
  local_diff=1.60607e-08
# W_pos, [2 2]
  0.000000	  0.000000	diff=3.99914e-15
  0.000000	  0.000000	diff=5.06273e-15
  0.000000	 -0.000000	diff=1.24126e-14
  0.000000	 -0.000000	diff=1.57138e-14
  local_diff=3.71882e-14
# v_pos, [1 2]
 -0.000000	  0.000000	diff=1.49251e-12
  0.000000	  0.000000	diff=2.52354e-13
  local_diff=1.74486e-12
# W_h, [2 4]
 -0.000009	 -0.000009	diff=2.12962e-13
  0.000006	  0.000006	diff=2.9753e-13
  0.000011	  0.000011	diff=3.7415e-13
 -0.000008	 -0.000008	diff=1.09474e-14
  0.000005	  0.000005	diff=3.55734e-12
  0.000000	  0.000000	diff=1.56363e-12
  0.000032	  0.000032	diff=1.59095e-10
 -0.000018	 -0.000018	diff=4.4842e-11
  local_diff=2.09954e-10
# W_soft, [4 2]
 -0.000017	 -0.000017	diff=5.5238e-13
 -0.000002	 -0.000002	diff=3.83745e-13
  0.000013	  0.000013	diff=2.08119e-14
  0.000005	  0.000005	diff=2.0477e-13
  0.000034	  0.000034	diff=1.38478e-13
 -0.000021	 -0.000021	diff=2.47524e-13
 -0.000013	 -0.000013	diff=3.38367e-13
  0.000001	  0.000001	diff=1.38259e-14
  local_diff=1.8999e-12
# Num params=182, abs_diff=2.59737e-08
Elapsed time is 2.878973 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 180, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 180
  src input 1: <s> <s> x y
  src mask: 0  0  1  1
  tgt input 1: <s> a </s> </s> </s>
  tgt output 1: a </s> </s> </s> </s>
  tgt mask: 1  1  0  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=7.25527e-13
  0.000000	  0.000000	diff=3.30373e-13
 -0.000000	 -0.000000	diff=6.59947e-13
  0.000000	  0.000000	diff=3.96124e-13
 -0.000000	 -0.000000	diff=6.46696e-13
 -0.000000	 -0.000000	diff=3.60854e-13
  0.000004	  0.000004	diff=1.64823e-11
  0.000002	  0.000002	diff=2.46041e-11
  0.000000	  0.000000	diff=1.89628e-13
 -0.000000	 -0.000000	diff=1.09527e-12
  0.000000	  0.000000	diff=1.38839e-12
 -0.000000	 -0.000000	diff=5.56712e-13
  0.000000	  0.000000	diff=9.92847e-13
  0.000000	  0.000000	diff=7.81952e-13
 -0.000004	 -0.000004	diff=1.75265e-11
 -0.000008	 -0.000008	diff=1.09849e-10
  0.000000	  0.000000	diff=6.72281e-13
 -0.000000	 -0.000000	diff=7.11101e-13
  0.000000	  0.000000	diff=1.69794e-13
 -0.000000	 -0.000000	diff=6.40575e-13
 -0.000000	 -0.000000	diff=9.25861e-13
  0.000000	  0.000000	diff=1.08435e-12
 -0.000000	 -0.000000	diff=1.36348e-11
 -0.000000	 -0.000000	diff=1.1162e-12
 -0.000000	 -0.000000	diff=1.12875e-12
  0.000000	  0.000000	diff=4.8725e-13
 -0.000000	 -0.000000	diff=7.88368e-13
  0.000000	  0.000000	diff=7.05899e-13
  0.000000	  0.000000	diff=6.91426e-13
 -0.000000	 -0.000000	diff=1.12456e-12
  0.000000	  0.000000	diff=2.6305e-13
  0.000000	  0.000000	diff=8.86e-11
  local_diff=2.89331e-10
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=2.77226e-13
  0.000000	  0.000000	diff=3.53462e-13
 -0.000000	 -0.000000	diff=8.21037e-13
  0.000000	  0.000000	diff=5.901e-13
  0.000000	  0.000000	diff=1.10312e-12
  0.000000	  0.000000	diff=1.46781e-12
  0.000004	  0.000004	diff=3.07653e-13
  0.000006	  0.000006	diff=1.02407e-12
  0.000000	  0.000000	diff=5.89346e-13
 -0.000000	 -0.000000	diff=1.48621e-12
  0.000000	  0.000000	diff=5.84522e-13
 -0.000000	 -0.000000	diff=1.85798e-13
 -0.000000	 -0.000000	diff=1.10088e-12
 -0.000000	 -0.000000	diff=8.72813e-13
 -0.000007	 -0.000007	diff=1.38621e-12
 -0.000011	 -0.000011	diff=2.23378e-12
 -0.000000	 -0.000000	diff=5.47288e-13
  0.000000	  0.000000	diff=1.36964e-12
 -0.000000	 -0.000000	diff=1.24207e-12
 -0.000000	  0.000000	diff=9.60686e-13
 -0.000000	  0.000000	diff=1.04472e-12
  0.000000	  0.000000	diff=1.12475e-12
  0.000000	  0.000000	diff=2.34169e-11
  0.000000	  0.000000	diff=1.64329e-12
  0.000000	  0.000000	diff=1.18779e-12
 -0.000000	 -0.000000	diff=4.0224e-13
  0.000000	  0.000000	diff=5.73037e-13
 -0.000000	 -0.000000	diff=1.38834e-13
 -0.000000	 -0.000000	diff=1.00893e-12
 -0.000000	 -0.000000	diff=1.09906e-12
 -0.000000	 -0.000000	diff=1.10885e-12
 -0.000000	 -0.000000	diff=3.64226e-11
  local_diff=8.76747e-11
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=1.04432e-12
 -0.000000	 -0.000000	diff=5.66269e-13
 -0.000000	 -0.000000	diff=2.60918e-12
 -0.000000	 -0.000000	diff=1.45481e-12
 -0.000000	 -0.000000	diff=6.97181e-13
 -0.000000	 -0.000000	diff=5.79122e-13
  0.000007	  0.000007	diff=1.62641e-10
  0.000064	  0.000064	diff=1.69971e-10
 -0.000000	 -0.000000	diff=1.37756e-12
  0.000000	  0.000000	diff=1.14599e-12
  0.000000	  0.000000	diff=1.04707e-14
 -0.000000	 -0.000000	diff=3.46298e-12
  0.000000	  0.000000	diff=5.90249e-13
  0.000000	  0.000000	diff=1.689e-12
 -0.000004	 -0.000004	diff=5.70541e-11
 -0.000036	 -0.000036	diff=2.73003e-10
 -0.000000	 -0.000000	diff=2.29041e-13
 -0.000000	 -0.000000	diff=4.95275e-13
 -0.000000	 -0.000000	diff=5.93886e-13
 -0.000000	 -0.000000	diff=6.37361e-13
 -0.000000	 -0.000000	diff=5.84604e-13
 -0.000000	 -0.000000	diff=9.52663e-13
  0.000000	  0.000000	diff=2.34704e-13
  0.000000	  0.000000	diff=6.99316e-13
 -0.000000	 -0.000000	diff=6.75809e-14
 -0.000000	 -0.000000	diff=3.48978e-13
  0.000000	 -0.000000	diff=3.91101e-13
 -0.000000	 -0.000000	diff=1.46681e-14
 -0.000000	 -0.000000	diff=6.65243e-13
 -0.000000	 -0.000000	diff=4.81605e-13
  0.000000	  0.000000	diff=1.11316e-12
  0.000000	  0.000000	diff=3.2885e-13
  0.000000	  0.000000	diff=1.37428e-12
  0.000000	  0.000000	diff=5.87971e-13
  0.000000	  0.000000	diff=1.42301e-13
  0.000000	  0.000000	diff=8.2193e-13
  0.000000	  0.000000	diff=1.59667e-12
  0.000000	  0.000000	diff=9.64348e-13
 -0.000000	 -0.000000	diff=3.62852e-10
 -0.000001	 -0.000001	diff=6.24802e-11
  0.000000	  0.000000	diff=1.3009e-12
  0.000000	  0.000000	diff=5.60905e-13
 -0.000000	 -0.000000	diff=1.06845e-12
  0.000000	  0.000000	diff=9.52214e-13
  0.000000	  0.000000	diff=2.4071e-13
  0.000000	  0.000000	diff=9.41199e-13
  0.000000	  0.000000	diff=2.07587e-12
 -0.000000	 -0.000000	diff=5.40467e-10
  local_diff=1.66416e-09
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=1.14414e-12
  0.000000	  0.000000	diff=7.24542e-13
 -0.000000	 -0.000000	diff=5.47795e-13
  0.000000	  0.000000	diff=7.66428e-13
  0.000000	  0.000000	diff=7.08064e-13
  0.000000	  0.000000	diff=9.00708e-13
  0.000015	  0.000015	diff=5.81742e-12
  0.000024	  0.000024	diff=4.45132e-11
  0.000000	  0.000000	diff=5.18061e-13
  0.000000	  0.000000	diff=5.38292e-13
  0.000000	  0.000000	diff=2.11489e-13
  0.000000	  0.000000	diff=3.8802e-13
  0.000000	  0.000000	diff=1.61666e-13
  0.000000	  0.000000	diff=4.22923e-13
  0.000024	  0.000024	diff=5.52161e-12
  0.000046	  0.000046	diff=2.53993e-10
  0.000000	  0.000000	diff=9.30403e-13
 -0.000000	 -0.000000	diff=1.54542e-12
 -0.000000	 -0.000000	diff=8.06774e-13
 -0.000000	 -0.000000	diff=3.47252e-13
 -0.000000	 -0.000000	diff=4.79507e-13
 -0.000000	 -0.000000	diff=9.1413e-13
  0.000000	  0.000000	diff=6.49666e-10
  0.000000	  0.000000	diff=2.57365e-11
 -0.000000	 -0.000000	diff=6.15397e-13
 -0.000000	 -0.000000	diff=1.35272e-12
  0.000000	  0.000000	diff=5.85448e-13
 -0.000000	 -0.000000	diff=3.30374e-13
 -0.000000	 -0.000000	diff=1.3182e-12
 -0.000000	 -0.000000	diff=5.95356e-13
 -0.000001	 -0.000001	diff=1.67821e-12
 -0.000001	 -0.000001	diff=2.95445e-09
  local_diff=3.95823e-09
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000004	 -0.000004	diff=1.73563e-09
 -0.000000	 -0.000000	diff=3.30264e-11
 -0.000003	 -0.000003	diff=1.21769e-09
 -0.000005	 -0.000005	diff=3.20416e-09
  local_diff=6.19051e-09
# W_emb_tgt, [2 4]
 -0.000027	 -0.000027	diff=2.64387e-09
 -0.000001	 -0.000001	diff=1.23787e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000037	 -0.000037	diff=8.6769e-09
  0.000000	  0.000000	diff=6.04578e-10
 -0.000024	 -0.000024	diff=1.27233e-09
 -0.000000	 -0.000000	diff=7.29822e-10
  local_diff=1.51654e-08
# W_a, [2 2]
  0.000000	  0.000000	diff=1.72623e-15
  0.000000	 -0.000000	diff=2.0995e-15
  0.000000	  0.000000	diff=1.56581e-15
  0.000000	 -0.000000	diff=1.94789e-15
  local_diff=7.33944e-15
# W_h, [2 4]
  0.000014	  0.000014	diff=1.64191e-13
 -0.000010	 -0.000010	diff=1.82098e-12
 -0.000020	 -0.000020	diff=8.50536e-13
  0.000014	  0.000014	diff=1.94071e-12
 -0.000015	 -0.000015	diff=5.23726e-12
 -0.000003	 -0.000003	diff=4.53978e-12
 -0.000069	 -0.000069	diff=4.91424e-10
  0.000023	  0.000023	diff=2.77838e-12
  local_diff=5.08756e-10
# W_soft, [4 2]
  0.000052	  0.000052	diff=6.21727e-13
 -0.000028	 -0.000028	diff=1.61122e-13
 -0.000026	 -0.000026	diff=6.56221e-13
  0.000003	  0.000003	diff=6.92557e-13
  0.000014	  0.000014	diff=6.11559e-16
 -0.000001	 -0.000001	diff=1.18726e-12
 -0.000009	 -0.000009	diff=1.40216e-12
 -0.000004	 -0.000004	diff=9.63901e-13
  local_diff=5.68557e-12
# Num params=180, abs_diff=2.78697e-08
Elapsed time is 2.198152 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 3)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 v_a=2 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 3
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=1.21914e-12
  0.000000	  0.000000	diff=2.03453e-12
 -0.000000	 -0.000000	diff=1.08414e-12
  0.000000	  0.000000	diff=3.52963e-13
 -0.000000	 -0.000000	diff=8.92648e-13
 -0.000000	 -0.000000	diff=1.62804e-12
  0.000003	  0.000003	diff=1.42265e-11
  0.000003	  0.000003	diff=3.31189e-11
  0.000000	  0.000000	diff=1.30119e-12
 -0.000000	 -0.000000	diff=1.39862e-12
  0.000000	  0.000000	diff=1.91037e-12
 -0.000000	 -0.000000	diff=1.55124e-12
  0.000000	  0.000000	diff=1.31835e-12
  0.000000	  0.000000	diff=7.75057e-13
 -0.000006	 -0.000006	diff=3.56686e-11
 -0.000011	 -0.000011	diff=1.35085e-10
  0.000000	  0.000000	diff=8.70774e-13
 -0.000000	 -0.000000	diff=1.18393e-12
  0.000000	  0.000000	diff=1.328e-12
 -0.000000	 -0.000000	diff=1.49884e-12
  0.000000	  0.000000	diff=1.0172e-12
  0.000000	  0.000000	diff=1.02992e-12
 -0.000000	 -0.000000	diff=1.34342e-10
 -0.000000	 -0.000000	diff=2.32447e-12
 -0.000000	 -0.000000	diff=9.45594e-13
  0.000000	  0.000000	diff=6.25907e-13
 -0.000000	 -0.000000	diff=1.45837e-12
  0.000000	  0.000000	diff=1.06635e-12
 -0.000000	 -0.000000	diff=6.8813e-13
 -0.000000	 -0.000000	diff=1.9757e-12
  0.000000	  0.000000	diff=7.78732e-14
  0.000000	  0.000000	diff=1.31043e-10
  local_diff=5.15042e-10
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=1.02997e-12
  0.000000	  0.000000	diff=1.3527e-12
  0.000000	  0.000000	diff=2.13038e-14
  0.000000	  0.000000	diff=6.30099e-13
  0.000000	  0.000000	diff=4.03861e-13
 -0.000000	 -0.000000	diff=4.09256e-13
 -0.000007	 -0.000007	diff=1.64441e-12
  0.000001	  0.000001	diff=5.66841e-12
 -0.000000	 -0.000000	diff=8.32569e-13
 -0.000000	 -0.000000	diff=8.74844e-13
 -0.000000	 -0.000000	diff=1.86688e-12
 -0.000000	 -0.000000	diff=1.13211e-12
 -0.000000	 -0.000000	diff=1.36893e-12
  0.000000	  0.000000	diff=1.04505e-12
  0.000005	  0.000005	diff=1.95071e-12
 -0.000003	 -0.000003	diff=6.48931e-12
  0.000000	  0.000000	diff=2.21508e-13
  0.000000	  0.000000	diff=1.75907e-13
  0.000000	  0.000000	diff=1.37113e-12
  0.000000	  0.000000	diff=1.58948e-12
  0.000000	  0.000000	diff=8.79805e-13
 -0.000000	 -0.000000	diff=1.02887e-12
 -0.000000	 -0.000000	diff=1.06276e-10
  0.000000	  0.000000	diff=8.28464e-13
 -0.000000	 -0.000000	diff=1.76287e-12
 -0.000000	 -0.000000	diff=1.84826e-12
 -0.000000	 -0.000000	diff=1.50769e-12
 -0.000000	 -0.000000	diff=1.5925e-12
 -0.000000	 -0.000000	diff=1.4096e-12
  0.000000	  0.000000	diff=1.17717e-12
  0.000000	  0.000000	diff=1.20899e-12
 -0.000000	 -0.000000	diff=1.18013e-10
  local_diff=2.67612e-10
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=1.84834e-12
 -0.000000	 -0.000000	diff=5.95989e-14
  0.000000	  0.000000	diff=1.06029e-12
 -0.000000	 -0.000000	diff=4.87089e-14
  0.000000	  0.000000	diff=1.44694e-12
 -0.000000	 -0.000000	diff=1.56916e-12
 -0.000007	 -0.000007	diff=1.20166e-10
  0.000032	  0.000032	diff=2.38629e-10
  0.000000	  0.000000	diff=1.16166e-12
  0.000000	  0.000000	diff=7.57252e-13
 -0.000000	 -0.000000	diff=1.87051e-12
 -0.000000	 -0.000000	diff=2.82517e-12
  0.000000	  0.000000	diff=1.5794e-12
  0.000000	  0.000000	diff=6.67025e-13
  0.000004	  0.000004	diff=3.86825e-11
 -0.000031	 -0.000031	diff=3.70928e-10
 -0.000000	 -0.000000	diff=1.00294e-12
  0.000000	  0.000000	diff=1.01068e-12
 -0.000000	 -0.000000	diff=1.11095e-12
 -0.000000	  0.000000	diff=8.91698e-13
 -0.000000	 -0.000000	diff=1.64908e-13
  0.000000	  0.000000	diff=8.73505e-13
  0.000000	  0.000000	diff=9.03275e-13
 -0.000000	 -0.000000	diff=5.01985e-13
  0.000000	  0.000000	diff=2.65617e-13
 -0.000000	 -0.000000	diff=1.04406e-12
  0.000000	  0.000000	diff=1.32717e-13
 -0.000000	 -0.000000	diff=6.49373e-13
  0.000000	  0.000000	diff=3.72845e-13
 -0.000000	 -0.000000	diff=5.43755e-13
 -0.000000	 -0.000000	diff=1.27143e-12
  0.000000	  0.000000	diff=1.24055e-12
 -0.000000	 -0.000000	diff=9.01832e-13
  0.000000	  0.000000	diff=9.75696e-13
 -0.000000	 -0.000000	diff=4.58081e-13
 -0.000000	 -0.000000	diff=1.57529e-12
 -0.000000	 -0.000000	diff=1.37072e-12
  0.000000	  0.000000	diff=1.64666e-12
  0.000000	  0.000000	diff=5.79812e-10
 -0.000001	 -0.000001	diff=2.40755e-11
 -0.000000	 -0.000000	diff=1.4908e-12
  0.000000	  0.000000	diff=1.37224e-12
  0.000000	  0.000000	diff=6.41895e-13
  0.000000	  0.000000	diff=9.31566e-13
 -0.000000	 -0.000000	diff=1.12611e-12
  0.000000	  0.000000	diff=1.0162e-12
 -0.000000	 -0.000000	diff=5.52999e-12
  0.000000	  0.000000	diff=7.78741e-10
  local_diff=2.19694e-09
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=1.09763e-12
  0.000000	  0.000000	diff=1.48361e-12
  0.000000	  0.000000	diff=1.06353e-12
  0.000000	  0.000000	diff=6.74564e-13
 -0.000000	 -0.000000	diff=1.04716e-12
  0.000000	  0.000000	diff=9.63086e-13
 -0.000014	 -0.000014	diff=5.07338e-12
  0.000019	  0.000019	diff=2.40577e-11
 -0.000000	 -0.000000	diff=9.41081e-13
  0.000000	  0.000000	diff=1.41527e-12
 -0.000000	 -0.000000	diff=1.47241e-12
  0.000000	  0.000000	diff=1.35831e-12
 -0.000000	 -0.000000	diff=2.44564e-12
  0.000000	  0.000000	diff=2.04321e-12
 -0.000018	 -0.000018	diff=4.33427e-11
  0.000021	  0.000021	diff=7.38484e-11
 -0.000000	 -0.000000	diff=1.26653e-12
 -0.000000	 -0.000000	diff=2.31901e-13
  0.000000	  0.000000	diff=1.22254e-12
  0.000000	  0.000000	diff=2.07891e-12
  0.000000	  0.000000	diff=1.21242e-12
  0.000000	  0.000000	diff=1.4157e-12
 -0.000000	 -0.000000	diff=8.11944e-10
  0.000000	  0.000000	diff=2.2411e-11
  0.000000	  0.000000	diff=1.12703e-12
 -0.000000	 -0.000000	diff=7.37007e-13
 -0.000000	 -0.000000	diff=1.16271e-12
 -0.000000	 -0.000000	diff=1.04809e-12
  0.000000	  0.000000	diff=4.66619e-13
 -0.000000	 -0.000000	diff=1.21589e-12
  0.000001	  0.000001	diff=4.5497e-12
 -0.000001	 -0.000001	diff=1.90854e-09
  local_diff=2.92296e-09
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000004	 -0.000004	diff=1.27732e-09
 -0.000002	 -0.000002	diff=1.16182e-09
 -0.000002	 -0.000002	diff=9.71432e-10
 -0.000005	 -0.000005	diff=1.09873e-09
  local_diff=4.5093e-09
# W_emb_tgt, [2 4]
 -0.000016	 -0.000016	diff=4.41251e-09
  0.000002	  0.000002	diff=1.08315e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000014	 -0.000014	diff=5.36542e-09
  0.000002	  0.000002	diff=1.10349e-09
 -0.000005	 -0.000005	diff=2.92407e-09
  0.000002	  0.000002	diff=1.17214e-09
  local_diff=1.60608e-08
# W_a, [2 2]
  0.000000	 -0.000000	diff=4.40436e-23
  0.000000	 -0.000000	diff=7.2354e-23
  0.000000	 -0.000000	diff=1.65894e-22
  0.000000	 -0.000000	diff=2.95469e-22
  local_diff=5.7776e-22
# v_a, [1 2]
 -0.000000	 -0.000000	diff=1.25454e-12
  0.000000	  0.000000	diff=1.82986e-12
  local_diff=3.08441e-12
# W_h, [2 4]
 -0.000014	 -0.000014	diff=7.44315e-13
  0.000010	  0.000010	diff=1.54572e-12
  0.000018	  0.000018	diff=6.18696e-13
 -0.000013	 -0.000013	diff=1.6273e-13
  0.000005	  0.000005	diff=4.70519e-12
  0.000000	  0.000000	diff=8.86246e-14
  0.000032	  0.000032	diff=1.58294e-10
 -0.000018	 -0.000018	diff=4.72752e-11
  local_diff=2.13434e-10
# W_soft, [4 2]
 -0.000019	 -0.000019	diff=4.15344e-13
 -0.000001	 -0.000001	diff=7.38931e-13
  0.000015	  0.000015	diff=5.71911e-13
  0.000005	  0.000005	diff=1.11599e-12
  0.000025	  0.000025	diff=1.1856e-12
 -0.000019	 -0.000019	diff=3.03095e-14
 -0.000007	 -0.000007	diff=5.94445e-13
  0.000001	  0.000001	diff=1.09243e-12
  local_diff=5.74496e-12
# Num params=182, abs_diff=2.66949e-08
Elapsed time is 2.227197 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 104, individual sizes:  W_src{1}=32 W_tgt{1}=48 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 1
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 104
  src input 1: y y x y
  src mask: 1  1  1  1
  tgt input 1: <s> a b a
  tgt output 1: a b a </s>
  tgt mask: 1  1  1  1
# W_src{1}, [8 4]
  0.000000	 -0.000000	diff=6.82914e-27
  0.000000	 -0.000000	diff=1.95177e-30
  0.000000	  0.000000	diff=5.93316e-31
  0.000000	  0.000000	diff=1.85467e-30
  0.000000	  0.000000	diff=7.88768e-13
  0.000033	  0.000033	diff=1.27003e-07
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=5.11769e-35
  0.000000	 -0.000000	diff=9.28012e-28
  0.000000	 -0.000000	diff=2.65226e-31
  0.000000	  0.000000	diff=7.67726e-30
  0.000000	  0.000000	diff=2.52031e-31
  0.000000	  0.000000	diff=5.62715e-13
  0.000450	  0.000428	diff=2.19286e-05
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=6.95443e-36
  0.000000	  0.000000	diff=1.11817e-28
  0.000000	  0.000000	diff=1.76192e-31
  0.000000	  0.000000	diff=5.90119e-31
  0.000000	 -0.000000	diff=1.67428e-31
  0.000000	 -0.000000	diff=5.70229e-13
  0.000000	  0.000000	diff=7.35255e-11
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=6.99214e-37
  0.000000	 -0.000000	diff=6.40794e-33
  0.000000	 -0.000000	diff=1.01069e-35
  0.000000	  0.000000	diff=8.40257e-36
  0.000000	  0.000000	diff=4.81695e-36
  0.000000	  0.000000	diff=3.26791e-17
 -0.000000	 -0.000000	diff=7.55856e-13
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=4.00763e-41
  local_diff=2.20557e-05
# W_tgt{1}, [8 6]
  0.665977	  0.690935	diff=0.0249579
  0.000000	  0.000000	diff=4.854e-10
  0.000000	  0.000000	diff=1.09604e-10
 -0.000000	 -0.000000	diff=8.31765e-13
-18.274228	-18.730010	diff=0.455782
  1.109839	  1.149613	diff=0.0397738
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.847529	 -0.811348	diff=0.0361808
  0.000000	  0.000000	diff=6.54257e-10
  0.000000	  0.000000	diff=6.09258e-12
  0.000000	  0.000000	diff=1.25222e-12
 22.609305	 21.994195	diff=0.61511
 -1.407330	 -1.349962	diff=0.0573681
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.60996e-36
  0.000000	  0.000000	diff=4.20065e-13
  0.000000	 -0.000000	diff=1.66166e-13
  0.000000	  0.000000	diff=5.21662e-62
  0.000000	 -0.000000	diff=6.33113e-39
  0.000000	 -0.000000	diff=2.09809e-30
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=3.86709e-32
  0.000000	  0.000000	diff=1.27216e-30
  0.000000	  0.000000	diff=8.70148e-13
  0.000000	 -0.000000	diff=9.14735e-60
  0.000000	  0.000000	diff=4.32829e-40
  0.000000	 -0.000000	diff=1.59049e-31
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000331	  0.000330	diff=1.19105e-06
  0.000000	  0.000000	diff=4.20065e-13
  0.000000	 -0.000000	diff=1.66166e-13
  0.000000	  0.000000	diff=2.63438e-13
 -0.006521	 -0.006498	diff=2.29323e-05
 -0.111675	 -0.111293	diff=0.000381317
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=3.24856e-13
  0.000000	  0.000000	diff=1.27216e-30
  0.000000	  0.000000	diff=8.70148e-13
  0.000000	 -0.000000	diff=1.38642e-16
  0.000000	  0.000000	diff=1.48915e-13
  0.000008	  0.000008	diff=2.68628e-12
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.22958
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000333	 -0.000347	diff=1.35904e-05
 -0.000013	 -0.000013	diff=1.84116e-08
 -0.000000	 -0.000000	diff=5.60943e-13
 -0.000000	 -0.000000	diff=2.59528e-13
  local_diff=1.36088e-05
# W_emb_tgt, [2 4]
-16.316047	-16.677489	diff=0.361442
-14.005769	-14.271785	diff=0.266017
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.00937e-09
 -0.000000	 -0.000000	diff=3.29865e-10
 -0.000000	 -0.000000	diff=1.12724e-12
 -0.000000	 -0.000000	diff=1.23536e-10
  local_diff=0.627458
# W_soft, [4 2]
  0.014631	  0.014616	diff=1.50311e-05
  0.151565	  0.151456	diff=0.000108968
 -0.406862	 -0.406893	diff=3.06572e-05
  0.240940	  0.240821	diff=0.000119271
 -1.424838	 -1.429208	diff=0.0043695
  2.618666	  2.617254	diff=0.00141252
  0.105468	  0.099156	diff=0.00631253
 -1.280499	 -1.287202	diff=0.00670337
  local_diff=0.0190718
# Num params=104, abs_diff=1.87614
Elapsed time is 0.709005 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s> x y y
  src mask: 0  1  1  1
  tgt input 1: <s> b b </s> </s>
  tgt output 1: b b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=2.15445e-24
 -0.000000	  0.000000	diff=7.14491e-13
  0.000000	  0.000000	diff=1.7299e-28
  0.000000	  0.000000	diff=1.69429e-23
  0.000000	  0.000000	diff=3.77489e-25
 -0.000000	  0.000000	diff=7.14484e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=2.75108e-24
  0.000000	 -0.000000	diff=1.71075e-14
  0.000000	 -0.000000	diff=2.19901e-28
  0.000000	 -0.000000	diff=7.34087e-23
  0.000000	 -0.000000	diff=1.63511e-24
  0.000000	 -0.000000	diff=1.70785e-14
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=7.59486e-54
  0.000000	 -0.000000	diff=1.36095e-41
  0.000000	 -0.000000	diff=1.24309e-59
  0.000000	 -0.000000	diff=6.76941e-54
  0.000000	 -0.000000	diff=1.39484e-51
  0.000000	 -0.000000	diff=1.35864e-41
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.47202e-42
  0.000000	  0.000000	diff=5.71942e-31
  0.000000	  0.000000	diff=1.16737e-47
  0.000000	  0.000000	diff=3.03682e-44
  0.000000	  0.000000	diff=4.74941e-41
  0.000000	  0.000000	diff=5.70972e-31
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.46316e-12
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=4.53762e-42
  0.000000	 -0.000000	diff=2.14155e-41
  0.000000	 -0.000000	diff=8.9099e-43
  0.000000	 -0.000000	diff=5.20718e-42
  0.000000	  0.000000	diff=4.77974e-42
  0.000000	 -0.000000	diff=2.66897e-41
  0.000000	 -0.000000	diff=1.81382e-26
  0.000000	 -0.000000	diff=6.06482e-26
  0.000000	 -0.000000	diff=1.05573e-31
  0.000000	  0.000000	diff=9.68972e-31
  0.000000	  0.000000	diff=7.73067e-33
  0.000000	  0.000000	diff=3.14478e-31
  0.000000	 -0.000000	diff=1.29258e-31
  0.000000	  0.000000	diff=1.32984e-30
  0.000000	  0.000000	diff=1.20203e-15
  0.000000	  0.000000	diff=1.88219e-15
  0.000000	  0.000000	diff=1.03886e-33
  0.000000	 -0.000000	diff=6.18645e-32
  0.000000	 -0.000000	diff=1.43998e-33
  0.000000	 -0.000000	diff=1.91375e-32
  0.000000	  0.000000	diff=2.32774e-33
  0.000000	 -0.000000	diff=5.9028e-32
  0.000000	  0.000000	diff=2.42931e-16
  0.000000	 -0.000000	diff=5.10375e-17
  0.000000	 -0.000000	diff=1.36325e-32
  0.000000	  0.000000	diff=1.66374e-30
  0.000000	 -0.000000	diff=4.04483e-33
  0.000000	  0.000000	diff=6.04443e-31
  0.000000	 -0.000000	diff=1.73299e-32
  0.000000	  0.000000	diff=2.94736e-30
  0.000000	  0.000000	diff=3.58103e-16
  0.000000	  0.000000	diff=2.20533e-15
  local_diff=5.94161e-15
# W_tgt{1}, [8 6]
 -0.000001	 -0.000001	diff=1.88913e-09
  0.000000	  0.000000	diff=3.15788e-18
 -0.000000	 -0.000000	diff=2.53582e-11
  0.000000	  0.000000	diff=1.01535e-25
 -0.000001	 -0.000001	diff=5.03243e-08
  0.000000	  0.000000	diff=9.90328e-12
  0.000000	 -0.000000	diff=1.00033e-43
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=8.50309e-10
  0.000000	 -0.000000	diff=5.35104e-18
 -0.000000	 -0.000000	diff=1.05437e-11
  0.000000	  0.000000	diff=6.51967e-26
 -0.000001	 -0.000001	diff=2.05349e-08
  0.000000	  0.000000	diff=3.66505e-12
  0.000000	  0.000000	diff=1.69504e-43
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=1.15066e-15
  0.000000	 -0.000000	diff=8.37396e-37
  0.000000	 -0.000000	diff=3.42575e-18
  0.000000	  0.000000	diff=2.42584e-34
  0.000000	 -0.000000	diff=2.01804e-15
  0.000000	  0.000000	diff=5.14885e-19
  0.000000	 -0.000000	diff=9.01108e-75
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.73834e-16
  0.000000	 -0.000000	diff=5.54152e-37
  0.000000	  0.000000	diff=5.17539e-19
  0.000000	 -0.000000	diff=3.66478e-35
  0.000000	  0.000000	diff=3.04872e-16
  0.000000	 -0.000000	diff=7.7785e-20
  0.000000	  0.000000	diff=4.38452e-75
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.21901e-15
  0.000000	 -0.000000	diff=5.65528e-39
  0.000000	  0.000000	diff=3.62924e-18
  0.000000	 -0.000000	diff=2.56993e-34
  0.000000	  0.000000	diff=2.13791e-15
  0.000000	 -0.000000	diff=5.45468e-19
  0.000000	  0.000000	diff=2.57998e-74
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=3.67957e-20
  0.000000	 -0.000000	diff=2.2675e-35
  0.000000	  0.000000	diff=1.09958e-22
  0.000000	 -0.000000	diff=7.81482e-39
  0.000000	  0.000000	diff=6.45327e-20
  0.000000	 -0.000000	diff=1.65384e-23
  0.000000	  0.000000	diff=2.90062e-67
  0.000000	  0.000000	diff=0
  local_diff=7.36481e-08
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=1.14953e-15
  0.000000	  0.000000	diff=2.43245e-15
  0.000000	  0.000000	diff=2.30865e-16
  0.000000	  0.000000	diff=3.0348e-16
  0.000000	  0.000000	diff=6.88977e-16
  0.000000	  0.000000	diff=1.82705e-15
  0.000000	  0.000000	diff=1.8177e-13
 -0.000000	 -0.000000	diff=6.47252e-13
  0.000000	  0.000000	diff=3.82377e-20
  0.000000	  0.000000	diff=7.59735e-20
  0.000000	  0.000000	diff=7.20752e-21
  0.000000	  0.000000	diff=9.47454e-21
  0.000000	  0.000000	diff=2.40474e-20
  0.000000	  0.000000	diff=5.73201e-20
  0.000000	  0.000000	diff=8.13338e-14
 -0.000000	 -0.000000	diff=1.0627e-12
  0.000000	  0.000000	diff=1.90747e-15
  0.000000	 -0.000000	diff=2.9684e-15
  0.000000	 -0.000000	diff=6.52651e-16
  0.000000	 -0.000000	diff=8.57925e-16
  0.000000	  0.000000	diff=1.25482e-15
  0.000000	 -0.000000	diff=3.82632e-15
 -0.000000	 -0.000000	diff=4.43623e-13
  0.000000	  0.000000	diff=3.79858e-13
  0.000000	 -0.000000	diff=2.88163e-16
  0.000000	  0.000000	diff=4.48441e-16
  0.000000	  0.000000	diff=9.85969e-17
  0.000000	  0.000000	diff=1.29608e-16
  0.000000	 -0.000000	diff=1.89566e-16
  0.000000	  0.000000	diff=5.78049e-16
  0.000000	  0.000000	diff=1.37163e-13
 -0.000000	 -0.000000	diff=1.49624e-13
  local_diff=3.10316e-12
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=3.37314e-16
 -0.000000	  0.000000	diff=7.48364e-13
  0.000000	 -0.000000	diff=2.52839e-20
  0.000000	 -0.000000	diff=2.88587e-20
  local_diff=7.48701e-13
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=4.02888e-13
 -0.000000	 -0.000000	diff=1.3518e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=7.89532e-19
  0.000000	 -0.000000	diff=4.08172e-19
  0.000001	  0.000001	diff=4.94941e-08
 -0.000002	 -0.000001	diff=7.63413e-08
  local_diff=1.25836e-07
# W_soft, [4 2]
  0.000000	  0.000000	diff=1.63336e-13
 -0.000000	 -0.000000	diff=5.70279e-13
 -0.000000	 -0.000000	diff=1.78709e-13
  0.000000	  0.000000	diff=2.0178e-13
 -0.000000	 -0.000000	diff=6.28554e-13
  0.000000	  0.000000	diff=4.0722e-13
 -0.000000	 -0.000000	diff=1.98809e-13
 -0.000000	 -0.000000	diff=2.25247e-14
  local_diff=2.37121e-12
# Num params=168, abs_diff=1.99492e-07
Elapsed time is 1.373524 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s> x y y
  src mask: 0  1  1  1
  tgt input 1: <s> b b </s> </s>
  tgt output 1: b b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=4.94782e-29
  0.000000	  0.000000	diff=2.62773e-17
  0.000000	  0.000000	diff=1.20299e-32
  0.000000	  0.000000	diff=3.98999e-27
  0.000000	  0.000000	diff=1.34912e-09
  0.000000	  0.000000	diff=6.48803e-20
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=1.1804e-37
  0.000000	 -0.000000	diff=6.3016e-29
  0.000000	 -0.000000	diff=3.36015e-17
  0.000000	 -0.000000	diff=1.5292e-32
  0.000000	 -0.000000	diff=5.15717e-27
  0.000000	 -0.000000	diff=6.21514e-31
  0.000000	 -0.000000	diff=2.81112e-19
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=1.69906e-66
  0.000000	 -0.000000	diff=4.38391e-52
  0.000000	 -0.000000	diff=1.96685e-71
  0.000000	 -0.000000	diff=6.34695e-66
  0.000000	 -0.000000	diff=1.04107e-64
  0.000000	 -0.000000	diff=4.38199e-52
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.5472e-50
  0.000000	  0.000000	diff=4.94712e-39
  0.000000	  0.000000	diff=1.08246e-56
  0.000000	  0.000000	diff=1.26422e-55
  0.000000	  0.000000	diff=1.52539e-51
  0.000000	  0.000000	diff=4.94541e-39
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.34912e-09
# W_src{2}, [8 4]
  0.000038	  0.000038	diff=1.80882e-07
  0.000415	  0.000413	diff=1.98257e-06
  0.000000	 -0.000000	diff=3.63844e-53
  0.000000	 -0.000000	diff=2.06029e-52
  0.005013	  0.005034	diff=2.04479e-05
 -0.017474	 -0.017408	diff=6.5837e-05
 -0.000000	 -0.000000	diff=4.08246e-12
  0.000000	  0.000000	diff=1.79006e-09
  0.000000	 -0.000000	diff=4.61099e-39
  0.000000	  0.000000	diff=6.91356e-39
  0.000000	  0.000000	diff=7.42599e-40
  0.000000	  0.000000	diff=2.34178e-39
  0.000000	 -0.000000	diff=5.13193e-39
  0.000000	  0.000000	diff=9.82144e-39
  0.000000	  0.000000	diff=2.00637e-19
  0.000000	  0.000000	diff=9.34894e-20
  0.000000	  0.000000	diff=3.3088e-40
  0.000000	  0.000000	diff=5.28168e-40
  0.000000	 -0.000000	diff=1.76609e-40
  0.000000	  0.000000	diff=2.94944e-40
  0.000000	  0.000000	diff=2.38521e-40
  0.000000	  0.000000	diff=2.33133e-39
  0.000000	  0.000000	diff=7.04271e-20
  0.000000	  0.000000	diff=1.01853e-20
  0.000000	 -0.000000	diff=3.98453e-39
  0.000000	  0.000000	diff=1.07568e-38
  0.000000	  0.000000	diff=1.04197e-39
  0.000000	  0.000000	diff=3.68464e-39
  0.000000	 -0.000000	diff=3.69414e-39
  0.000000	  0.000000	diff=1.8885e-38
  0.000000	 -0.000000	diff=1.2146e-20
  0.000000	  0.000000	diff=1.30199e-19
  local_diff=8.84501e-05
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=3.45527e-10
  0.000000	 -0.000000	diff=3.73798e-21
  0.000000	 -0.000000	diff=3.66215e-24
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=2.0097e-09
 -0.000000	 -0.000000	diff=2.30805e-10
  0.000000	  0.000000	diff=8.73997e-64
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=1.45361e-10
  0.000000	  0.000000	diff=6.16526e-15
  0.000000	  0.000000	diff=1.87866e-24
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=8.17618e-10
  0.000000	  0.000000	diff=7.06152e-13
  0.000000	 -0.000000	diff=1.48098e-63
  0.000000	 -0.000000	diff=4.25443e-14
  0.000000	 -0.000000	diff=3.49673e-27
  0.000000	  0.000000	diff=1.70264e-32
  0.000000	 -0.000000	diff=1.22029e-43
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=5.76264e-27
  0.000000	 -0.000000	diff=2.62114e-23
  0.000000	 -0.000000	diff=1.57043e-93
  0.000000	 -0.000000	diff=2.64791e-34
  0.000000	  0.000000	diff=2.568e-13
  0.000000	  0.000000	diff=1.43274e-31
  0.000000	 -0.000000	diff=9.47536e-27
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=7.86381e-14
  0.000000	 -0.000000	diff=1.8717e-23
  0.000000	  0.000000	diff=9.11343e-77
  0.000000	 -0.000000	diff=2.22816e-33
  0.000000	 -0.000000	diff=7.71721e-56
  0.000000	 -0.000000	diff=1.3346e-41
  0.000000	  0.000000	diff=1.2448e-25
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=1.44065e-40
  0.000000	 -0.000000	diff=2.45677e-34
  0.000000	 -0.000000	diff=1.28386e-71
  0.000000	 -0.000000	diff=1.01822e-52
  0.000000	  0.000000	diff=1.07974e-34
  0.000000	 -0.000000	diff=4.40654e-32
  0.000000	  0.000000	diff=3.16473e-43
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.60383e-34
  0.000000	  0.000000	diff=2.17694e-23
  0.000000	  0.000000	diff=2.46413e-84
  0.000000	  0.000000	diff=6.85295e-34
  local_diff=3.5501e-09
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=3.62451e-13
 -0.000000	 -0.000000	diff=1.3623e-13
 -0.000000	 -0.000000	diff=5.02925e-13
  0.000000	  0.000000	diff=5.4452e-14
  0.000000	  0.000000	diff=3.39417e-13
  0.000000	  0.000000	diff=2.12804e-14
  0.000000	  0.000000	diff=3.71072e-13
 -0.000000	 -0.000000	diff=5.09008e-13
  0.000000	 -0.000000	diff=6.03028e-20
  0.000000	  0.000000	diff=3.21492e-19
  0.000000	  0.000000	diff=2.83234e-24
  0.000000	  0.000000	diff=6.51055e-24
  0.000000	 -0.000000	diff=6.81393e-20
  0.000000	 -0.000000	diff=6.34477e-20
 -0.000000	 -0.000000	diff=3.17136e-13
  0.000000	  0.000000	diff=1.10669e-13
  0.021660	  0.021644	diff=1.62213e-05
 -0.010074	 -0.010082	diff=8.10324e-06
 -0.004782	 -0.004781	diff=9.56961e-07
  0.002654	  0.002654	diff=1.45711e-07
  0.035377	  0.035371	diff=5.56391e-06
 -0.003264	 -0.003268	diff=3.61935e-06
  0.015890	  0.015869	diff=2.0875e-05
  0.257396	  0.256733	diff=0.000663085
 -0.009115	 -0.009121	diff=5.81019e-06
  0.006978	  0.006988	diff=9.83407e-06
 -0.001094	 -0.001094	diff=4.8922e-07
 -0.041693	 -0.041925	diff=0.000231937
 -0.003097	 -0.003101	diff=4.02777e-06
  0.003241	  0.003238	diff=2.98127e-06
  0.032197	  0.032157	diff=3.96739e-05
 -0.488926	 -0.493737	diff=0.00481123
  local_diff=0.00582455
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=4.79244e-21
  0.000000	  0.000000	diff=6.21663e-19
  0.000000	  0.000000	diff=3.97312e-10
  0.000000	  0.000000	diff=4.98006e-17
  local_diff=3.97312e-10
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=3.56072e-10
  0.000000	 -0.000000	diff=4.47895e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.40444e-13
  0.000000	  0.000000	diff=6.05501e-16
  0.000000	  0.000000	diff=2.16515e-09
 -0.000000	 -0.000000	diff=3.52464e-09
  local_diff=6.04645e-09
# W_soft, [4 2]
  0.003314	  0.003257	diff=5.74002e-05
  0.063391	  0.063336	diff=5.48146e-05
 -0.169196	 -0.169247	diff=5.09466e-05
  0.102698	  0.102653	diff=4.43992e-05
 -0.035975	 -0.036002	diff=2.75974e-05
  0.098266	  0.098237	diff=2.84965e-05
 -0.088545	 -0.088565	diff=2.06253e-05
  0.026354	  0.026330	diff=2.37666e-05
  local_diff=0.000308046
# Num params=168, abs_diff=0.00622106
Elapsed time is 1.539143 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 176, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 176
  src input 1: <s> y x x
  src mask: 0  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.001254	  0.001261	diff=7.38686e-06
  0.000000	  0.000000	diff=5.78469e-17
  0.000000	 -0.000000	diff=1.01121e-31
  0.000000	 -0.000000	diff=1.92733e-29
  0.158212	  0.159173	diff=0.000960895
  0.000000	  0.000000	diff=4.33861e-16
 -0.000250	 -0.000248	diff=2.93254e-06
  0.000000	  0.000000	diff=1.29485e-16
  0.000000	  0.000000	diff=5.19006e-25
  0.000000	 -0.000000	diff=8.36502e-17
  0.000000	  0.000000	diff=1.28543e-31
  0.000000	  0.000000	diff=8.35137e-29
  0.000000	  0.000000	diff=1.40357e-31
  0.000000	 -0.000000	diff=1.43504e-17
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.922e-61
  0.000000	 -0.000000	diff=2.62173e-53
  0.000000	  0.000000	diff=4.25152e-68
  0.000000	  0.000000	diff=1.54448e-67
  0.000000	 -0.000000	diff=1.74991e-69
  0.000000	 -0.000000	diff=3.29746e-54
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=9.83931e-46
  0.000000	  0.000000	diff=1.25062e-37
  0.000000	 -0.000000	diff=2.17623e-52
  0.000000	  0.000000	diff=4.85363e-54
  0.000000	 -0.000000	diff=4.24796e-55
  0.000000	  0.000000	diff=7.7452e-39
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.000971214
# W_src{2}, [8 4]
  0.003224	  0.003209	diff=1.46474e-05
 -0.004942	 -0.004918	diff=2.40502e-05
  0.000000	  0.000000	diff=1.0774e-53
  0.000000	  0.000000	diff=7.32354e-53
  0.261445	  0.262567	diff=0.001122
 -0.867284	 -0.864109	diff=0.00317517
 -0.000000	 -0.000000	diff=4.56003e-10
 -0.000002	 -0.000001	diff=1.52883e-08
  0.000000	  0.000000	diff=3.06686e-38
  0.000000	  0.000000	diff=5.73859e-38
  0.000000	 -0.000000	diff=6.36319e-39
  0.000000	  0.000000	diff=1.99628e-38
  0.000000	  0.000000	diff=3.31609e-38
  0.000000	  0.000000	diff=1.01018e-37
  0.000000	 -0.000000	diff=6.2176e-19
  0.000000	  0.000000	diff=7.32183e-19
  0.000000	 -0.000000	diff=3.68688e-39
  0.000000	 -0.000000	diff=1.20675e-38
  0.000000	  0.000000	diff=1.70066e-39
  0.000000	 -0.000000	diff=5.34929e-39
  0.000000	 -0.000000	diff=2.24077e-39
  0.000000	 -0.000000	diff=2.9601e-38
  0.000000	 -0.000000	diff=4.85458e-19
  0.000000	 -0.000000	diff=1.23966e-19
  0.000000	  0.000000	diff=3.59461e-38
  0.000000	  0.000000	diff=9.68826e-38
  0.000000	 -0.000000	diff=1.12433e-38
  0.000000	  0.000000	diff=3.39502e-38
  0.000000	  0.000000	diff=3.17958e-38
  0.000000	  0.000000	diff=2.06821e-37
  0.000000	  0.000000	diff=3.58141e-19
  0.000000	  0.000000	diff=5.10657e-19
  local_diff=0.00433588
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=3.53885e-11
  0.000000	 -0.000000	diff=4.20559e-22
  0.000000	  0.000000	diff=1.41973e-12
  0.000000	 -0.000000	diff=1.49227e-93
 -0.000000	 -0.000000	diff=4.01058e-10
  0.000000	  0.000000	diff=6.95415e-13
  0.000000	 -0.000000	diff=1.36148e-55
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=1.39873e-11
  0.016850	  0.017432	diff=0.000581548
 -0.000005	 -0.000005	diff=1.63489e-07
  0.000000	  0.000000	diff=6.27819e-18
 -0.000000	 -0.000000	diff=1.62473e-10
  0.000044	  0.000046	diff=1.5444e-06
  0.000000	  0.000000	diff=2.30701e-55
  3.273790	  3.530125	diff=0.256335
  0.000000	  0.000000	diff=2.36915e-13
 -0.002587	 -0.002574	diff=1.34491e-05
  0.000001	  0.000001	diff=3.91346e-09
  0.000000	 -0.000000	diff=9.58608e-19
  0.000000	  0.000000	diff=1.99412e-12
 -0.000007	 -0.000007	diff=3.46416e-08
  0.000000	 -0.000000	diff=8.35723e-94
 -0.000002	 -0.000002	diff=1.77143e-08
 -0.000000	 -0.000000	diff=9.90894e-13
 -0.002502	 -0.002489	diff=1.25791e-05
  0.000001	  0.000001	diff=3.66089e-09
  0.000000	 -0.000000	diff=9.27136e-19
 -0.000000	 -0.000000	diff=1.83621e-12
 -0.000006	 -0.000006	diff=3.24012e-08
  0.000000	  0.000000	diff=6.03763e-93
 -0.000002	 -0.000002	diff=1.65672e-08
  0.000000	 -0.000000	diff=1.00656e-19
 -0.001870	 -0.001862	diff=7.0359e-06
  0.000001	  0.000001	diff=2.04874e-09
  0.000000	 -0.000000	diff=6.93683e-19
 -0.000000	 -0.000000	diff=6.23814e-13
 -0.000005	 -0.000005	diff=1.81221e-08
  0.000000	  0.000000	diff=8.92759e-64
 -0.000001	 -0.000001	diff=9.25791e-09
  0.000000	 -0.000000	diff=1.85065e-25
  0.001802	  0.001809	diff=6.60194e-06
 -0.000001	 -0.000001	diff=1.9209e-09
  0.000000	  0.000000	diff=6.73598e-19
  0.000000	  0.000000	diff=2.46331e-16
  0.000005	  0.000005	diff=1.70028e-08
  0.000000	  0.000000	diff=5.46376e-84
  0.000001	  0.000001	diff=8.64204e-09
  local_diff=0.256958
# W_tgt{2}, [8 4]
  0.000482	  0.000487	diff=4.30135e-06
 -0.129208	 -0.128560	diff=0.000648313
  0.000000	  0.000000	diff=3.91993e-10
 -0.000203	 -0.000202	diff=1.22106e-06
 -0.000000	 -0.000000	diff=1.16504e-11
 -2.188387	 -2.180283	diff=0.00810429
 -0.000023	 -0.000022	diff=2.11442e-07
  0.000000	  0.000000	diff=4.03045e-09
 -0.000167	 -0.000166	diff=8.42192e-07
  0.121537	  0.122118	diff=0.000580739
 -0.000000	 -0.000000	diff=2.42734e-10
  0.000159	  0.000159	diff=7.54623e-07
  0.000000	  0.000000	diff=1.32217e-10
  2.025519	  2.033286	diff=0.00776719
  0.000022	  0.000022	diff=1.97718e-07
 -0.000000	 -0.000000	diff=3.78767e-09
 -0.117148	 -0.117065	diff=8.30687e-05
  0.175358	  0.175497	diff=0.000139066
  0.021245	  0.021241	diff=3.75291e-06
 -0.045413	 -0.045421	diff=7.9792e-06
 -0.249366	 -0.249207	diff=0.000159306
  0.080066	  0.080127	diff=6.063e-05
 -0.128219	 -0.128009	diff=0.000209255
 -1.835474	 -1.821901	diff=0.0135728
 -0.157398	 -0.156765	diff=0.000633399
  0.202520	  0.202529	diff=9.16323e-06
 -0.031462	 -0.031317	diff=0.00014483
  0.138145	  0.138453	diff=0.000308902
 -0.002893	 -0.002866	diff=2.68371e-05
  0.053886	  0.053856	diff=3.00519e-05
 -0.130706	 -0.130483	diff=0.000223197
 -0.496780	 -0.565991	diff=0.0692114
  local_diff=0.101932
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.449810	  0.457780	diff=0.00796968
  0.000000	  0.000000	diff=3.17353e-17
  0.000000	  0.000000	diff=5.2171e-09
  0.000000	  0.000000	diff=1.03568e-16
  local_diff=0.00796968
# W_emb_tgt, [2 4]
 -0.000000	 -0.000000	diff=2.77889e-12
 -0.000000	 -0.000000	diff=1.12537e-12
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=1.82379e-23
  0.000000	 -0.000000	diff=1.44066e-12
  0.000000	  0.000000	diff=3.63588e-10
  0.174029	  0.174701	diff=0.000671944
  local_diff=0.000671945
# W_h, [2 4]
  0.007191	  0.007190	diff=4.53093e-07
  0.206067	  0.206068	diff=1.19647e-06
 -0.265919	 -0.266410	diff=0.000490461
 -7.793612	 -7.791739	diff=0.00187306
  1.911988	  1.911840	diff=0.000147331
 -2.593384	 -2.588799	diff=0.00458552
 -0.072544	 -0.073119	diff=0.000574981
  0.789250	  0.790091	diff=0.000841381
  local_diff=0.00851439
# W_soft, [4 2]
 -2.733187	 -2.735182	diff=0.0019956
  1.227116	  1.227054	diff=6.2027e-05
  1.540589	  1.540443	diff=0.000145849
 -0.030451	 -0.032314	diff=0.00186362
 -5.238513	 -5.241345	diff=0.00283206
  2.035890	  2.035819	diff=7.1456e-05
  3.086743	  3.086652	diff=9.0678e-05
  0.121598	  0.118874	diff=0.00272319
  local_diff=0.00978448
# Num params=176, abs_diff=0.391137
Elapsed time is 2.021188 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 4, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_pos=4 v_pos=2 W_h=8 W_soft=8
# assert = 0
# attnFunc = 4
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# distSigma = 0.5
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000020	  0.000020	diff=1.19702e-07
  0.000158	 -0.000005	diff=0.00016318
 -0.000000	 -0.000000	diff=3.79136e-10
  0.000006	  0.000006	diff=3.00514e-08
 -0.019692	 -0.019538	diff=0.000154198
 -0.000104	 -0.000103	diff=7.06928e-07
 -0.000005	 -0.000005	diff=6.23523e-08
  0.000053	  0.000053	diff=5.21627e-07
  0.000000	  0.000000	diff=5.1051e-09
 -0.000194	 -0.000000	diff=0.000193484
  0.000000	  0.000000	diff=1.4879e-33
  0.000000	 -0.000000	diff=1.14551e-25
  0.000000	 -0.000000	diff=5.91303e-30
  0.000000	 -0.000000	diff=1.80097e-17
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000005	  0.000005	diff=1.77024e-08
  0.000003	  0.000003	diff=9.95974e-09
  0.000000	  0.000000	diff=1.75556e-10
 -0.000003	 -0.000003	diff=1.16707e-08
  0.014496	  0.014553	diff=5.7821e-05
  0.000049	  0.000049	diff=1.73519e-07
 -0.000000	 -0.000000	diff=2.80262e-13
 -0.000000	 -0.000000	diff=3.79726e-10
 -0.000000	 -0.000000	diff=1.31348e-12
  0.000000	  0.000000	diff=1.83824e-13
 -0.000000	 -0.000000	diff=2.43885e-13
  0.000000	  0.000000	diff=2.91847e-13
 -0.000028	 -0.000028	diff=3.71991e-09
  0.000001	  0.000001	diff=4.99505e-11
  0.000000	  0.000000	diff=4.66506e-13
 -0.000000	 -0.000000	diff=3.07049e-13
  local_diff=0.000570346
# W_src{2}, [8 4]
 -0.000588	 -0.000585	diff=2.5476e-06
  0.000125	  0.000124	diff=4.85875e-07
 -0.000023	 -0.000023	diff=7.97532e-08
 -0.000000	 -0.000000	diff=9.0729e-10
 -0.023150	 -0.023019	diff=0.00013055
 -0.011376	 -0.011347	diff=2.97192e-05
  0.000782	  0.000789	diff=6.62581e-06
 -0.000000	 -0.000000	diff=7.15729e-11
  0.000000	 -0.000000	diff=1.80015e-38
  0.000000	  0.000000	diff=1.054e-37
  0.000000	  0.000000	diff=7.52237e-39
  0.000000	  0.000000	diff=4.32932e-38
  0.000000	 -0.000000	diff=1.16579e-38
  0.000000	  0.000000	diff=1.68256e-37
  0.000000	 -0.000000	diff=9.09115e-19
  0.000000	  0.000000	diff=6.2568e-19
 -0.000317	 -0.000316	diff=1.11321e-06
  0.000267	  0.000266	diff=9.09454e-07
 -0.000001	 -0.000001	diff=1.85421e-09
  0.000001	  0.000001	diff=2.90036e-09
 -0.000668	 -0.000667	diff=6.24788e-07
 -0.000226	 -0.000226	diff=3.62964e-08
  0.000726	  0.000732	diff=5.71225e-06
  0.000000	  0.000000	diff=1.58999e-11
  0.000089	  0.000089	diff=8.98581e-08
  0.000092	  0.000093	diff=5.47743e-07
  0.000024	  0.000024	diff=8.78324e-08
  0.000001	  0.000001	diff=4.91936e-09
  0.026478	  0.026652	diff=0.00017376
  0.008571	  0.008574	diff=3.07465e-06
 -0.000205	 -0.000204	diff=4.4998e-07
 -0.000000	 -0.000000	diff=1.0598e-12
  local_diff=0.000356425
# W_tgt{1}, [8 6]
 -0.000001	 -0.000001	diff=4.19801e-09
  0.000000	 -0.000000	diff=5.93927e-20
  0.000000	  0.000000	diff=3.33753e-12
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=5.0626e-08
 -0.000000	 -0.000000	diff=7.51526e-13
  0.000000	  0.000000	diff=5.90485e-53
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=1.82159e-09
  0.000000	  0.000000	diff=1.2389e-12
  0.000000	  0.000000	diff=1.68655e-12
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=2.06042e-08
  0.000000	  0.000000	diff=1.6857e-12
  0.000000	 -0.000000	diff=1.00057e-52
 -0.000000	 -0.000000	diff=4.0213e-13
  0.000000	  0.000000	diff=6.94016e-12
  0.000000	  0.000000	diff=3.58775e-13
 -0.000000	 -0.000000	diff=2.42289e-13
  0.000000	  0.000000	diff=6.20853e-14
 -0.000000	 -0.000000	diff=1.43713e-11
  0.000000	  0.000000	diff=1.08379e-14
 -0.000000	 -0.000001	diff=4.99793e-07
  0.000003	  0.000002	diff=1.07353e-06
  0.000000	  0.000000	diff=7.01618e-12
 -0.000000	 -0.000000	diff=2.58601e-13
 -0.000000	 -0.000000	diff=1.05059e-12
 -0.000000	 -0.000000	diff=3.99415e-13
 -0.000000	 -0.000000	diff=1.39014e-11
 -0.000000	 -0.000000	diff=2.61914e-13
  0.000003	  0.000005	diff=1.97835e-06
 -0.000013	 -0.000009	diff=4.20626e-06
 -0.000027	 -0.000027	diff=6.56326e-08
  0.000000	  0.000000	diff=5.73235e-13
 -0.000031	 -0.000031	diff=9.11821e-08
  0.000000	  0.000000	diff=1.02302e-12
 -0.000012	 -0.000012	diff=3.45513e-08
 -0.000000	 -0.000000	diff=5.12906e-13
 -0.000000	 -0.000000	diff=4.22781e-11
  0.000000	  0.000000	diff=6.80762e-12
 -0.000001	 -0.000001	diff=1.01452e-10
  0.000000	  0.000000	diff=1.20733e-13
 -0.000001	 -0.000001	diff=1.46778e-10
  0.000000	  0.000000	diff=8.33417e-14
 -0.000000	 -0.000000	diff=6.25166e-11
  0.000000	  0.000000	diff=2.63575e-13
 -0.000000	 -0.000000	diff=6.84447e-08
  0.000000	  0.000000	diff=1.46928e-07
  local_diff=8.24234e-06
# W_tgt{2}, [8 4]
  0.001410	  0.001412	diff=1.464e-06
 -0.000000	 -0.000000	diff=2.93398e-10
 -0.000000	 -0.000000	diff=8.25959e-10
  0.000002	  0.000002	diff=9.62961e-10
 -0.000062	 -0.000061	diff=2.88258e-07
  0.000004	  0.000004	diff=1.78148e-08
  0.000001	  0.000002	diff=2.03498e-07
 -0.000003	 -0.000003	diff=4.4258e-08
 -0.000000	 -0.000000	diff=2.96047e-13
  0.000000	  0.000000	diff=6.09366e-13
 -0.000000	 -0.000000	diff=3.24934e-13
  0.000000	  0.000000	diff=8.44173e-14
 -0.000000	 -0.000000	diff=8.03062e-14
  0.000000	  0.000000	diff=5.43826e-13
  0.000000	  0.000005	diff=4.31779e-06
 -0.000013	 -0.000010	diff=2.86293e-06
  0.001093	  0.001093	diff=5.90998e-07
 -0.000000	 -0.000000	diff=1.58349e-10
 -0.000000	 -0.000000	diff=4.53642e-10
  0.000001	  0.000001	diff=5.24e-10
 -0.000052	 -0.000051	diff=2.05837e-07
  0.000003	  0.000003	diff=9.64209e-09
 -0.000000	 -0.000000	diff=3.65474e-09
  0.000000	  0.000000	diff=5.19358e-10
 -0.000300	 -0.000300	diff=7.34139e-08
  0.000000	  0.000000	diff=1.68296e-11
  0.000000	  0.000000	diff=4.80336e-11
 -0.000000	 -0.000000	diff=5.85121e-11
  0.000009	  0.000009	diff=1.02734e-08
 -0.000001	 -0.000001	diff=1.06621e-09
 -0.000000	 -0.000000	diff=3.09226e-08
  0.000000	  0.000000	diff=6.99742e-09
  local_diff=1.01352e-05
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.055225	 -0.053908	diff=0.00131691
  0.000000	  0.000000	diff=3.14847e-17
  0.000276	  0.000000	diff=0.000276148
  0.000319	  0.000000	diff=0.000318753
  local_diff=0.00191182
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=8.73261e-16
 -0.000000	 -0.000000	diff=6.5708e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.21566e-20
  0.000000	 -0.000000	diff=9.68362e-16
  0.000001	  0.000001	diff=5.11986e-08
 -0.000001	 -0.000001	diff=8.12709e-08
  local_diff=1.3247e-07
# W_pos, [2 2]
  0.013483	  0.013517	diff=3.4179e-05
  0.005323	  0.005291	diff=3.21478e-05
 -0.000000	 -0.000000	diff=8.69149e-14
 -0.000000	 -0.000000	diff=3.00446e-13
  local_diff=6.63268e-05
# v_pos, [1 2]
 -0.022079	 -0.021905	diff=0.000174608
 -0.076306	 -0.074289	diff=0.00201677
  local_diff=0.00219138
# W_h, [2 4]
 -0.000001	 -0.000001	diff=2.4264e-09
  0.018819	  0.018878	diff=5.95072e-05
  0.000000	  0.000000	diff=5.93914e-10
 -0.009100	 -0.009086	diff=1.38216e-05
 -0.000003	 -0.000004	diff=7.33727e-07
  0.055878	  0.056410	diff=0.000531996
 -0.000002	 -0.000007	diff=5.38299e-06
  0.000011	  0.000006	diff=4.7819e-06
  local_diff=0.000616227
# W_soft, [4 2]
 -0.009536	 -0.009583	diff=4.76194e-05
 -0.007614	 -0.010962	diff=0.00334772
  0.991862	  0.991821	diff=4.06572e-05
 -0.967893	 -0.971276	diff=0.00338334
 -0.009489	 -0.009536	diff=4.69765e-05
 -0.009284	 -0.012587	diff=0.00330246
  0.986164	  0.986124	diff=4.01076e-05
 -0.960663	 -0.964000	diff=0.00333755
  local_diff=0.0135464
# Num params=182, abs_diff=0.0192775
Elapsed time is 2.928397 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 180, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 180
  src input 1: <s> <s> x y
  src mask: 0  0  1  1
  tgt input 1: <s> a </s> </s> </s>
  tgt output 1: a </s> </s> </s> </s>
  tgt mask: 1  1  0  0  0
# W_src{1}, [8 4]
 -0.000010	 -0.000010	diff=5.80667e-08
  0.000000	  0.000000	diff=1.34186e-15
  0.000000	  0.000000	diff=1.18329e-22
  0.000000	  0.000000	diff=1.52873e-33
 -0.001243	 -0.001250	diff=7.4602e-06
  0.000000	  0.000000	diff=5.92526e-14
  0.000002	  0.000002	diff=2.30536e-08
  0.000000	  0.000000	diff=1.74694e-13
  0.000000	  0.000000	diff=2.32677e-30
  0.000000	  0.000000	diff=2.20413e-17
  0.000000	  0.000000	diff=5.53782e-34
  0.000000	 -0.000000	diff=1.82225e-33
  0.000000	  0.000000	diff=7.53374e-33
  0.000000	  0.000000	diff=2.06121e-17
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.14396e-67
  0.000000	  0.000000	diff=1.6979e-54
  0.000000	 -0.000000	diff=1.41002e-23
  0.000000	  0.000000	diff=4.08255e-71
 -0.000000	 -0.000000	diff=3.93273e-10
  0.000000	 -0.000000	diff=1.41025e-28
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=3.56817e-28
  0.000000	 -0.000000	diff=2.03989e-51
  0.000000	 -0.000000	diff=1.73023e-38
  0.000000	  0.000000	diff=9.98634e-28
  0.000000	 -0.000000	diff=4.42823e-55
  0.000000	  0.000000	diff=4.94294e-13
  0.000000	  0.000000	diff=1.00228e-32
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.53593e-32
  local_diff=7.54171e-06
# W_src{2}, [8 4]
 -0.000067	 -0.000066	diff=3.00941e-07
  0.000566	  0.000564	diff=2.45139e-06
 -0.000000	 -0.000000	diff=3.82788e-10
  0.000003	  0.000003	diff=1.59276e-08
 -0.006707	 -0.006721	diff=1.32144e-05
 -0.046658	 -0.046516	diff=0.000142552
  0.000000	  0.000000	diff=5.88197e-10
  0.000000	  0.000000	diff=1.84115e-11
  0.000000	  0.000000	diff=9.57032e-39
  0.000000	 -0.000000	diff=4.70762e-38
  0.000000	 -0.000000	diff=1.0355e-39
  0.000000	 -0.000000	diff=4.18274e-39
  0.000000	  0.000000	diff=1.20606e-38
  0.000000	 -0.000000	diff=2.74019e-38
  0.000000	 -0.000000	diff=5.83619e-19
  0.000000	 -0.000000	diff=1.69628e-18
 -0.000000	 -0.000000	diff=1.08545e-09
  0.000322	  0.000321	diff=6.91994e-07
 -0.000000	 -0.000000	diff=2.35902e-11
  0.000002	  0.000002	diff=5.68942e-09
  0.000111	  0.000111	diff=5.39148e-08
 -0.001752	 -0.001750	diff=1.73542e-06
  0.000000	  0.000000	diff=1.36923e-10
  0.000000	  0.000000	diff=2.49311e-13
  0.000000	  0.000000	diff=7.7673e-10
 -0.000188	 -0.000188	diff=1.81268e-07
  0.000000	  0.000000	diff=1.84462e-10
 -0.000001	 -0.000001	diff=9.52992e-10
  0.000727	  0.000735	diff=8.16531e-06
  0.035747	  0.035835	diff=8.77148e-05
 -0.000000	 -0.000000	diff=9.55325e-11
 -0.000000	 -0.000000	diff=2.53747e-13
  local_diff=0.000257087
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=1.8438e-09
  0.000000	  0.000000	diff=6.60538e-20
  0.000000	  0.000000	diff=7.84351e-21
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=2.22368e-08
  0.000000	  0.000000	diff=5.80066e-09
  0.000000	  0.000000	diff=2.90095e-53
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=8.00612e-10
  0.000000	  0.000000	diff=4.25713e-20
  0.000000	 -0.000000	diff=1.58485e-21
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=9.04999e-09
 -0.000000	 -0.000000	diff=1.79588e-13
  0.000000	 -0.000000	diff=4.91562e-53
  0.000000	 -0.000000	diff=3.51855e-63
  0.000000	 -0.000000	diff=3.04511e-18
  0.000000	 -0.000000	diff=1.17092e-36
  0.000000	 -0.000000	diff=2.28769e-30
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=5.01836e-18
  0.000000	 -0.000000	diff=7.90179e-21
  0.000000	 -0.000000	diff=5.15549e-85
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.62986e-18
  0.000000	  0.000000	diff=1.52167e-36
  0.000000	  0.000000	diff=2.73768e-31
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.68602e-18
  0.000000	  0.000000	diff=3.30789e-21
  0.000000	  0.000000	diff=6.69984e-85
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.72445e-51
  0.000000	  0.000000	diff=4.08275e-37
  0.000000	 -0.000000	diff=8.5963e-26
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=8.76291e-26
  0.000000	  0.000000	diff=4.44014e-33
  0.000000	  0.000000	diff=2.48029e-65
  0.000000	 -0.000000	diff=3.38679e-64
  0.000000	  0.000000	diff=1.79091e-26
  0.000000	  0.000000	diff=3.96354e-41
  0.000000	 -0.000000	diff=8.20729e-37
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=2.95143e-26
  0.000000	  0.000000	diff=1.24571e-22
  0.000000	  0.000000	diff=2.11743e-83
  0.000000	 -0.000000	diff=8.82269e-83
  local_diff=3.9732e-08
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=3.56574e-17
  0.000000	 -0.000000	diff=9.58074e-18
  0.000000	 -0.000000	diff=1.87329e-19
  0.000000	 -0.000000	diff=6.38997e-19
  0.000000	  0.000000	diff=2.45419e-17
  0.000000	 -0.000000	diff=1.20626e-17
  0.000000	  0.000000	diff=5.85818e-13
  0.000000	  0.000000	diff=8.52086e-13
  0.000000	 -0.000000	diff=5.80114e-19
  0.000000	 -0.000000	diff=5.98519e-18
  0.000000	  0.000000	diff=5.94903e-23
  0.000000	  0.000000	diff=4.88193e-23
  0.000000	 -0.000000	diff=8.32051e-19
  0.000000	 -0.000000	diff=7.64317e-18
 -0.000000	 -0.000000	diff=2.71353e-13
 -0.000000	 -0.000000	diff=4.79567e-13
 -0.000060	 -0.000060	diff=1.13329e-08
 -0.000010	 -0.000010	diff=1.91944e-09
 -0.000041	 -0.000041	diff=7.85678e-09
  0.000164	  0.000164	diff=2.75008e-08
 -0.000001	 -0.000001	diff=1.67537e-10
  0.000004	  0.000004	diff=6.97502e-10
 -0.000000	 -0.000000	diff=2.78683e-11
  0.001613	  0.001614	diff=8.43897e-07
  0.001181	  0.001177	diff=4.31122e-06
  0.000192	  0.000193	diff=7.26157e-07
  0.000809	  0.000806	diff=2.98892e-06
 -0.003190	 -0.003200	diff=1.04156e-05
  0.000017	  0.000017	diff=6.32407e-08
 -0.000071	 -0.000071	diff=2.64007e-07
  0.000000	  0.000000	diff=4.05702e-11
 -0.031767	 -0.031444	diff=0.00032264
  local_diff=0.000342302
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.003537	 -0.003599	diff=6.21049e-05
  0.000000	 -0.000000	diff=4.88283e-17
  0.000000	  0.000000	diff=7.98032e-09
  0.000000	  0.000000	diff=4.13408e-23
  local_diff=6.21129e-05
# W_emb_tgt, [2 4]
 -0.000000	 -0.000000	diff=8.95706e-09
  0.000000	  0.000000	diff=5.66152e-16
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=9.63368e-14
  0.000000	  0.000000	diff=5.20232e-22
  0.000000	  0.000000	diff=2.24885e-08
 -0.000001	 -0.000001	diff=3.5697e-08
  local_diff=6.71427e-08
# W_a, [2 2]
 -0.000021	 -0.000021	diff=3.70089e-10
 -0.000521	 -0.000521	diff=1.71619e-08
  0.000288	  0.000288	diff=7.68791e-08
  0.007194	  0.007197	diff=3.43123e-06
  local_diff=3.52564e-06
# W_h, [2 4]
 -0.001058	 -0.001056	diff=1.41846e-06
 -0.021041	 -0.021013	diff=2.80146e-05
  0.003438	  0.003453	diff=1.51023e-05
  0.068412	  0.068710	diff=0.000298424
 -0.000042	 -0.000042	diff=1.01615e-09
 -0.000860	 -0.000860	diff=4.58733e-08
  0.000597	  0.000597	diff=4.51913e-07
  0.011855	  0.011864	diff=8.91774e-06
  local_diff=0.000352376
# W_soft, [4 2]
  0.000034	  0.000034	diff=1.69184e-07
  0.996541	  0.996539	diff=1.68627e-06
 -0.996574	 -0.996576	diff=1.5133e-06
  0.000003	  0.000003	diff=1.50324e-08
  0.000034	  0.000034	diff=1.69393e-07
  0.989316	  0.989314	diff=1.68673e-06
 -0.989349	 -0.989351	diff=1.51355e-06
  0.000003	  0.000003	diff=1.50438e-08
  local_diff=6.76852e-06
# Num params=180, abs_diff=0.00103182
Elapsed time is 2.109499 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 3)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

# Init LSTM parameters using dataType=double, initRange=10
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 v_a=2 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 3
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# logId = 3
# srcSos = 1
# tgtSos = 1
# tgtEos = 2
# srcVocabSize = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <s> a b </s> </s>
  tgt output 1: a b </s> </s> </s>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000001	  0.000001	diff=7.71111e-09
  0.000158	 -0.000005	diff=0.000163181
  0.000000	  0.000000	diff=1.93104e-11
  0.000006	  0.000006	diff=3.36581e-08
 -0.001355	 -0.001346	diff=9.21503e-06
 -0.000001	 -0.000001	diff=3.75515e-08
 -0.000000	 -0.000000	diff=2.01904e-09
  0.000060	  0.000060	diff=5.64828e-07
  0.000000	  0.000000	diff=5.10438e-09
 -0.000194	 -0.000000	diff=0.000193484
  0.000000	  0.000000	diff=1.4879e-33
  0.000000	 -0.000000	diff=1.14678e-25
  0.000000	 -0.000000	diff=6.28577e-30
  0.000000	 -0.000000	diff=2.29507e-17
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.10326e-09
  0.000003	  0.000003	diff=1.08596e-08
  0.000000	  0.000000	diff=6.13123e-12
 -0.000004	 -0.000004	diff=1.2986e-08
  0.000962	  0.000963	diff=1.24815e-06
  0.000007	  0.000007	diff=2.70073e-08
  0.000000	  0.000000	diff=2.92672e-13
  0.000000	  0.000000	diff=5.82397e-11
 -0.000000	 -0.000000	diff=5.47623e-13
 -0.000000	 -0.000000	diff=7.6165e-13
 -0.000000	 -0.000000	diff=5.50316e-13
  0.000000	  0.000000	diff=2.0178e-13
 -0.000002	 -0.000002	diff=1.19224e-09
 -0.000000	 -0.000000	diff=2.50214e-11
  0.000000	  0.000000	diff=2.46577e-13
  0.000000	  0.000000	diff=5.68236e-13
  local_diff=0.000367833
# W_src{2}, [8 4]
 -0.000045	 -0.000045	diff=1.87212e-07
 -0.000309	 -0.000308	diff=1.2531e-06
 -0.000002	 -0.000002	diff=5.37233e-09
 -0.000001	 -0.000001	diff=3.91209e-09
 -0.003418	 -0.003401	diff=1.61501e-05
 -0.001512	 -0.001510	diff=2.10921e-06
  0.000063	  0.000064	diff=5.14387e-07
 -0.000000	 -0.000000	diff=2.42587e-11
  0.000000	 -0.000000	diff=1.88493e-38
  0.000000	  0.000000	diff=1.17096e-37
  0.000000	  0.000000	diff=7.70299e-39
  0.000000	  0.000000	diff=4.5087e-38
  0.000000	 -0.000000	diff=1.2678e-38
  0.000000	  0.000000	diff=1.78807e-37
  0.000000	 -0.000000	diff=8.80711e-19
  0.000000	  0.000000	diff=9.66699e-19
 -0.000026	 -0.000026	diff=8.6516e-08
 -0.000268	 -0.000267	diff=1.02299e-06
 -0.000000	 -0.000000	diff=1.48921e-10
 -0.000001	 -0.000001	diff=2.85365e-09
 -0.000216	 -0.000216	diff=6.9323e-07
 -0.000041	 -0.000041	diff=3.07332e-08
  0.000059	  0.000059	diff=4.43512e-07
 -0.000000	 -0.000000	diff=1.60273e-11
  0.000007	  0.000007	diff=6.92439e-09
  0.000095	  0.000095	diff=1.44847e-07
  0.000002	  0.000002	diff=5.79726e-09
  0.000000	  0.000000	diff=9.01186e-10
  0.003121	  0.003139	diff=1.77592e-05
  0.001323	  0.001323	diff=7.59726e-09
 -0.000017	 -0.000017	diff=3.48392e-08
  0.000000	  0.000000	diff=1.45749e-12
  local_diff=4.04634e-05
# W_tgt{1}, [8 6]
 -0.000001	 -0.000001	diff=4.19872e-09
  0.000000	 -0.000000	diff=5.93927e-20
  0.000000	  0.000000	diff=3.33753e-12
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=5.0626e-08
 -0.000000	 -0.000000	diff=7.51526e-13
  0.000000	  0.000000	diff=5.90485e-53
  0.000000	  0.000000	diff=0
 -0.000000	 -0.000000	diff=1.82159e-09
  0.000000	  0.000000	diff=5.28357e-13
  0.000000	  0.000000	diff=9.76005e-13
  0.000000	  0.000000	diff=0
 -0.000001	 -0.000001	diff=2.06035e-08
  0.000000	  0.000000	diff=9.75154e-13
  0.000000	 -0.000000	diff=1.00057e-52
 -0.000000	 -0.000000	diff=3.08413e-13
  0.000000	  0.000000	diff=1.07353e-12
  0.000000	  0.000000	diff=5.10656e-13
 -0.000000	 -0.000000	diff=6.21694e-13
  0.000000	  0.000000	diff=5.61926e-14
 -0.000000	 -0.000000	diff=4.56229e-13
  0.000000	  0.000000	diff=5.90052e-13
 -0.000000	 -0.000001	diff=4.99793e-07
  0.000003	  0.000002	diff=1.07353e-06
  0.000000	  0.000000	diff=1.51555e-12
 -0.000000	 -0.000000	diff=1.12705e-12
 -0.000000	 -0.000000	diff=9.86106e-14
 -0.000000	 -0.000000	diff=3.93558e-13
 -0.000000	 -0.000000	diff=5.81601e-13
 -0.000000	 -0.000000	diff=8.41935e-13
  0.000003	  0.000005	diff=1.97835e-06
 -0.000013	 -0.000009	diff=4.20626e-06
 -0.000002	 -0.000002	diff=5.18708e-09
  0.000000	  0.000000	diff=2.5367e-15
 -0.000002	 -0.000002	diff=7.16958e-09
  0.000000	  0.000000	diff=4.09434e-13
 -0.000001	 -0.000001	diff=2.78134e-09
 -0.000000	 -0.000000	diff=2.31839e-13
 -0.000000	 -0.000000	diff=1.18494e-11
  0.000000	  0.000000	diff=6.94714e-12
 -0.000000	 -0.000000	diff=7.18298e-12
  0.000000	  0.000000	diff=1.45839e-13
 -0.000000	 -0.000000	diff=1.12771e-11
  0.000000	  0.000000	diff=5.36816e-13
 -0.000000	 -0.000000	diff=5.2539e-12
  0.000000	  0.000000	diff=1.83226e-13
 -0.000000	 -0.000000	diff=6.84446e-08
  0.000000	  0.000000	diff=1.46927e-07
  local_diff=8.06576e-06
# W_tgt{2}, [8 4]
  0.000109	  0.000109	diff=4.31145e-08
 -0.000000	 -0.000000	diff=4.7707e-11
 -0.000000	 -0.000000	diff=6.42872e-11
  0.000000	  0.000000	diff=1.58615e-10
 -0.000005	 -0.000005	diff=2.3855e-08
  0.000001	  0.000001	diff=2.94526e-09
  0.000001	  0.000002	diff=2.03539e-07
 -0.000003	 -0.000003	diff=4.37609e-08
 -0.000000	 -0.000000	diff=2.96047e-13
  0.000000	  0.000000	diff=1.01176e-13
 -0.000000	 -0.000000	diff=3.24934e-13
  0.000000	  0.000000	diff=8.44173e-14
 -0.000000	 -0.000000	diff=8.03062e-14
  0.000000	  0.000000	diff=1.66716e-13
  0.000000	  0.000005	diff=4.31779e-06
 -0.000013	 -0.000010	diff=2.86293e-06
  0.000084	  0.000084	diff=3.69071e-09
 -0.000000	 -0.000000	diff=2.59601e-11
 -0.000000	 -0.000000	diff=3.47241e-11
  0.000000	  0.000000	diff=8.59228e-11
 -0.000004	 -0.000004	diff=1.5838e-08
  0.000000	  0.000000	diff=1.59444e-09
 -0.000000	 -0.000000	diff=3.63246e-09
  0.000000	  0.000000	diff=7.87449e-10
 -0.000023	 -0.000023	diff=2.54425e-09
  0.000000	  0.000000	diff=2.3192e-12
  0.000000	  0.000000	diff=3.88335e-12
 -0.000000	 -0.000000	diff=9.60237e-12
  0.000001	  0.000001	diff=9.86622e-10
 -0.000000	 -0.000000	diff=1.7678e-10
 -0.000000	 -0.000000	diff=3.09203e-08
  0.000000	  0.000000	diff=7.02617e-09
  local_diff=7.56557e-06
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.003808	 -0.003702	diff=0.000105797
  0.000000	  0.000000	diff=4.23686e-17
  0.000276	  0.000000	diff=0.000276148
  0.000319	  0.000000	diff=0.000318753
  local_diff=0.000700698
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=8.73261e-16
 -0.000000	 -0.000000	diff=6.5708e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=1.21566e-20
  0.000000	 -0.000000	diff=9.68362e-16
  0.000001	  0.000001	diff=5.11986e-08
 -0.000001	 -0.000001	diff=8.12716e-08
  local_diff=1.32471e-07
# W_a, [2 2]
  0.000132	  0.000126	diff=5.62188e-06
 -0.000165	 -0.000164	diff=1.35735e-06
 -0.000000	 -0.000000	diff=4.68953e-13
  0.000000	  0.000000	diff=4.85336e-13
  local_diff=6.97923e-06
# v_a, [1 2]
 -0.004163	 -0.004146	diff=1.76561e-05
 -0.000435	 -0.000435	diff=2.00205e-07
  local_diff=1.78563e-05
# W_h, [2 4]
 -0.000004	 -0.000004	diff=1.4079e-08
  0.003128	  0.003139	diff=1.05677e-05
  0.000006	  0.000006	diff=3.00859e-08
 -0.004576	 -0.004553	diff=2.23587e-05
 -0.000010	 -0.000011	diff=7.87962e-07
  0.008809	  0.008893	diff=8.43632e-05
 -0.000002	 -0.000007	diff=5.38299e-06
  0.000011	  0.000006	diff=4.7819e-06
  local_diff=0.000128287
# W_soft, [4 2]
 -0.009588	 -0.009636	diff=4.78789e-05
 -0.002234	 -0.005573	diff=0.00333881
  0.992061	  0.992021	diff=3.96587e-05
 -0.973438	 -0.976813	diff=0.00337457
 -0.009596	 -0.009644	diff=4.77818e-05
 -0.002327	 -0.005659	diff=0.00333203
  0.991124	  0.991085	diff=3.95783e-05
 -0.972414	 -0.975781	diff=0.00336772
  local_diff=0.013588
# Num params=182, abs_diff=0.0148659
Elapsed time is 2.177881 seconds.
[?1l>