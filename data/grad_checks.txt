# Script dir = /Users/lmthang/nmt.matlab/scripts
cd /Users/lmthang/nmt.matlab/scripts/../code

## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 104, individual sizes:  W_src{1}=32 W_tgt{1}=48 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 1
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 104
  src input 1: y y x y
  src mask: 1  1  1  1
  tgt input 1: <t_sos> a b a
  tgt output 1: a b a <t_eos>
  tgt mask: 1  1  1  1
# W_src{1}, [8 4]
 -0.000013	 -0.000013	diff=1.00581e-10
 -0.000002	 -0.000002	diff=1.58468e-11
 -0.000010	 -0.000010	diff=1.1217e-09
 -0.000001	 -0.000001	diff=1.23089e-10
 -0.000000	 -0.000000	diff=1.04141e-12
  0.000000	  0.000000	diff=9.07881e-13
 -0.003613	 -0.003613	diff=8.10743e-08
  0.000713	  0.000713	diff=9.21717e-09
  0.000015	  0.000015	diff=1.37375e-10
  0.000003	  0.000003	diff=2.07755e-11
  0.000011	  0.000011	diff=1.43185e-09
  0.000001	  0.000001	diff=1.86931e-10
  0.000000	  0.000000	diff=2.33636e-12
 -0.000000	 -0.000000	diff=1.13417e-12
  0.004176	  0.004176	diff=1.0838e-07
 -0.000891	 -0.000891	diff=1.45165e-08
  0.000001	  0.000001	diff=3.86068e-12
  0.000000	  0.000000	diff=5.75087e-13
  0.000000	  0.000000	diff=3.83232e-12
  0.000000	  0.000000	diff=7.18741e-13
 -0.000000	 -0.000000	diff=3.80584e-13
 -0.000000	 -0.000000	diff=1.08735e-12
  0.000155	  0.000154	diff=2.82143e-07
 -0.000021	 -0.000021	diff=1.65579e-10
 -0.000000	 -0.000000	diff=1.37378e-13
 -0.000000	 -0.000000	diff=4.1579e-13
 -0.000000	 -0.000000	diff=8.26237e-13
 -0.000000	 -0.000000	diff=9.4915e-13
  0.000000	  0.000000	diff=2.77459e-13
  0.000000	  0.000000	diff=5.61059e-13
 -0.000120	 -0.000120	diff=1.68958e-09
  0.000016	  0.000016	diff=3.36779e-08
  local_diff=5.34021e-07
# W_tgt{1}, [8 6]
 -0.000023	 -0.000023	diff=8.22795e-11
  0.000002	  0.000002	diff=4.21865e-11
  0.000027	  0.000027	diff=1.70418e-09
 -0.000000	 -0.000000	diff=4.36351e-10
  0.000018	  0.000018	diff=8.6079e-11
  0.000001	  0.000001	diff=1.0676e-11
  0.019842	  0.019842	diff=1.67844e-07
 -0.001313	 -0.001313	diff=3.03045e-08
  0.000041	  0.000041	diff=2.24695e-11
  0.000002	  0.000002	diff=4.93694e-11
  0.000000	  0.000000	diff=1.03452e-08
  0.000005	  0.000005	diff=1.76185e-10
  0.000055	  0.000055	diff=2.0443e-11
  0.000005	  0.000005	diff=6.52866e-11
 -0.011633	 -0.011633	diff=3.68551e-07
 -0.001429	 -0.001429	diff=8.41353e-09
  0.000000	  0.000000	diff=3.61114e-12
 -0.000000	 -0.000000	diff=5.59428e-13
 -0.000001	 -0.000001	diff=1.66645e-12
  0.000000	  0.000000	diff=5.90792e-13
 -0.000000	 -0.000000	diff=5.34451e-13
 -0.000000	 -0.000000	diff=1.84839e-13
 -0.000167	 -0.000167	diff=8.2321e-07
 -0.000041	 -0.000041	diff=1.27712e-09
 -0.000000	 -0.000000	diff=3.83453e-13
  0.000000	  0.000000	diff=3.47029e-13
  0.000000	  0.000000	diff=2.38324e-13
 -0.000000	 -0.000000	diff=4.6071e-13
  0.000000	  0.000000	diff=2.05234e-13
  0.000000	  0.000000	diff=1.718e-13
  0.000055	  0.000055	diff=4.22464e-09
  0.000031	  0.000031	diff=2.84871e-08
  0.000001	  0.000001	diff=9.52438e-13
  0.000000	  0.000000	diff=3.51754e-13
  0.000000	  0.000000	diff=7.37492e-12
  0.000000	  0.000000	diff=3.04127e-13
  0.000002	  0.000002	diff=1.7391e-13
  0.000000	  0.000000	diff=5.4158e-13
  0.000041	  0.000042	diff=1.62139e-06
 -0.000089	 -0.000089	diff=2.78163e-09
 -0.000001	 -0.000001	diff=5.47438e-13
 -0.000000	 -0.000000	diff=4.30218e-13
 -0.000000	 -0.000000	diff=5.80738e-13
 -0.000000	 -0.000000	diff=4.95699e-13
 -0.000001	 -0.000001	diff=2.21791e-13
 -0.000000	 -0.000000	diff=8.2266e-13
 -0.000100	 -0.000100	diff=1.49232e-08
  0.000069	  0.000068	diff=1.43545e-08
  local_diff=3.09882e-06
# W_emb_src, [2 4]
 -0.001162	 -0.001162	diff=2.73404e-07
  0.001998	  0.001997	diff=7.75039e-07
 -0.001487	 -0.001487	diff=3.43119e-07
  0.002311	  0.002310	diff=8.76973e-07
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=2.26853e-06
# W_emb_tgt, [2 4]
 -0.009062	 -0.009061	diff=8.53796e-07
 -0.003136	 -0.003135	diff=3.85396e-07
 -0.004123	 -0.004123	diff=8.56602e-07
 -0.001353	 -0.001353	diff=2.27634e-07
  0.004611	  0.004612	diff=4.17262e-07
  0.001362	  0.001362	diff=2.80845e-07
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=3.02154e-06
# W_soft, [4 2]
 -0.014903	 -0.014903	diff=9.79672e-08
 -0.003292	 -0.003292	diff=9.79819e-08
  0.005365	  0.005365	diff=9.79731e-08
  0.012831	  0.012831	diff=9.79869e-08
  0.010052	  0.010052	diff=5.11384e-08
  0.001880	  0.001880	diff=5.11442e-08
 -0.001340	 -0.001340	diff=5.11415e-08
 -0.010593	 -0.010593	diff=5.11469e-08
  local_diff=5.9648e-07
# Num params=104, abs_diff=9.5194e-06
Elapsed time is 0.722024 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s_sos> x y y
  src mask: 0  1  1  1
  tgt input 1: <t_sos> b b <t_eos> <t_eos>
  tgt output 1: b b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=2.37356e-13
  0.000000	  0.000000	diff=5.07596e-13
 -0.000000	 -0.000000	diff=3.89347e-13
  0.000000	  0.000000	diff=2.09694e-13
  0.000000	  0.000000	diff=6.7354e-13
 -0.000000	 -0.000000	diff=3.01608e-13
 -0.000098	 -0.000098	diff=1.71358e-10
 -0.000027	 -0.000027	diff=2.02507e-10
 -0.000000	 -0.000000	diff=4.03735e-13
  0.000000	  0.000000	diff=4.93459e-13
 -0.000000	 -0.000000	diff=1.05589e-12
  0.000000	  0.000000	diff=1.31381e-12
 -0.000000	 -0.000000	diff=5.29186e-13
 -0.000000	 -0.000000	diff=6.33429e-14
 -0.000071	 -0.000071	diff=2.73825e-10
 -0.000016	 -0.000016	diff=2.06476e-10
 -0.000000	 -0.000000	diff=3.1992e-13
  0.000000	  0.000000	diff=3.49978e-14
 -0.000000	 -0.000000	diff=3.31659e-13
  0.000000	  0.000000	diff=5.91489e-13
 -0.000000	 -0.000000	diff=7.90748e-13
 -0.000000	 -0.000000	diff=2.27064e-14
 -0.000000	 -0.000000	diff=1.57994e-10
 -0.000000	 -0.000000	diff=1.19818e-13
  0.000000	  0.000000	diff=3.78066e-14
 -0.000000	 -0.000000	diff=3.79243e-13
  0.000000	  0.000000	diff=3.76031e-13
 -0.000000	 -0.000000	diff=5.89753e-13
  0.000000	  0.000000	diff=5.50325e-13
  0.000000	  0.000000	diff=3.55559e-13
  0.000001	  0.000001	diff=2.3666e-12
  0.000000	  0.000000	diff=4.45165e-10
  local_diff=1.47037e-09
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=7.25711e-14
 -0.000000	 -0.000000	diff=9.41711e-14
 -0.000000	 -0.000000	diff=2.72845e-13
 -0.000000	 -0.000000	diff=4.41692e-14
  0.000000	  0.000000	diff=4.86349e-13
 -0.000000	 -0.000000	diff=4.3558e-13
  0.000000	  0.000000	diff=8.2258e-13
 -0.000001	 -0.000001	diff=3.2864e-12
  0.000000	  0.000000	diff=3.94709e-14
  0.000000	  0.000000	diff=1.44032e-13
  0.000000	  0.000000	diff=2.51421e-13
  0.000000	  0.000000	diff=1.28913e-12
 -0.000000	 -0.000000	diff=4.95312e-13
  0.000000	  0.000000	diff=3.3129e-13
  0.000010	  0.000010	diff=7.19492e-13
 -0.000035	 -0.000035	diff=8.99509e-12
 -0.000000	 -0.000000	diff=4.46887e-13
 -0.000000	 -0.000000	diff=2.6235e-13
 -0.000000	 -0.000000	diff=5.15374e-13
 -0.000000	 -0.000000	diff=8.96287e-14
  0.000000	  0.000000	diff=1.77944e-13
  0.000000	 -0.000000	diff=1.78689e-13
 -0.000000	 -0.000000	diff=2.93359e-11
  0.000000	  0.000000	diff=3.58466e-14
  0.000000	  0.000000	diff=9.04837e-13
  0.000000	  0.000000	diff=9.27368e-13
  0.000000	  0.000000	diff=3.49249e-13
  0.000000	  0.000000	diff=3.77428e-13
  0.000000	 -0.000000	diff=2.36505e-13
  0.000000	  0.000000	diff=2.4404e-13
  0.000000	  0.000000	diff=2.02618e-13
 -0.000000	 -0.000000	diff=4.59638e-10
  local_diff=5.11703e-10
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=3.35442e-13
  0.000000	  0.000000	diff=3.94848e-13
 -0.000000	 -0.000000	diff=8.35513e-13
  0.000000	  0.000000	diff=3.19567e-12
 -0.000000	 -0.000000	diff=3.12538e-13
  0.000000	  0.000000	diff=2.25089e-13
  0.000018	  0.000018	diff=1.56162e-10
 -0.000180	 -0.000180	diff=6.4791e-10
  0.000000	  0.000000	diff=5.97299e-13
 -0.000000	 -0.000000	diff=1.17176e-12
  0.000000	  0.000000	diff=7.39324e-13
 -0.000000	 -0.000000	diff=6.04085e-12
  0.000000	  0.000000	diff=3.74592e-13
 -0.000001	 -0.000001	diff=1.50315e-12
 -0.000019	 -0.000019	diff=5.46561e-10
  0.000267	  0.000267	diff=1.72464e-09
 -0.000000	 -0.000000	diff=7.72659e-13
  0.000000	  0.000000	diff=5.256e-13
  0.000000	  0.000000	diff=1.40037e-13
  0.000000	  0.000000	diff=6.0965e-13
 -0.000000	 -0.000000	diff=1.20597e-13
  0.000000	  0.000000	diff=1.34371e-13
 -0.000000	 -0.000000	diff=8.68219e-14
 -0.000000	 -0.000000	diff=3.16904e-13
 -0.000000	 -0.000000	diff=2.54767e-13
  0.000000	  0.000000	diff=1.13838e-13
  0.000000	  0.000000	diff=3.30865e-13
 -0.000000	 -0.000000	diff=3.9686e-13
 -0.000000	 -0.000000	diff=1.03145e-13
  0.000000	  0.000000	diff=4.09281e-13
 -0.000000	 -0.000000	diff=8.13412e-13
  0.000000	  0.000000	diff=2.02349e-12
  0.000000	  0.000000	diff=4.83992e-13
 -0.000000	 -0.000000	diff=3.21717e-13
  0.000000	  0.000000	diff=3.58882e-13
  0.000000	  0.000000	diff=1.14669e-13
  0.000000	  0.000000	diff=5.65705e-13
 -0.000000	 -0.000000	diff=8.01985e-14
  0.000000	  0.000000	diff=7.736e-10
  0.000000	  0.000000	diff=1.464e-11
  0.000000	  0.000000	diff=3.80087e-14
 -0.000000	 -0.000000	diff=3.63436e-13
 -0.000000	 -0.000000	diff=1.01133e-12
 -0.000000	 -0.000000	diff=7.74789e-14
  0.000000	  0.000000	diff=8.27628e-13
 -0.000000	 -0.000000	diff=5.33543e-13
  0.000001	  0.000001	diff=4.38372e-11
  0.000002	  0.000002	diff=3.02569e-09
  local_diff=6.96069e-09
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=1.92292e-13
 -0.000000	 -0.000000	diff=6.25853e-14
 -0.000000	 -0.000000	diff=2.1148e-13
 -0.000000	 -0.000000	diff=5.64859e-13
  0.000000	  0.000000	diff=8.46261e-14
 -0.000000	 -0.000000	diff=5.17635e-13
  0.000012	  0.000012	diff=2.91316e-10
 -0.000062	 -0.000062	diff=4.91028e-11
  0.000000	  0.000000	diff=3.36282e-13
 -0.000000	 -0.000000	diff=6.32542e-13
  0.000000	  0.000000	diff=4.91868e-13
 -0.000000	 -0.000000	diff=1.5889e-13
  0.000000	  0.000000	diff=6.1663e-13
 -0.000000	 -0.000000	diff=1.73656e-14
  0.000019	  0.000019	diff=7.04199e-09
 -0.000193	 -0.000193	diff=7.89954e-10
  0.000000	  0.000000	diff=8.50074e-14
  0.000000	  0.000000	diff=3.42618e-13
 -0.000000	 -0.000000	diff=1.87641e-13
 -0.000000	 -0.000000	diff=6.48417e-14
 -0.000000	 -0.000000	diff=4.69917e-13
  0.000000	  0.000000	diff=1.03154e-12
  0.000000	  0.000000	diff=1.33143e-09
  0.000000	  0.000000	diff=2.00005e-11
  0.000000	  0.000000	diff=2.25047e-13
  0.000000	  0.000000	diff=1.90105e-13
  0.000000	  0.000000	diff=3.55687e-13
  0.000000	  0.000000	diff=4.70236e-13
  0.000000	  0.000000	diff=5.76478e-13
  0.000000	  0.000000	diff=3.9976e-13
  0.000002	  0.000002	diff=3.88208e-12
 -0.000000	 -0.000000	diff=4.67449e-09
  local_diff=1.42105e-08
# W_emb_src, [2 4]
  0.000077	  0.000077	diff=2.28501e-08
 -0.000079	 -0.000079	diff=6.2331e-08
  0.000060	  0.000060	diff=2.10513e-08
 -0.000053	 -0.000053	diff=5.22341e-08
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.58466e-07
# W_emb_tgt, [2 4]
  0.000078	  0.000078	diff=1.34663e-08
  0.000007	  0.000007	diff=5.13426e-09
 -0.000015	 -0.000015	diff=2.08447e-08
  0.000013	  0.000013	diff=8.10949e-09
  0.000152	  0.000152	diff=3.17758e-08
 -0.000016	 -0.000016	diff=8.84772e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=8.81784e-08
# W_soft, [4 2]
 -0.000066	 -0.000066	diff=2.39247e-12
 -0.000008	 -0.000008	diff=2.44774e-12
  0.000061	  0.000061	diff=3.34885e-12
  0.000013	  0.000013	diff=2.46908e-12
 -0.000231	 -0.000231	diff=3.58424e-11
 -0.000009	 -0.000009	diff=3.57434e-11
  0.000264	  0.000264	diff=3.59311e-11
 -0.000024	 -0.000024	diff=3.53022e-11
  local_diff=1.53477e-10
# Num params=168, abs_diff=2.69951e-07
Elapsed time is 1.354492 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s_sos> x y y
  src mask: 0  1  1  1
  tgt input 1: <t_sos> b b <t_eos> <t_eos>
  tgt output 1: b b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=2.41921e-13
  0.000000	  0.000000	diff=1.13882e-13
  0.000000	  0.000000	diff=7.78944e-13
  0.000000	  0.000000	diff=1.53588e-12
  0.000000	  0.000000	diff=3.10804e-13
 -0.000000	 -0.000000	diff=8.21178e-13
 -0.000126	 -0.000126	diff=4.98445e-10
 -0.000035	 -0.000035	diff=2.84288e-10
 -0.000000	 -0.000000	diff=6.99491e-13
  0.000000	  0.000000	diff=5.76578e-13
 -0.000000	 -0.000000	diff=1.58157e-12
  0.000000	  0.000000	diff=8.81302e-13
 -0.000000	 -0.000000	diff=8.39032e-13
 -0.000000	 -0.000000	diff=4.56608e-13
 -0.000077	 -0.000077	diff=6.81639e-10
 -0.000023	 -0.000023	diff=2.56557e-10
 -0.000000	 -0.000000	diff=8.33355e-13
  0.000000	  0.000000	diff=6.33076e-14
 -0.000000	 -0.000000	diff=1.30624e-12
  0.000000	  0.000000	diff=1.26546e-13
 -0.000000	 -0.000000	diff=8.68984e-13
 -0.000000	 -0.000000	diff=1.20782e-13
  0.000000	  0.000000	diff=4.11869e-10
 -0.000000	 -0.000000	diff=2.93692e-12
  0.000000	  0.000000	diff=4.68143e-13
 -0.000000	 -0.000000	diff=4.52296e-14
  0.000000	  0.000000	diff=5.79574e-14
 -0.000000	 -0.000000	diff=5.04332e-13
  0.000000	  0.000000	diff=6.19124e-13
  0.000000	  0.000000	diff=2.456e-13
  0.000001	  0.000001	diff=2.79816e-12
  0.000000	  0.000000	diff=3.29819e-10
  local_diff=2.48245e-09
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=3.10627e-13
 -0.000000	 -0.000000	diff=3.34141e-13
 -0.000000	 -0.000000	diff=4.59341e-13
 -0.000000	 -0.000000	diff=1.82374e-13
  0.000000	  0.000000	diff=8.80668e-13
 -0.000000	 -0.000000	diff=5.2049e-13
  0.000002	  0.000002	diff=1.86338e-12
 -0.000010	 -0.000010	diff=6.511e-12
  0.000000	  0.000000	diff=6.27137e-13
  0.000000	  0.000000	diff=5.02097e-13
  0.000000	  0.000000	diff=5.24494e-13
  0.000000	  0.000000	diff=7.49579e-13
 -0.000000	 -0.000000	diff=7.8091e-13
  0.000000	  0.000000	diff=9.79299e-14
  0.000013	  0.000013	diff=4.05552e-12
 -0.000037	 -0.000037	diff=1.36201e-11
 -0.000000	 -0.000000	diff=6.85669e-13
 -0.000000	 -0.000000	diff=6.98618e-13
 -0.000000	 -0.000000	diff=2.27543e-13
 -0.000000	 -0.000000	diff=2.81124e-13
  0.000000	  0.000000	diff=4.17616e-13
  0.000000	 -0.000000	diff=2.3321e-13
  0.000000	  0.000000	diff=1.56117e-10
  0.000000	  0.000000	diff=5.09185e-14
  0.000000	  0.000000	diff=5.70324e-13
  0.000000	  0.000000	diff=1.13197e-13
  0.000000	  0.000000	diff=3.1908e-13
  0.000000	  0.000000	diff=7.63119e-13
  0.000000	 -0.000000	diff=3.80106e-13
  0.000000	  0.000000	diff=3.15695e-13
  0.000000	  0.000000	diff=3.69123e-13
 -0.000000	 -0.000000	diff=1.62375e-10
  local_diff=3.55937e-10
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=9.10741e-13
  0.000000	  0.000000	diff=4.84747e-13
 -0.000000	 -0.000000	diff=4.35695e-13
  0.000000	  0.000000	diff=6.58287e-12
 -0.000000	 -0.000000	diff=1.12174e-13
  0.000001	  0.000001	diff=9.01199e-13
  0.000028	  0.000028	diff=2.80272e-10
 -0.000217	 -0.000217	diff=1.5364e-09
  0.000000	  0.000000	diff=8.90854e-13
 -0.000001	 -0.000001	diff=2.84567e-12
 -0.000000	 -0.000000	diff=2.90013e-12
 -0.000000	 -0.000000	diff=1.27122e-11
  0.000000	  0.000000	diff=3.09495e-13
 -0.000001	 -0.000001	diff=1.49146e-12
 -0.000029	 -0.000029	diff=8.7929e-10
  0.000325	  0.000325	diff=3.92382e-09
  0.000000	 -0.000000	diff=7.66829e-13
  0.000000	  0.000000	diff=2.41177e-13
  0.000000	  0.000000	diff=6.69556e-13
  0.000000	  0.000000	diff=1.22768e-13
  0.000000	 -0.000000	diff=1.0682e-13
  0.000000	  0.000000	diff=9.24893e-13
 -0.000000	 -0.000000	diff=1.19799e-12
 -0.000000	 -0.000000	diff=3.05874e-13
 -0.000000	 -0.000000	diff=6.02126e-13
  0.000000	  0.000000	diff=3.59146e-13
  0.000000	  0.000000	diff=4.31064e-14
  0.000000	  0.000000	diff=1.2625e-12
  0.000000	 -0.000000	diff=9.36276e-13
  0.000000	  0.000000	diff=2.28239e-13
 -0.000000	 -0.000000	diff=2.48092e-13
  0.000000	  0.000000	diff=4.15305e-12
  0.000000	  0.000000	diff=8.19603e-13
 -0.000000	 -0.000000	diff=1.08799e-12
 -0.000000	 -0.000000	diff=4.13952e-13
  0.000000	  0.000000	diff=4.31799e-13
  0.000000	  0.000000	diff=3.54324e-13
 -0.000000	 -0.000000	diff=6.30747e-14
  0.000000	  0.000000	diff=1.66443e-09
  0.000001	  0.000001	diff=2.01473e-11
  0.000000	  0.000000	diff=6.94325e-13
 -0.000000	 -0.000000	diff=3.40176e-14
 -0.000000	 -0.000000	diff=6.05442e-13
 -0.000000	 -0.000000	diff=1.16727e-12
  0.000000	  0.000000	diff=1.92438e-13
 -0.000000	 -0.000000	diff=1.35242e-12
  0.000000	  0.000000	diff=6.43237e-11
  0.000002	  0.000002	diff=2.56913e-09
  local_diff=1.09878e-08
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=9.93559e-13
 -0.000000	 -0.000000	diff=4.36458e-13
 -0.000000	 -0.000000	diff=4.70311e-13
 -0.000000	 -0.000000	diff=3.70685e-13
  0.000000	  0.000000	diff=3.27424e-13
 -0.000000	 -0.000000	diff=3.81042e-13
  0.000017	  0.000017	diff=6.04319e-10
 -0.000106	 -0.000106	diff=2.84581e-10
  0.000000	  0.000000	diff=9.60599e-14
 -0.000000	 -0.000000	diff=3.73683e-13
  0.000000	  0.000000	diff=1.76759e-13
 -0.000000	 -0.000000	diff=3.57188e-13
  0.000000	  0.000000	diff=1.16965e-13
 -0.000000	 -0.000000	diff=5.43616e-13
  0.000033	  0.000033	diff=9.75778e-09
 -0.000236	 -0.000236	diff=3.00329e-10
  0.000000	  0.000000	diff=2.1985e-13
  0.000000	  0.000000	diff=8.98444e-15
 -0.000000	 -0.000000	diff=1.39195e-13
 -0.000000	 -0.000000	diff=1.24977e-12
 -0.000000	 -0.000000	diff=7.87939e-13
  0.000000	  0.000000	diff=4.94831e-13
  0.000000	  0.000000	diff=1.10421e-09
  0.000000	  0.000000	diff=1.75796e-11
  0.000000	  0.000000	diff=1.12459e-13
  0.000000	  0.000000	diff=2.77725e-13
  0.000000	  0.000000	diff=5.90784e-13
  0.000000	  0.000000	diff=1.86654e-13
  0.000000	  0.000000	diff=6.1457e-14
  0.000000	  0.000000	diff=1.90634e-13
  0.000002	  0.000002	diff=6.33688e-12
  0.000001	  0.000001	diff=6.42654e-09
  local_diff=1.85106e-08
# W_emb_src, [2 4]
  0.000086	  0.000086	diff=3.56953e-08
 -0.000080	 -0.000080	diff=8.6828e-08
  0.000092	  0.000092	diff=4.07023e-08
 -0.000076	 -0.000076	diff=8.65576e-08
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=2.49783e-07
# W_emb_tgt, [2 4]
  0.000106	  0.000106	diff=2.25548e-08
  0.000007	  0.000007	diff=6.80561e-09
 -0.000010	 -0.000010	diff=2.68549e-08
  0.000013	  0.000013	diff=1.02163e-08
  0.000171	  0.000171	diff=5.5605e-08
 -0.000022	 -0.000022	diff=1.45325e-08
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.36569e-07
# W_soft, [4 2]
 -0.000099	 -0.000099	diff=5.54114e-12
  0.000004	  0.000004	diff=5.65959e-12
  0.000084	  0.000084	diff=5.34958e-12
  0.000011	  0.000011	diff=5.47651e-12
 -0.000355	 -0.000355	diff=7.53036e-11
  0.000051	  0.000051	diff=7.47551e-11
  0.000328	  0.000328	diff=7.47174e-11
 -0.000023	 -0.000023	diff=7.50729e-11
  local_diff=3.21876e-10
# Num params=168, abs_diff=4.19011e-07
Elapsed time is 1.371711 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 176, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 176
  src input 1: <s_sos> y x x
  src mask: 0  1  1  1
  tgt input 1: <t_sos> a b <t_eos> <t_eos>
  tgt output 1: a b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=1.15401e-12
  0.000000	  0.000000	diff=5.13354e-13
 -0.000000	 -0.000000	diff=9.59474e-13
  0.000000	  0.000000	diff=3.26627e-13
 -0.000000	 -0.000000	diff=3.42819e-16
 -0.000000	 -0.000000	diff=5.73973e-13
 -0.000005	 -0.000005	diff=1.196e-11
 -0.000004	 -0.000004	diff=1.98325e-11
 -0.000000	 -0.000000	diff=1.44392e-12
  0.000000	  0.000000	diff=1.06636e-13
 -0.000000	 -0.000000	diff=9.31791e-13
  0.000000	  0.000000	diff=5.17458e-13
 -0.000000	 -0.000000	diff=4.76719e-13
 -0.000000	 -0.000000	diff=1.41568e-12
 -0.000004	 -0.000004	diff=2.07079e-11
 -0.000003	 -0.000003	diff=1.98266e-11
  0.000000	  0.000000	diff=1.13727e-12
  0.000000	  0.000000	diff=7.10917e-13
 -0.000000	 -0.000000	diff=5.47778e-13
  0.000000	  0.000000	diff=6.17749e-13
 -0.000000	 -0.000000	diff=1.09919e-12
 -0.000000	 -0.000000	diff=1.48999e-13
 -0.000000	 -0.000000	diff=6.72318e-11
 -0.000000	 -0.000000	diff=2.32263e-13
 -0.000000	 -0.000000	diff=6.87993e-13
 -0.000000	 -0.000000	diff=9.56168e-13
  0.000000	  0.000000	diff=8.0625e-13
 -0.000000	 -0.000000	diff=9.86056e-13
  0.000000	  0.000000	diff=8.53916e-13
  0.000000	  0.000000	diff=1.13281e-12
  0.000000	  0.000000	diff=3.63277e-13
  0.000000	  0.000000	diff=1.21661e-10
  local_diff=2.7992e-10
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=1.08086e-12
 -0.000000	 -0.000000	diff=1.25062e-12
 -0.000000	 -0.000000	diff=1.98774e-13
 -0.000000	 -0.000000	diff=5.07398e-13
 -0.000000	 -0.000000	diff=1.33975e-12
  0.000000	  0.000000	diff=6.78005e-13
 -0.000000	 -0.000000	diff=9.58758e-13
  0.000000	  0.000000	diff=1.16417e-12
  0.000000	  0.000000	diff=8.64851e-13
  0.000000	  0.000000	diff=6.19948e-13
  0.000000	  0.000000	diff=1.76449e-13
  0.000000	  0.000000	diff=4.50339e-13
  0.000000	  0.000000	diff=5.91149e-13
 -0.000000	 -0.000000	diff=5.46162e-13
  0.000001	  0.000001	diff=1.19235e-12
 -0.000002	 -0.000002	diff=8.37292e-13
 -0.000000	 -0.000000	diff=6.70782e-13
 -0.000000	 -0.000000	diff=6.53302e-13
 -0.000000	 -0.000000	diff=6.1873e-13
 -0.000000	 -0.000000	diff=8.14782e-13
 -0.000000	 -0.000000	diff=5.38529e-13
  0.000000	  0.000000	diff=2.66726e-13
 -0.000000	 -0.000000	diff=2.41288e-12
  0.000000	  0.000000	diff=1.02706e-12
  0.000000	  0.000000	diff=5.28545e-14
  0.000000	  0.000000	diff=7.02214e-13
 -0.000000	  0.000000	diff=8.36709e-13
  0.000000	  0.000000	diff=6.8384e-13
  0.000000	  0.000000	diff=2.37466e-13
 -0.000000	 -0.000000	diff=7.79555e-13
  0.000000	  0.000000	diff=8.49151e-13
 -0.000000	 -0.000000	diff=1.06647e-10
  local_diff=1.30248e-10
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=1.03449e-12
  0.000000	  0.000000	diff=1.1837e-13
 -0.000000	 -0.000000	diff=7.3446e-13
  0.000000	  0.000000	diff=1.36647e-12
 -0.000000	 -0.000000	diff=2.81041e-13
  0.000000	  0.000000	diff=4.79924e-13
  0.000001	  0.000001	diff=8.47644e-12
 -0.000013	 -0.000013	diff=9.5054e-11
  0.000000	  0.000000	diff=5.90973e-13
 -0.000000	 -0.000000	diff=1.35574e-12
 -0.000000	 -0.000000	diff=2.45259e-13
 -0.000000	 -0.000000	diff=4.25095e-13
  0.000000	  0.000000	diff=4.39027e-13
 -0.000000	 -0.000000	diff=9.22238e-13
 -0.000001	 -0.000001	diff=1.21362e-11
  0.000021	  0.000021	diff=2.07959e-10
  0.000000	  0.000000	diff=9.53227e-15
 -0.000000	 -0.000000	diff=6.1877e-13
 -0.000000	 -0.000000	diff=7.01619e-13
  0.000000	  0.000000	diff=7.98304e-13
  0.000000	  0.000000	diff=2.67518e-15
  0.000000	  0.000000	diff=3.80173e-13
  0.000000	  0.000000	diff=2.03503e-13
 -0.000000	 -0.000000	diff=8.23554e-14
  0.000000	  0.000000	diff=1.07037e-14
 -0.000000	 -0.000000	diff=6.14425e-13
 -0.000000	 -0.000000	diff=7.0207e-13
  0.000000	  0.000000	diff=8.56682e-13
  0.000000	  0.000000	diff=4.09518e-15
  0.000000	  0.000000	diff=3.96105e-13
  0.000000	  0.000000	diff=6.71254e-13
 -0.000000	 -0.000000	diff=3.03003e-13
  0.000000	  0.000000	diff=8.61659e-13
  0.000000	  0.000000	diff=1.55335e-13
  0.000000	  0.000000	diff=2.85866e-13
 -0.000000	 -0.000000	diff=1.11982e-12
  0.000000	  0.000000	diff=1.34182e-12
  0.000000	  0.000000	diff=1.00784e-14
 -0.000000	 -0.000000	diff=3.39965e-11
  0.000000	  0.000000	diff=1.61464e-13
  0.000000	  0.000000	diff=1.23617e-12
 -0.000000	 -0.000000	diff=1.16557e-12
  0.000000	  0.000000	diff=7.19144e-14
 -0.000000	 -0.000000	diff=1.91719e-13
  0.000000	  0.000000	diff=6.88723e-13
 -0.000000	 -0.000000	diff=5.5722e-13
 -0.000000	 -0.000000	diff=1.54688e-12
  0.000000	  0.000000	diff=7.10183e-10
  local_diff=1.09155e-09
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=1.01821e-12
 -0.000000	 -0.000000	diff=6.50681e-13
 -0.000000	 -0.000000	diff=1.2041e-12
 -0.000000	 -0.000000	diff=8.4822e-13
 -0.000000	 -0.000000	diff=1.38325e-12
 -0.000000	 -0.000000	diff=1.30917e-12
 -0.000000	 -0.000000	diff=4.30846e-13
 -0.000014	 -0.000014	diff=3.89942e-11
 -0.000000	 -0.000000	diff=9.60195e-13
 -0.000000	 -0.000000	diff=5.37241e-13
 -0.000000	 -0.000000	diff=8.03003e-13
  0.000000	  0.000000	diff=8.80959e-13
 -0.000000	 -0.000000	diff=6.68635e-14
 -0.000000	 -0.000000	diff=4.83283e-14
 -0.000000	 -0.000000	diff=5.51043e-13
 -0.000014	 -0.000014	diff=1.42579e-10
  0.000000	  0.000000	diff=8.54673e-14
  0.000000	  0.000000	diff=4.88508e-13
 -0.000000	  0.000000	diff=8.53057e-13
 -0.000000	 -0.000000	diff=9.19855e-14
 -0.000000	  0.000000	diff=9.28763e-13
  0.000000	  0.000000	diff=1.27981e-13
  0.000000	  0.000000	diff=4.64611e-12
  0.000000	  0.000000	diff=3.90588e-12
 -0.000000	 -0.000000	diff=6.47705e-13
 -0.000000	 -0.000000	diff=4.77247e-13
 -0.000000	 -0.000000	diff=6.49188e-13
  0.000000	  0.000000	diff=9.3183e-13
 -0.000000	 -0.000000	diff=5.2309e-13
  0.000000	  0.000000	diff=2.73283e-13
  0.000000	  0.000000	diff=1.45438e-12
  0.000000	  0.000000	diff=3.85074e-10
  local_diff=5.93424e-10
# W_emb_src, [2 4]
  0.000004	  0.000004	diff=1.45314e-09
 -0.000001	 -0.000001	diff=1.315e-09
  0.000001	  0.000001	diff=7.72613e-10
  0.000001	  0.000001	diff=8.84382e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=4.42513e-09
# W_emb_tgt, [2 4]
  0.000006	  0.000006	diff=2.35617e-09
 -0.000000	 -0.000000	diff=1.2321e-10
  0.000008	  0.000008	diff=1.84118e-09
 -0.000001	 -0.000001	diff=2.19218e-10
  0.000015	  0.000014	diff=2.75965e-09
 -0.000001	 -0.000001	diff=3.27809e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=7.62724e-09
# W_h, [2 4]
  0.000005	  0.000005	diff=9.68785e-13
  0.000000	  0.000000	diff=4.645e-13
 -0.000007	 -0.000007	diff=4.92434e-13
 -0.000001	 -0.000001	diff=1.34432e-12
  0.000004	  0.000004	diff=9.50942e-12
  0.000008	  0.000008	diff=5.67737e-14
  0.000015	  0.000015	diff=1.24254e-10
 -0.000001	 -0.000001	diff=1.47555e-11
  local_diff=1.51846e-10
# W_soft, [4 2]
 -0.000002	 -0.000002	diff=1.20095e-12
 -0.000012	 -0.000012	diff=7.36002e-13
  0.000013	  0.000013	diff=1.39403e-12
  0.000001	  0.000001	diff=9.32272e-13
 -0.000002	 -0.000002	diff=4.28245e-13
 -0.000013	 -0.000013	diff=1.09766e-12
  0.000014	  0.000014	diff=1.02683e-12
  0.000001	  0.000001	diff=9.99976e-13
  local_diff=7.81597e-12
# Num params=176, abs_diff=1.43072e-08
Elapsed time is 2.186268 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 2, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 176, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_h=8 W_soft=8
# assert = 0
# attnFunc = 2
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 176
  src input 1: <s_sos> y x x
  src mask: 0  1  1  1
  tgt input 1: <t_sos> a b <t_eos> <t_eos>
  tgt output 1: a b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=5.62369e-13
  0.000000	  0.000000	diff=2.59853e-13
 -0.000000	 -0.000000	diff=5.15874e-14
  0.000000	  0.000000	diff=6.89048e-13
 -0.000000	 -0.000000	diff=7.07253e-14
 -0.000000	 -0.000000	diff=7.2385e-13
 -0.000001	 -0.000001	diff=4.5385e-11
 -0.000004	 -0.000004	diff=2.13138e-11
 -0.000000	 -0.000000	diff=2.1711e-13
  0.000000	  0.000000	diff=3.38922e-13
 -0.000000	 -0.000000	diff=2.96359e-13
  0.000000	  0.000000	diff=6.27411e-13
 -0.000000	 -0.000000	diff=4.12303e-13
 -0.000000	 -0.000000	diff=8.40943e-13
 -0.000002	 -0.000002	diff=4.27925e-11
 -0.000004	 -0.000004	diff=2.1136e-11
  0.000000	  0.000000	diff=9.83086e-14
  0.000000	  0.000000	diff=3.96143e-13
 -0.000000	 -0.000000	diff=5.16742e-13
  0.000000	  0.000000	diff=5.74833e-13
 -0.000000	 -0.000000	diff=4.06092e-13
 -0.000000	 -0.000000	diff=5.869e-13
 -0.000000	 -0.000000	diff=5.02534e-11
 -0.000000	 -0.000000	diff=1.17393e-13
 -0.000000	 -0.000000	diff=3.6641e-13
 -0.000000	 -0.000000	diff=2.77611e-13
  0.000000	  0.000000	diff=5.27066e-14
 -0.000000	 -0.000000	diff=1.51412e-13
  0.000000	  0.000000	diff=4.0704e-13
  0.000000	  0.000000	diff=1.32766e-13
  0.000000	  0.000000	diff=1.75955e-13
  0.000000	  0.000000	diff=1.36617e-10
  local_diff=3.26848e-10
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=2.84328e-13
  0.000000	  0.000000	diff=7.14954e-13
 -0.000000	 -0.000000	diff=2.1242e-16
 -0.000000	 -0.000000	diff=1.26179e-13
 -0.000000	 -0.000000	diff=2.05754e-13
  0.000000	  0.000000	diff=1.17307e-13
  0.000000	  0.000000	diff=2.22788e-13
  0.000001	  0.000001	diff=3.13879e-13
  0.000000	  0.000000	diff=4.76127e-13
  0.000000	  0.000000	diff=3.58645e-13
  0.000000	  0.000000	diff=3.45693e-13
  0.000000	  0.000000	diff=7.24668e-13
  0.000000	  0.000000	diff=3.52831e-13
 -0.000000	 -0.000000	diff=3.51834e-13
  0.000001	  0.000001	diff=9.49921e-13
 -0.000000	 -0.000000	diff=2.40631e-12
  0.000000	 -0.000000	diff=1.8002e-13
 -0.000000	 -0.000000	diff=6.40971e-13
  0.000000	 -0.000000	diff=3.00742e-13
 -0.000000	 -0.000000	diff=4.52848e-13
  0.000000	 -0.000000	diff=4.09249e-13
  0.000000	  0.000000	diff=6.54771e-13
 -0.000000	 -0.000000	diff=1.26143e-11
  0.000000	  0.000000	diff=3.67622e-13
  0.000000	  0.000000	diff=2.54162e-13
  0.000000	  0.000000	diff=2.93866e-13
  0.000000	  0.000000	diff=4.15271e-13
  0.000000	  0.000000	diff=1.95942e-13
  0.000000	  0.000000	diff=1.36694e-13
 -0.000000	 -0.000000	diff=6.43794e-13
  0.000000	  0.000000	diff=1.395e-13
 -0.000000	 -0.000000	diff=6.44132e-11
  local_diff=9.00644e-11
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=3.24477e-13
  0.000000	  0.000000	diff=5.57438e-13
 -0.000000	 -0.000000	diff=2.48114e-14
  0.000000	  0.000000	diff=6.40747e-13
 -0.000000	 -0.000000	diff=4.28148e-13
  0.000000	  0.000000	diff=9.35483e-13
  0.000001	  0.000001	diff=9.89978e-12
 -0.000013	 -0.000013	diff=9.46878e-11
  0.000000	  0.000000	diff=5.91866e-13
 -0.000000	 -0.000000	diff=5.68425e-13
 -0.000000	 -0.000000	diff=2.45068e-13
 -0.000000	 -0.000000	diff=2.74562e-13
  0.000000	  0.000000	diff=2.71175e-13
 -0.000000	 -0.000000	diff=5.35328e-13
 -0.000001	 -0.000001	diff=1.28552e-11
  0.000021	  0.000021	diff=2.07837e-10
  0.000000	  0.000000	diff=1.02558e-14
  0.000000	 -0.000000	diff=7.95292e-13
  0.000000	 -0.000000	diff=7.18824e-13
  0.000000	  0.000000	diff=8.1847e-13
  0.000000	  0.000000	diff=3.77913e-15
  0.000000	  0.000000	diff=3.98826e-13
  0.000000	  0.000000	diff=1.48621e-13
 -0.000000	 -0.000000	diff=5.62234e-13
  0.000000	  0.000000	diff=1.30619e-14
  0.000000	 -0.000000	diff=7.2159e-14
  0.000000	 -0.000000	diff=7.1696e-13
  0.000000	  0.000000	diff=2.1459e-13
  0.000000	  0.000000	diff=7.66621e-15
  0.000000	  0.000000	diff=2.51183e-13
  0.000000	  0.000000	diff=4.06619e-13
 -0.000000	 -0.000000	diff=2.78342e-13
  0.000000	  0.000000	diff=1.51056e-13
  0.000000	  0.000000	diff=5.54463e-13
  0.000000	  0.000000	diff=2.85848e-13
 -0.000000	 -0.000000	diff=3.0164e-13
  0.000000	  0.000000	diff=6.31211e-13
  0.000000	  0.000000	diff=7.21441e-13
 -0.000000	 -0.000000	diff=3.25798e-11
  0.000000	  0.000000	diff=3.68532e-13
  0.000000	  0.000000	diff=8.95557e-13
 -0.000000	 -0.000000	diff=9.69013e-13
  0.000000	  0.000000	diff=7.82427e-13
 -0.000000	 -0.000000	diff=5.20629e-13
  0.000000	  0.000000	diff=2.19318e-14
 -0.000000	 -0.000000	diff=8.67073e-13
 -0.000000	 -0.000000	diff=1.40474e-13
  0.000000	  0.000000	diff=7.1231e-10
  local_diff=1.08819e-09
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=3.07694e-13
 -0.000000	 -0.000000	diff=6.49701e-13
 -0.000000	 -0.000000	diff=2.1697e-13
 -0.000000	 -0.000000	diff=1.37275e-13
 -0.000000	 -0.000000	diff=3.77988e-14
 -0.000000	 -0.000000	diff=1.1278e-13
 -0.000000	 -0.000000	diff=5.12617e-14
 -0.000014	 -0.000014	diff=3.92854e-11
 -0.000000	 -0.000000	diff=4.60903e-13
 -0.000000	 -0.000000	diff=5.33072e-13
 -0.000000	 -0.000000	diff=9.2447e-14
  0.000000	  0.000000	diff=1.68193e-13
 -0.000000	 -0.000000	diff=6.68503e-14
 -0.000000	 -0.000000	diff=5.23682e-14
 -0.000000	 -0.000000	diff=1.74409e-13
 -0.000014	 -0.000014	diff=1.42862e-10
  0.000000	  0.000000	diff=8.54672e-14
  0.000000	  0.000000	diff=2.22001e-13
  0.000000	  0.000000	diff=1.42514e-13
 -0.000000	 -0.000000	diff=9.20039e-14
  0.000000	  0.000000	diff=4.92323e-13
  0.000000	  0.000000	diff=1.28015e-13
  0.000000	  0.000000	diff=5.35619e-12
  0.000000	  0.000000	diff=3.24924e-12
  0.000000	 -0.000000	diff=6.2837e-14
 -0.000000	 -0.000000	diff=2.33205e-13
  0.000000	 -0.000000	diff=6.13541e-14
  0.000000	  0.000000	diff=2.21361e-13
  0.000000	 -0.000000	diff=1.87453e-13
  0.000000	  0.000000	diff=2.73396e-13
  0.000000	  0.000000	diff=7.62869e-13
  0.000000	  0.000000	diff=3.85073e-10
  local_diff=5.81852e-10
# W_emb_src, [2 4]
  0.000001	  0.000001	diff=1.56103e-10
  0.000003	  0.000003	diff=2.01394e-09
 -0.000001	 -0.000001	diff=3.5835e-10
  0.000002	  0.000002	diff=1.40578e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=2.66897e-09
# W_emb_tgt, [2 4]
  0.000006	  0.000006	diff=2.35652e-09
 -0.000000	 -0.000000	diff=1.21816e-10
  0.000008	  0.000008	diff=1.84249e-09
 -0.000001	 -0.000001	diff=2.19207e-10
  0.000015	  0.000014	diff=2.7622e-09
 -0.000001	 -0.000001	diff=3.26376e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=7.62861e-09
# W_h, [2 4]
  0.000006	  0.000006	diff=9.67893e-13
 -0.000001	 -0.000001	diff=1.51365e-13
 -0.000008	 -0.000008	diff=2.76346e-13
 -0.000000	 -0.000000	diff=4.44339e-13
  0.000004	  0.000004	diff=1.00331e-11
  0.000008	  0.000008	diff=9.67137e-13
  0.000015	  0.000015	diff=1.25062e-10
 -0.000001	 -0.000001	diff=1.32985e-11
  local_diff=1.512e-10
# W_soft, [4 2]
 -0.000002	 -0.000002	diff=3.68239e-13
 -0.000012	 -0.000012	diff=4.11355e-13
  0.000013	  0.000013	diff=2.27869e-13
  0.000001	  0.000001	diff=4.39558e-13
 -0.000002	 -0.000002	diff=6.19585e-13
 -0.000013	 -0.000013	diff=4.4984e-13
  0.000014	  0.000014	diff=6.23031e-13
  0.000001	  0.000001	diff=4.39172e-13
  local_diff=3.57865e-12
# Num params=176, abs_diff=1.25393e-08
Elapsed time is 2.359097 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 4, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_pos=4 v_pos=2 W_h=8 W_soft=8
# assert = 0
# attnFunc = 4
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# distSigma = 0.5
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <t_sos> a b <t_eos> <t_eos>
  tgt output 1: a b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=6.44272e-14
  0.000000	  0.000000	diff=1.02416e-12
  0.000000	  0.000000	diff=2.2908e-13
  0.000000	  0.000000	diff=8.97627e-13
  0.000000	  0.000000	diff=6.51753e-14
 -0.000000	 -0.000000	diff=1.16031e-13
 -0.000004	 -0.000004	diff=1.48283e-11
 -0.000003	 -0.000003	diff=1.51039e-11
 -0.000000	 -0.000000	diff=3.89788e-13
  0.000000	  0.000000	diff=1.03058e-12
 -0.000000	 -0.000000	diff=8.02751e-13
  0.000000	  0.000000	diff=7.58505e-14
 -0.000000	 -0.000000	diff=3.38087e-13
 -0.000000	 -0.000000	diff=2.97698e-13
 -0.000001	 -0.000001	diff=1.77014e-11
 -0.000002	 -0.000002	diff=1.89173e-11
 -0.000000	 -0.000000	diff=1.02997e-13
  0.000000	  0.000000	diff=3.64311e-13
 -0.000000	 -0.000000	diff=1.20766e-12
  0.000000	  0.000000	diff=3.0214e-13
 -0.000000	 -0.000000	diff=2.47426e-13
 -0.000000	 -0.000000	diff=9.18021e-15
  0.000000	  0.000000	diff=6.44907e-11
 -0.000000	 -0.000000	diff=4.97002e-14
  0.000000	  0.000000	diff=7.91501e-13
 -0.000000	 -0.000000	diff=9.75185e-14
  0.000000	  0.000000	diff=2.69571e-13
 -0.000000	 -0.000000	diff=1.31402e-13
  0.000000	  0.000000	diff=5.04838e-14
  0.000000	  0.000000	diff=2.66957e-13
  0.000000	  0.000000	diff=1.54193e-12
  0.000000	  0.000000	diff=5.88331e-11
  local_diff=2.00639e-10
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=1.47042e-13
 -0.000000	 -0.000000	diff=1.20294e-12
 -0.000000	 -0.000000	diff=8.07364e-14
 -0.000000	 -0.000000	diff=4.87028e-13
  0.000000	  0.000000	diff=1.57975e-13
  0.000000	  0.000000	diff=1.05405e-14
  0.000000	  0.000000	diff=3.5021e-13
 -0.000001	 -0.000001	diff=3.49093e-13
  0.000000	  0.000000	diff=5.38857e-13
  0.000000	  0.000000	diff=5.54582e-13
  0.000000	  0.000000	diff=3.85126e-13
  0.000000	  0.000000	diff=1.47913e-13
 -0.000000	 -0.000000	diff=5.56191e-13
 -0.000000	 -0.000000	diff=2.02898e-13
  0.000002	  0.000002	diff=9.04053e-13
 -0.000001	 -0.000001	diff=5.45916e-13
 -0.000000	 -0.000000	diff=2.17541e-13
 -0.000000	 -0.000000	diff=6.7117e-13
  0.000000	 -0.000000	diff=1.00134e-13
 -0.000000	 -0.000000	diff=1.15063e-14
  0.000000	  0.000000	diff=2.82248e-13
  0.000000	 -0.000000	diff=3.29927e-15
  0.000000	  0.000000	diff=2.96493e-11
 -0.000000	 -0.000000	diff=2.10447e-13
  0.000000	  0.000000	diff=6.19059e-13
  0.000000	  0.000000	diff=1.13868e-12
  0.000000	  0.000000	diff=8.44179e-14
  0.000000	  0.000000	diff=2.00724e-13
 -0.000000	 -0.000000	diff=3.6294e-13
  0.000000	  0.000000	diff=3.74066e-16
 -0.000000	 -0.000000	diff=3.79962e-13
 -0.000000	 -0.000000	diff=2.20997e-11
  local_diff=6.26526e-11
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=3.32934e-13
  0.000000	  0.000000	diff=4.79802e-14
  0.000000	  0.000000	diff=2.53023e-13
 -0.000000	 -0.000000	diff=1.08423e-12
 -0.000000	 -0.000000	diff=9.2899e-13
  0.000000	  0.000000	diff=7.95067e-13
  0.000000	  0.000000	diff=2.5483e-11
 -0.000008	 -0.000008	diff=7.49062e-11
  0.000000	  0.000000	diff=2.22119e-13
 -0.000000	 -0.000000	diff=8.18772e-13
 -0.000000	 -0.000000	diff=7.04146e-13
 -0.000000	 -0.000000	diff=5.63989e-13
  0.000000	  0.000000	diff=1.48525e-13
 -0.000000	 -0.000000	diff=3.11159e-13
 -0.000000	 -0.000000	diff=5.77712e-11
  0.000041	  0.000041	diff=1.49342e-10
  0.000000	 -0.000000	diff=3.16848e-14
  0.000000	  0.000000	diff=5.24262e-14
  0.000000	 -0.000000	diff=4.03547e-15
  0.000000	 -0.000000	diff=1.43837e-13
  0.000000	 -0.000000	diff=3.3405e-14
  0.000000	 -0.000000	diff=5.51597e-14
  0.000000	  0.000000	diff=3.57559e-13
  0.000000	  0.000000	diff=6.9115e-13
  0.000000	  0.000000	diff=8.34101e-14
  0.000000	 -0.000000	diff=2.36541e-13
  0.000000	 -0.000000	diff=1.2402e-14
  0.000000	  0.000000	diff=5.08786e-13
  0.000000	  0.000000	diff=8.30965e-14
  0.000000	  0.000000	diff=3.82183e-13
  0.000000	  0.000000	diff=1.88422e-14
 -0.000000	 -0.000000	diff=4.62289e-13
 -0.000000	 -0.000000	diff=3.4158e-14
 -0.000000	 -0.000000	diff=2.09745e-13
 -0.000000	 -0.000000	diff=4.42826e-13
  0.000000	  0.000000	diff=5.83786e-14
 -0.000000	 -0.000000	diff=1.00868e-13
  0.000000	  0.000000	diff=1.54389e-13
  0.000000	  0.000000	diff=3.40559e-11
 -0.000000	 -0.000000	diff=1.77019e-13
 -0.000000	 -0.000000	diff=3.27477e-13
  0.000000	  0.000000	diff=1.93707e-13
 -0.000000	 -0.000000	diff=3.009e-13
 -0.000000	 -0.000000	diff=4.06483e-13
 -0.000000	 -0.000000	diff=3.65526e-13
 -0.000000	 -0.000000	diff=8.66272e-14
 -0.000000	 -0.000000	diff=2.46564e-14
  0.000000	  0.000000	diff=6.58084e-10
  local_diff=1.01189e-09
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=7.49522e-13
 -0.000000	 -0.000000	diff=4.10851e-13
 -0.000000	 -0.000000	diff=1.10038e-14
 -0.000000	 -0.000000	diff=1.16023e-14
 -0.000000	 -0.000000	diff=5.30018e-13
 -0.000000	 -0.000000	diff=9.34488e-13
  0.000000	  0.000000	diff=2.08652e-12
 -0.000004	 -0.000004	diff=8.61725e-12
  0.000000	  0.000000	diff=9.71259e-13
 -0.000000	 -0.000000	diff=8.5675e-13
  0.000000	  0.000000	diff=3.5256e-13
 -0.000000	 -0.000000	diff=2.21227e-13
  0.000000	  0.000000	diff=4.42115e-13
 -0.000000	 -0.000000	diff=2.23452e-13
  0.000002	  0.000002	diff=3.85626e-13
 -0.000011	 -0.000011	diff=5.47745e-11
  0.000000	  0.000000	diff=4.09992e-14
  0.000000	  0.000000	diff=3.18213e-13
 -0.000000	 -0.000000	diff=1.96767e-13
 -0.000000	 -0.000000	diff=8.34267e-14
 -0.000000	 -0.000000	diff=2.9962e-13
 -0.000000	 -0.000000	diff=4.61601e-13
  0.000000	  0.000000	diff=6.75137e-11
  0.000000	  0.000000	diff=5.61272e-13
  0.000000	  0.000000	diff=4.76638e-13
  0.000000	  0.000000	diff=6.00806e-14
  0.000000	  0.000000	diff=1.69292e-13
  0.000000	  0.000000	diff=6.95861e-13
  0.000000	  0.000000	diff=2.4962e-13
  0.000000	  0.000000	diff=2.62333e-13
 -0.000000	 -0.000000	diff=2.88627e-13
  0.000000	  0.000000	diff=3.96165e-10
  local_diff=5.39422e-10
# W_emb_src, [2 4]
  0.000003	  0.000003	diff=6.80994e-10
  0.000002	  0.000002	diff=1.5191e-09
  0.000002	  0.000002	diff=6.28532e-10
  0.000004	  0.000004	diff=1.6561e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=4.48473e-09
# W_emb_tgt, [2 4]
  0.000009	  0.000009	diff=1.19458e-10
 -0.000000	 -0.000000	diff=6.05161e-10
  0.000009	  0.000009	diff=2.55759e-09
 -0.000001	 -0.000001	diff=7.08421e-10
  0.000009	  0.000009	diff=3.47903e-09
 -0.000002	 -0.000002	diff=8.5347e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=8.32313e-09
# W_pos, [2 2]
  0.000000	  0.000000	diff=4.37313e-16
  0.000000	  0.000000	diff=5.53617e-16
  0.000000	  0.000000	diff=2.66128e-15
  0.000000	  0.000000	diff=3.36906e-15
  local_diff=7.02127e-15
# v_pos, [1 2]
  0.000000	 -0.000000	diff=1.73235e-14
  0.000000	 -0.000000	diff=6.38654e-14
  local_diff=8.11889e-14
# W_h, [2 4]
  0.000000	  0.000000	diff=3.0718e-13
 -0.000001	 -0.000001	diff=1.12553e-13
  0.000000	  0.000000	diff=5.68507e-13
 -0.000000	 -0.000000	diff=1.31589e-13
  0.000000	  0.000000	diff=4.48427e-13
  0.000002	  0.000002	diff=4.21145e-12
 -0.000003	 -0.000003	diff=2.76779e-12
  0.000009	  0.000009	diff=7.31231e-11
  local_diff=8.16706e-11
# W_soft, [4 2]
  0.000003	  0.000003	diff=1.31571e-13
  0.000001	  0.000001	diff=7.45913e-13
 -0.000004	 -0.000004	diff=6.78445e-13
  0.000000	  0.000000	diff=5.757e-13
 -0.000009	 -0.000009	diff=6.33644e-13
 -0.000010	 -0.000010	diff=2.60443e-13
  0.000018	  0.000018	diff=3.0242e-13
  0.000000	  0.000000	diff=6.75622e-13
  local_diff=4.00376e-12
# Num params=182, abs_diff=1.47082e-08
Elapsed time is 2.949826 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 180, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 180
  src input 1: <s_sos> <s_sos> x y
  src mask: 0  0  1  1
  tgt input 1: <t_sos> a <t_eos> <t_eos> <t_eos>
  tgt output 1: a <t_eos> <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  0  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=7.29981e-14
  0.000000	  0.000000	diff=3.45351e-13
  0.000000	  0.000000	diff=5.41757e-13
  0.000000	  0.000000	diff=9.39996e-14
  0.000000	  0.000000	diff=9.4185e-13
  0.000000	  0.000000	diff=2.43581e-13
 -0.000002	 -0.000002	diff=3.20165e-12
 -0.000002	 -0.000002	diff=5.97279e-12
  0.000000	  0.000000	diff=4.52683e-13
  0.000000	  0.000000	diff=2.52471e-13
  0.000000	  0.000000	diff=3.25591e-13
  0.000000	  0.000000	diff=6.95659e-13
  0.000000	  0.000000	diff=2.07537e-13
 -0.000000	 -0.000000	diff=3.04882e-13
  0.000001	  0.000001	diff=3.10857e-12
 -0.000002	 -0.000002	diff=2.77414e-11
 -0.000000	 -0.000000	diff=4.24606e-13
  0.000000	  0.000000	diff=7.13472e-13
 -0.000000	 -0.000000	diff=9.89182e-13
  0.000000	  0.000000	diff=3.03353e-13
 -0.000000	 -0.000000	diff=3.39481e-13
 -0.000000	 -0.000000	diff=3.60347e-13
  0.000000	  0.000000	diff=4.42298e-11
 -0.000000	 -0.000000	diff=2.90594e-13
  0.000000	  0.000000	diff=9.48051e-13
 -0.000000	 -0.000000	diff=2.04795e-13
 -0.000000	 -0.000000	diff=1.46339e-13
 -0.000000	 -0.000000	diff=4.19684e-14
  0.000000	  0.000000	diff=3.4646e-13
  0.000000	  0.000000	diff=1.58848e-13
 -0.000000	 -0.000000	diff=2.83335e-13
  0.000000	  0.000000	diff=2.91963e-11
  local_diff=1.2348e-10
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=1.07742e-13
 -0.000000	 -0.000000	diff=3.94974e-14
  0.000000	  0.000000	diff=5.38294e-13
 -0.000000	 -0.000000	diff=1.46931e-13
 -0.000000	 -0.000000	diff=1.4868e-13
 -0.000000	 -0.000000	diff=4.34942e-13
 -0.000001	 -0.000001	diff=7.51768e-14
 -0.000002	 -0.000002	diff=3.59746e-13
 -0.000000	 -0.000000	diff=3.5121e-13
  0.000000	  0.000000	diff=4.66605e-13
 -0.000000	 -0.000000	diff=5.01531e-13
  0.000000	  0.000000	diff=3.82771e-13
  0.000000	  0.000000	diff=1.43889e-13
  0.000000	  0.000000	diff=6.47665e-13
 -0.000003	 -0.000003	diff=1.13245e-12
 -0.000006	 -0.000006	diff=1.69432e-12
  0.000000	  0.000000	diff=3.76857e-13
 -0.000000	 -0.000000	diff=4.39274e-13
  0.000000	  0.000000	diff=2.44728e-13
  0.000000	 -0.000000	diff=1.58245e-13
  0.000000	 -0.000000	diff=1.94575e-14
  0.000000	 -0.000000	diff=3.83298e-13
 -0.000000	 -0.000000	diff=9.19485e-12
 -0.000000	 -0.000000	diff=2.37913e-13
  0.000000	 -0.000000	diff=3.83684e-13
  0.000000	  0.000000	diff=5.83449e-14
  0.000000	 -0.000000	diff=3.05945e-13
  0.000000	  0.000000	diff=1.95741e-13
  0.000000	  0.000000	diff=2.44279e-14
  0.000000	  0.000000	diff=4.7357e-13
 -0.000000	 -0.000000	diff=3.77879e-13
  0.000000	  0.000000	diff=7.06789e-11
  local_diff=9.07246e-11
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=7.25756e-13
  0.000000	  0.000000	diff=2.95402e-13
  0.000000	  0.000000	diff=4.29085e-13
 -0.000000	 -0.000000	diff=1.2439e-12
  0.000000	  0.000000	diff=4.97173e-13
  0.000000	  0.000000	diff=2.70681e-13
 -0.000002	 -0.000002	diff=1.31413e-11
 -0.000003	 -0.000003	diff=3.3357e-11
 -0.000000	 -0.000000	diff=1.94969e-13
 -0.000000	 -0.000000	diff=3.92032e-13
 -0.000000	 -0.000000	diff=6.05502e-13
 -0.000000	 -0.000000	diff=2.63428e-13
 -0.000000	 -0.000000	diff=5.99105e-13
 -0.000000	 -0.000000	diff=2.97478e-14
  0.000004	  0.000004	diff=5.52557e-11
  0.000043	  0.000043	diff=5.96793e-11
  0.000000	 -0.000000	diff=4.21896e-14
  0.000000	 -0.000000	diff=3.44054e-13
  0.000000	  0.000000	diff=6.08105e-14
  0.000000	  0.000000	diff=1.44592e-13
  0.000000	  0.000000	diff=3.20568e-15
  0.000000	 -0.000000	diff=4.65181e-14
 -0.000000	 -0.000000	diff=3.56732e-13
 -0.000000	 -0.000000	diff=8.74018e-14
  0.000000	 -0.000000	diff=1.21114e-15
  0.000000	  0.000000	diff=2.05701e-14
  0.000000	  0.000000	diff=8.50198e-15
  0.000000	 -0.000000	diff=2.20437e-14
  0.000000	  0.000000	diff=4.26017e-15
  0.000000	 -0.000000	diff=5.42772e-15
 -0.000000	 -0.000000	diff=4.17933e-14
  0.000000	  0.000000	diff=5.51945e-13
 -0.000000	 -0.000000	diff=2.195e-13
  0.000000	  0.000000	diff=8.72408e-13
 -0.000000	 -0.000000	diff=6.26744e-13
  0.000000	  0.000000	diff=1.15647e-13
 -0.000000	 -0.000000	diff=1.69409e-13
  0.000000	  0.000000	diff=1.5442e-13
  0.000000	  0.000000	diff=6.81612e-11
 -0.000000	 -0.000000	diff=4.61665e-12
  0.000000	  0.000000	diff=9.02058e-14
  0.000000	  0.000000	diff=3.18037e-13
 -0.000000	 -0.000000	diff=2.77071e-14
 -0.000000	 -0.000000	diff=4.55328e-13
  0.000000	  0.000000	diff=2.19831e-13
 -0.000000	 -0.000000	diff=6.65442e-13
  0.000000	  0.000000	diff=3.27213e-13
  0.000000	  0.000000	diff=7.18662e-10
  local_diff=9.64423e-10
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=2.6482e-13
 -0.000000	 -0.000000	diff=4.81619e-14
  0.000000	  0.000000	diff=3.3018e-13
 -0.000000	 -0.000000	diff=5.90227e-13
 -0.000000	 -0.000000	diff=6.47074e-13
  0.000000	  0.000000	diff=6.33284e-14
 -0.000003	 -0.000003	diff=1.54394e-13
 -0.000004	 -0.000004	diff=6.06883e-12
 -0.000000	 -0.000000	diff=7.80614e-13
 -0.000000	 -0.000000	diff=3.83745e-13
 -0.000000	 -0.000000	diff=3.75541e-13
  0.000000	  0.000000	diff=6.19586e-13
 -0.000000	 -0.000000	diff=1.63401e-13
  0.000000	  0.000000	diff=5.78669e-13
 -0.000007	 -0.000007	diff=4.53918e-12
 -0.000006	 -0.000006	diff=7.48942e-11
 -0.000000	 -0.000000	diff=1.59301e-13
  0.000000	  0.000000	diff=9.76222e-14
  0.000000	  0.000000	diff=1.11042e-13
  0.000000	  0.000000	diff=3.94753e-14
  0.000000	  0.000000	diff=4.64388e-13
  0.000000	  0.000000	diff=7.99365e-13
  0.000000	  0.000000	diff=2.54616e-11
  0.000000	  0.000000	diff=6.96546e-13
  0.000000	  0.000000	diff=5.95319e-13
 -0.000000	 -0.000000	diff=7.95734e-13
 -0.000000	 -0.000000	diff=6.07923e-13
  0.000000	  0.000000	diff=5.00202e-13
 -0.000000	 -0.000000	diff=2.03692e-13
  0.000000	  0.000000	diff=6.6742e-13
  0.000000	  0.000000	diff=4.67468e-13
  0.000000	  0.000000	diff=5.11352e-10
  local_diff=6.33521e-10
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=3.35599e-10
  0.000006	  0.000006	diff=4.557e-09
  0.000002	  0.000002	diff=6.47648e-10
  0.000007	  0.000007	diff=5.6199e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.11601e-08
# W_emb_tgt, [2 4]
  0.000005	  0.000005	diff=1.31678e-09
 -0.000000	 -0.000000	diff=3.49627e-10
  0.000014	  0.000014	diff=2.00779e-10
  0.000000	  0.000000	diff=6.55954e-10
  0.000010	  0.000010	diff=8.88435e-10
  0.000000	  0.000000	diff=8.84384e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=4.29596e-09
# W_a, [2 2]
  0.000000	  0.000000	diff=7.47855e-18
  0.000000	 -0.000000	diff=1.13606e-17
  0.000000	  0.000000	diff=6.10241e-17
  0.000000	 -0.000000	diff=7.40864e-17
  local_diff=1.5395e-16
# W_h, [2 4]
 -0.000001	 -0.000001	diff=4.01148e-13
 -0.000000	 -0.000000	diff=6.02068e-13
 -0.000001	 -0.000001	diff=7.16567e-13
  0.000002	  0.000002	diff=2.30846e-13
  0.000002	  0.000002	diff=4.09431e-12
 -0.000003	 -0.000003	diff=1.81413e-13
  0.000008	  0.000008	diff=1.19995e-10
 -0.000013	 -0.000013	diff=2.44074e-11
  local_diff=1.50629e-10
# W_soft, [4 2]
 -0.000004	 -0.000004	diff=8.13512e-13
 -0.000005	 -0.000005	diff=2.98689e-13
  0.000011	  0.000011	diff=2.10296e-13
 -0.000002	 -0.000002	diff=6.11954e-13
  0.000000	  0.000000	diff=5.19165e-13
  0.000001	  0.000001	diff=1.9912e-13
 -0.000001	 -0.000001	diff=1.19276e-13
  0.000000	  0.000000	diff=1.27018e-13
  local_diff=2.89903e-12
# Num params=180, abs_diff=1.74218e-08
Elapsed time is 2.239840 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 3)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 v_a=2 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 3
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <t_sos> a b <t_eos> <t_eos>
  tgt output 1: a b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=8.00371e-13
  0.000000	  0.000000	diff=1.43985e-13
  0.000000	  0.000000	diff=4.10294e-13
  0.000000	  0.000000	diff=1.88997e-13
  0.000000	  0.000000	diff=8.69743e-13
  0.000000	  0.000000	diff=1.0275e-12
 -0.000001	 -0.000001	diff=3.66596e-13
 -0.000003	 -0.000003	diff=1.53492e-11
  0.000000	  0.000000	diff=2.40552e-13
  0.000000	  0.000000	diff=9.83197e-13
 -0.000000	 -0.000000	diff=1.72878e-13
  0.000000	  0.000000	diff=3.56062e-13
 -0.000000	 -0.000000	diff=3.61859e-13
 -0.000000	 -0.000000	diff=1.91999e-14
  0.000001	  0.000001	diff=2.19597e-13
 -0.000002	 -0.000002	diff=1.88039e-11
 -0.000000	 -0.000000	diff=5.07358e-13
  0.000000	  0.000000	diff=7.51131e-13
 -0.000000	 -0.000000	diff=5.19066e-13
  0.000000	  0.000000	diff=1.51849e-12
 -0.000000	 -0.000000	diff=7.52178e-14
 -0.000000	 -0.000000	diff=8.81454e-13
  0.000000	  0.000000	diff=4.5304e-11
 -0.000000	 -0.000000	diff=8.50707e-14
  0.000000	  0.000000	diff=2.33457e-13
 -0.000000	 -0.000000	diff=8.49771e-13
  0.000000	  0.000000	diff=4.61693e-13
 -0.000000	 -0.000000	diff=1.04128e-12
  0.000000	  0.000000	diff=3.9158e-13
  0.000000	  0.000000	diff=4.30975e-13
  0.000000	  0.000000	diff=6.16567e-13
  0.000000	  0.000000	diff=6.49217e-11
  local_diff=1.58903e-10
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=5.071e-13
 -0.000000	 -0.000000	diff=4.07919e-13
 -0.000000	 -0.000000	diff=1.04907e-12
 -0.000000	 -0.000000	diff=5.07713e-13
  0.000000	  0.000000	diff=7.45921e-13
  0.000000	  0.000000	diff=7.25016e-13
  0.000000	  0.000000	diff=9.21135e-13
 -0.000001	 -0.000001	diff=1.93758e-13
  0.000000	  0.000000	diff=9.22649e-13
  0.000000	  0.000000	diff=8.67573e-13
 -0.000000	 -0.000000	diff=5.99137e-13
  0.000000	  0.000000	diff=1.20439e-12
 -0.000000	 -0.000000	diff=9.27364e-13
 -0.000000	 -0.000000	diff=8.13359e-13
  0.000001	  0.000001	diff=5.48371e-14
 -0.000000	 -0.000000	diff=4.02649e-13
 -0.000000	 -0.000000	diff=4.77768e-13
 -0.000000	 -0.000000	diff=3.97787e-13
  0.000000	  0.000000	diff=3.08803e-13
 -0.000000	 -0.000000	diff=2.47615e-13
  0.000000	  0.000000	diff=7.50108e-13
  0.000000	  0.000000	diff=5.4724e-13
  0.000000	  0.000000	diff=3.15126e-11
 -0.000000	 -0.000000	diff=5.28326e-13
 -0.000000	  0.000000	diff=1.07904e-12
  0.000000	  0.000000	diff=5.04197e-14
 -0.000000	 -0.000000	diff=2.89711e-13
  0.000000	  0.000000	diff=1.15654e-13
 -0.000000	 -0.000000	diff=1.51795e-13
 -0.000000	 -0.000000	diff=3.69549e-14
 -0.000000	 -0.000000	diff=1.97857e-13
 -0.000000	 -0.000000	diff=9.51656e-12
  local_diff=5.70579e-11
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=3.72916e-13
  0.000000	  0.000000	diff=1.48819e-12
  0.000000	  0.000000	diff=1.17001e-12
 -0.000000	 -0.000000	diff=3.53712e-13
 -0.000000	 -0.000000	diff=1.20281e-12
  0.000000	  0.000000	diff=7.78511e-13
  0.000000	  0.000000	diff=2.4777e-11
 -0.000008	 -0.000008	diff=7.47682e-11
  0.000000	  0.000000	diff=1.19564e-12
 -0.000000	 -0.000000	diff=1.28021e-12
 -0.000000	 -0.000000	diff=7.02208e-13
 -0.000000	 -0.000000	diff=1.73267e-13
  0.000000	  0.000000	diff=1.55444e-13
 -0.000000	 -0.000000	diff=3.28682e-13
 -0.000000	 -0.000000	diff=5.63645e-11
  0.000041	  0.000041	diff=1.48848e-10
  0.000000	 -0.000000	diff=3.77001e-14
 -0.000000	  0.000000	diff=7.66416e-13
  0.000000	 -0.000000	diff=9.92387e-15
 -0.000000	 -0.000000	diff=5.78751e-13
  0.000000	 -0.000000	diff=4.31702e-14
 -0.000000	 -0.000000	diff=6.6024e-13
  0.000000	  0.000000	diff=9.50798e-13
  0.000000	  0.000000	diff=6.89826e-13
  0.000000	  0.000000	diff=7.08177e-14
 -0.000000	 -0.000000	diff=4.85478e-13
  0.000000	 -0.000000	diff=2.8444e-14
  0.000000	  0.000000	diff=9.91327e-13
  0.000000	  0.000000	diff=6.10445e-14
  0.000000	  0.000000	diff=4.2188e-13
  0.000000	  0.000000	diff=1.85049e-12
 -0.000000	 -0.000000	diff=5.69376e-13
 -0.000000	 -0.000000	diff=3.39459e-14
 -0.000000	 -0.000000	diff=1.63079e-12
 -0.000000	 -0.000000	diff=1.6889e-12
  0.000000	  0.000000	diff=6.51581e-13
 -0.000000	 -0.000000	diff=6.09973e-13
  0.000000	  0.000000	diff=1.54746e-13
  0.000000	  0.000000	diff=3.40403e-11
 -0.000000	 -0.000000	diff=1.38036e-12
 -0.000000	 -0.000000	diff=1.03812e-12
  0.000000	  0.000000	diff=9.01456e-13
 -0.000000	 -0.000000	diff=3.01136e-13
 -0.000000	 -0.000000	diff=3.01759e-13
 -0.000000	 -0.000000	diff=3.4535e-13
 -0.000000	 -0.000000	diff=7.93623e-13
 -0.000000	 -0.000000	diff=7.49234e-13
  0.000000	  0.000000	diff=6.57661e-10
  local_diff=1.02446e-09
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=7.49948e-13
 -0.000000	 -0.000000	diff=4.10872e-13
 -0.000000	 -0.000000	diff=1.41022e-12
 -0.000000	 -0.000000	diff=7.21463e-13
 -0.000000	 -0.000000	diff=8.91451e-13
 -0.000000	 -0.000000	diff=9.34527e-13
  0.000000	  0.000000	diff=1.05573e-12
 -0.000004	 -0.000004	diff=8.25052e-12
  0.000000	  0.000000	diff=9.70876e-13
 -0.000000	 -0.000000	diff=8.54024e-13
  0.000000	  0.000000	diff=3.57981e-13
 -0.000000	 -0.000000	diff=2.18301e-13
 -0.000000	  0.000000	diff=1.86272e-12
 -0.000000	 -0.000000	diff=9.314e-13
  0.000002	  0.000002	diff=4.95903e-13
 -0.000011	 -0.000011	diff=5.51055e-11
  0.000000	  0.000000	diff=4.10017e-14
  0.000000	  0.000000	diff=3.18259e-13
 -0.000000	 -0.000000	diff=1.96766e-13
 -0.000000	 -0.000000	diff=6.27138e-13
  0.000000	 -0.000000	diff=4.10928e-13
 -0.000000	 -0.000000	diff=4.6165e-13
  0.000000	  0.000000	diff=6.75847e-11
  0.000000	  0.000000	diff=6.33582e-14
  0.000000	  0.000000	diff=4.76642e-13
  0.000000	  0.000000	diff=6.01996e-14
  0.000000	  0.000000	diff=1.6929e-13
  0.000000	  0.000000	diff=6.9594e-13
  0.000000	  0.000000	diff=4.60919e-13
  0.000000	  0.000000	diff=9.73041e-13
 -0.000000	 -0.000000	diff=8.96045e-13
  0.000000	  0.000000	diff=3.95813e-10
  local_diff=5.4447e-10
# W_emb_src, [2 4]
 -0.000001	 -0.000001	diff=7.73459e-10
  0.000006	  0.000006	diff=4.81493e-09
  0.000001	  0.000001	diff=1.91402e-10
  0.000006	  0.000006	diff=3.37345e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=9.15323e-09
# W_emb_tgt, [2 4]
  0.000009	  0.000009	diff=1.18484e-10
 -0.000000	 -0.000000	diff=6.03698e-10
  0.000009	  0.000009	diff=2.55808e-09
 -0.000001	 -0.000001	diff=7.0913e-10
  0.000009	  0.000009	diff=3.4782e-09
 -0.000002	 -0.000002	diff=8.53459e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=8.32105e-09
# W_a, [2 2]
  0.000000	 -0.000000	diff=1.51558e-25
  0.000000	 -0.000000	diff=1.54981e-24
  0.000000	 -0.000000	diff=8.4392e-25
  0.000000	 -0.000000	diff=6.59622e-24
  local_diff=9.14151e-24
# v_a, [1 2]
  0.000000	  0.000000	diff=3.55298e-14
 -0.000000	 -0.000000	diff=4.0791e-13
  local_diff=4.4344e-13
# W_h, [2 4]
  0.000000	  0.000000	diff=1.27709e-12
 -0.000001	 -0.000001	diff=8.19788e-13
  0.000001	  0.000001	diff=5.57235e-13
 -0.000000	 -0.000000	diff=4.53928e-14
  0.000000	  0.000000	diff=7.46421e-13
  0.000002	  0.000002	diff=3.86453e-12
 -0.000003	 -0.000003	diff=3.73473e-12
  0.000009	  0.000009	diff=7.19565e-11
  local_diff=8.30017e-11
# W_soft, [4 2]
  0.000003	  0.000003	diff=3.07555e-13
  0.000001	  0.000001	diff=1.21206e-13
 -0.000004	 -0.000004	diff=1.20303e-12
  0.000000	  0.000000	diff=7.4225e-13
 -0.000009	 -0.000009	diff=2.68281e-13
 -0.000011	 -0.000011	diff=8.80558e-13
  0.000019	  0.000019	diff=4.68874e-13
  0.000001	  0.000001	diff=1.05048e-12
  local_diff=5.04223e-12
# Num params=182, abs_diff=1.93477e-08
Elapsed time is 2.203099 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 104, individual sizes:  W_src{1}=32 W_tgt{1}=48 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 1
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 104
  src input 1: y y x y
  src mask: 1  1  1  1
  tgt input 1: <t_sos> a b a
  tgt output 1: a b a <t_eos>
  tgt mask: 1  1  1  1
# W_src{1}, [8 4]
 -0.000013	 -0.000013	diff=4.63718e-07
  0.000001	  0.000001	diff=3.65501e-08
 -0.000932	 -0.000900	diff=3.1885e-05
  0.000000	  0.000000	diff=5.99269e-12
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000012	  0.000012	diff=3.89478e-07
 -0.000001	 -0.000001	diff=3.07312e-08
  0.000818	  0.000845	diff=2.66832e-05
 -0.000000	 -0.000000	diff=3.9331e-12
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000001	  0.000001	diff=5.53295e-09
 -0.000000	 -0.000000	diff=2.5681e-11
  0.000099	  0.000099	diff=3.74947e-07
 -0.000000	 -0.000000	diff=2.84401e-12
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000002	 -0.000002	diff=9.24172e-09
  0.000000	  0.000000	diff=2.51403e-11
 -0.000129	 -0.000129	diff=6.36201e-07
  0.000000	  0.000000	diff=2.67178e-12
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=6.05147e-05
# W_tgt{1}, [8 6]
 -0.063025	 -0.053372	diff=0.00965252
  0.000000	  0.000000	diff=1.28429e-08
  0.000000	 -0.000000	diff=1.50853e-15
 -0.000000	 -0.000000	diff=2.483e-12
-31.263908	-32.483123	diff=1.21921
 -0.010618	 -0.011040	diff=0.000421337
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.048896	  0.062674	diff=0.0137782
  0.000000	  0.000000	diff=1.72803e-08
  0.000000	  0.000000	diff=8.37179e-16
  0.000000	  0.000000	diff=9.17082e-13
 39.771604	 38.144140	diff=1.62746
  0.013573	  0.012957	diff=0.000615584
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.023973	  0.024038	diff=6.48058e-05
  0.000000	 -0.000000	diff=3.79277e-51
  0.000000	  0.000000	diff=4.41704e-17
  0.000000	 -0.000000	diff=2.09651e-15
 -0.685378	 -0.683481	diff=0.00189718
  0.000137	  0.000137	diff=1.83166e-07
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.019028	 -0.018988	diff=4.01812e-05
  0.000000	  0.000000	diff=2.58066e-51
  0.000000	 -0.000000	diff=4.51516e-20
  0.000000	  0.000000	diff=2.24548e-18
  0.554215	  0.555460	diff=0.00124536
  0.000000	  0.000000	diff=6.82596e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.023973	  0.024038	diff=6.48058e-05
  0.000000	  0.000000	diff=2.55251e-10
  0.000000	  0.000000	diff=4.41704e-17
  0.000000	 -0.000000	diff=2.09651e-15
 -0.685378	 -0.683481	diff=0.00189718
  0.000137	  0.000137	diff=1.83166e-07
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.019028	 -0.018988	diff=4.01812e-05
 -0.000000	 -0.000000	diff=2.87921e-10
  0.000000	 -0.000000	diff=4.51516e-20
  0.000000	  0.000000	diff=2.24548e-18
  0.554215	  0.555460	diff=0.00124536
  0.000000	  0.000000	diff=6.82596e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=2.87764
# W_emb_src, [2 4]
 -0.000003	 -0.000003	diff=1.14337e-07
 -0.000003	 -0.000003	diff=9.65271e-08
 -0.000990	 -0.000953	diff=3.72485e-05
 -0.000900	 -0.000869	diff=3.17681e-05
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=6.92275e-05
# W_emb_tgt, [2 4]
-27.956638	-28.915513	diff=0.958875
-24.302396	-25.019891	diff=0.717496
 -0.000005	 -0.000005	diff=1.23032e-07
 -0.000005	 -0.000005	diff=1.29694e-07
  0.000001	  0.000001	diff=2.66556e-08
 -0.000000	 -0.000000	diff=8.71782e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.67637
# W_soft, [4 2]
 -3.427182	 -3.427237	diff=5.54155e-05
 -2.145279	 -2.146908	diff=0.00162899
  0.126818	  0.126673	diff=0.000145468
  5.449159	  5.447473	diff=0.00168599
  2.285337	  2.285337	diff=3.86105e-08
  1.413201	  1.412786	diff=0.000414105
 -0.000600	 -0.000601	diff=1.90223e-06
 -3.697104	 -3.697522	diff=0.000418031
  local_diff=0.00434995
# Num params=104, abs_diff=4.55849
Elapsed time is 0.654010 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s_sos> x y y
  src mask: 0  1  1  1
  tgt input 1: <t_sos> b b <t_eos> <t_eos>
  tgt output 1: b b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000645	 -0.000655	diff=9.57798e-06
 -0.000000	 -0.000000	diff=9.14617e-13
  0.000020	  0.000019	diff=2.86991e-07
  0.000000	 -0.000000	diff=4.7598e-16
-12.880180	-12.036708	diff=0.843472
 -0.000000	 -0.000000	diff=4.27527e-10
  0.000000	  0.000000	diff=1.13196e-12
 -0.000000	 -0.000000	diff=6.82978e-13
  0.000219	  0.000218	diff=1.07071e-06
  0.000000	  0.000000	diff=1.68232e-13
 -0.000006	 -0.000006	diff=3.12514e-08
  0.000000	  0.000000	diff=1.58105e-16
  3.844936	  3.998194	diff=0.153258
  0.000000	  0.000000	diff=4.66287e-11
  0.000000	  0.000000	diff=1.98321e-12
  0.000000	  0.000000	diff=1.18925e-12
 -0.000042	 -0.000042	diff=2.38479e-07
  0.000000	  0.000000	diff=1.00509e-13
  0.000005	  0.000005	diff=1.92753e-08
  0.000000	  0.000000	diff=3.02454e-17
  0.427493	  0.429236	diff=0.00174272
  0.000000	  0.000000	diff=1.20405e-11
  0.000000	  0.000000	diff=1.87317e-13
  0.000000	  0.000000	diff=7.12328e-13
  0.000000	 -0.000000	diff=3.66484e-15
  0.000000	 -0.000000	diff=9.15927e-27
  0.000000	 -0.000000	diff=3.32337e-17
  0.000000	 -0.000000	diff=7.69988e-27
 -0.000000	 -0.000000	diff=2.56314e-13
  0.000000	 -0.000000	diff=7.75586e-20
  0.000000	  0.000000	diff=4.93975e-22
  0.000000	 -0.000000	diff=1.66729e-27
  local_diff=0.998483
# W_src{2}, [8 4]
  0.060915	  0.059955	diff=0.000960268
 -0.105433	 -0.105172	diff=0.00026134
  0.026054	  0.026043	diff=1.08659e-05
  0.097445	  0.097690	diff=0.000245299
 -0.717873	 -0.715295	diff=0.00257756
  0.304524	  0.303461	diff=0.00106279
 -0.417615	 -0.416720	diff=0.000895252
  0.014483	  0.014604	diff=0.000121373
  0.000000	  0.000000	diff=1.47533e-12
  0.000000	  0.000000	diff=6.74657e-13
 -0.000000	 -0.000000	diff=6.01845e-13
  0.000000	  0.000000	diff=1.12799e-13
  0.000000	  0.000000	diff=9.99918e-13
  0.000000	  0.000000	diff=7.96308e-13
  0.000000	  0.000000	diff=1.33443e-12
 -0.000000	  0.000000	diff=7.38353e-13
  0.060181	  0.060104	diff=7.68896e-05
 -0.157522	 -0.157616	diff=9.45347e-05
  0.042343	  0.042319	diff=2.43084e-05
 -0.038686	 -0.038684	diff=2.3279e-06
  0.060124	  0.060122	diff=1.77464e-06
 -0.051238	 -0.051260	diff=2.20286e-05
 -0.736389	 -0.733520	diff=0.00286856
 -0.002836	 -0.002831	diff=5.27755e-06
  0.043146	  0.043124	diff=2.16903e-05
  0.353888	  0.353337	diff=0.000551438
 -0.118440	 -0.118594	diff=0.000153526
  0.090253	  0.090250	diff=2.50515e-06
 -0.117548	 -0.117562	diff=1.49065e-05
  0.145487	  0.145627	diff=0.000140061
  1.845915	  1.865950	diff=0.0200348
  0.006550	  0.006578	diff=2.81229e-05
  local_diff=0.0301775
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=1.30654e-12
  0.000021	  0.000022	diff=2.78137e-07
  0.008457	  0.008348	diff=0.000109014
  0.000000	 -0.000000	diff=2.99343e-17
  0.000000	  0.000000	diff=8.27219e-13
 -0.000000	 -0.000000	diff=1.49694e-12
 -0.000000	 -0.000000	diff=1.06007e-10
  0.000000	  0.000000	diff=5.36662e-20
  0.000000	  0.000000	diff=1.0941e-13
 -0.000021	 -0.000021	diff=2.58047e-07
 -0.007876	 -0.007974	diff=9.78879e-05
  0.000000	  0.000000	diff=2.85921e-17
 -0.000000	 -0.000000	diff=6.30957e-13
  0.000000	  0.000000	diff=1.40573e-12
  0.000000	  0.000000	diff=9.3218e-11
  0.000000	 -0.000000	diff=5.12599e-20
  0.000000	  0.000000	diff=6.40149e-15
 -0.000012	 -0.000012	diff=1.54628e-08
  0.000010	  0.000010	diff=1.5639e-10
  0.000000	 -0.000000	diff=2.35214e-17
  0.000000	  0.000000	diff=1.87085e-15
 -0.000000	 -0.000000	diff=2.82549e-13
  0.000000	  0.000000	diff=8.78595e-13
  0.000000	 -0.000000	diff=6.99841e-21
  0.000000	  0.000000	diff=1.49288e-16
  0.000023	  0.000023	diff=1.60918e-08
 -0.000530	 -0.000531	diff=4.36512e-07
  0.000000	 -0.000000	diff=8.37201e-18
  0.000000	 -0.000000	diff=5.35507e-14
  0.000000	  0.000000	diff=8.84905e-13
 -0.000000	 -0.000000	diff=2.21974e-13
  0.000000	  0.000000	diff=3.42112e-21
  0.000000	  0.000000	diff=5.50464e-41
  0.000037	  0.000037	diff=1.40205e-07
 -0.002408	 -0.002417	diff=9.03936e-06
  0.000000	  0.000000	diff=1.60276e-23
  0.000000	 -0.000000	diff=2.43863e-13
  0.000000	  0.000000	diff=1.14525e-12
  0.000000	 -0.000000	diff=6.97213e-17
  0.000000	  0.000000	diff=5.16151e-61
  0.000000	 -0.000000	diff=1.17579e-28
  0.000000	  0.000000	diff=9.2265e-13
 -0.000000	 -0.000000	diff=6.92046e-13
  0.000000	  0.000000	diff=2.6898e-29
  0.000000	 -0.000000	diff=5.3467e-19
  0.000000	  0.000000	diff=4.92409e-17
  0.000000	 -0.000000	diff=1.58417e-22
  0.000000	  0.000000	diff=2.32445e-34
  local_diff=0.000217086
# W_tgt{2}, [8 4]
 -0.071362	 -0.071485	diff=0.00012359
  0.532100	  0.530731	diff=0.00136848
 -0.000101	 -0.000100	diff=3.81767e-07
 -0.000796	 -0.000776	diff=1.97807e-05
 -0.031510	 -0.031391	diff=0.000118883
  0.015004	  0.015053	diff=4.851e-05
  0.051053	  0.050694	diff=0.000358598
  3.638081	  3.595972	diff=0.0421091
 -0.000001	 -0.000001	diff=5.37918e-13
  0.000005	  0.000005	diff=6.04414e-13
 -0.000000	 -0.000000	diff=2.64499e-13
 -0.000000	 -0.000000	diff=1.00026e-12
 -0.000000	 -0.000000	diff=6.89229e-13
  0.000000	  0.000000	diff=1.19153e-13
  0.000002	  0.000002	diff=2.10882e-13
  0.000003	  0.000003	diff=7.21238e-12
  0.021535	  0.021699	diff=0.000164271
  0.069052	  0.069106	diff=5.32004e-05
 -0.028745	 -0.028754	diff=8.95531e-06
 -0.060642	 -0.060183	diff=0.000459439
  0.042561	  0.042483	diff=7.84445e-05
 -0.007008	 -0.007014	diff=5.64043e-06
  0.148883	  0.148898	diff=1.54763e-05
  0.428078	  0.418259	diff=0.00981886
  0.052168	  0.052767	diff=0.000599286
 -0.081964	 -0.081873	diff=9.04268e-05
  0.015287	  0.015313	diff=2.62133e-05
  0.322878	  0.325820	diff=0.00294157
 -0.051675	 -0.051693	diff=1.82975e-05
  0.023439	  0.023505	diff=6.56215e-05
 -0.066655	 -0.066689	diff=3.41197e-05
  1.828751	  1.858322	diff=0.0295713
  local_diff=0.0880985
# W_emb_src, [2 4]
 -0.000000	 -0.000000	diff=5.27539e-13
  0.000000	  0.000000	diff=2.27522e-12
-11.492646	-10.784612	diff=0.708034
-39.612802	-37.246982	diff=2.36582
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=3.07385
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=6.01745e-13
 -0.000000	 -0.000000	diff=4.59418e-13
  0.004332	  0.004304	diff=2.80815e-05
 -0.003162	 -0.003177	diff=1.53719e-05
 -0.000000	 -0.000000	diff=1.87861e-09
  0.000000	  0.000000	diff=1.00048e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=4.34562e-05
# W_soft, [4 2]
  0.163799	  0.163397	diff=0.000401677
 -0.361160	 -0.361564	diff=0.000404727
  0.006846	  0.006467	diff=0.000379625
  0.192091	  0.191701	diff=0.000389864
 -0.395371	 -0.395582	diff=0.000210191
 -0.150213	 -0.150430	diff=0.000217699
  0.520510	  0.520169	diff=0.000341006
  0.026195	  0.025843	diff=0.000352205
  local_diff=0.00269699
# Num params=168, abs_diff=4.19357
Elapsed time is 1.372962 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s_sos> x y y
  src mask: 0  1  1  1
  tgt input 1: <t_sos> b b <t_eos> <t_eos>
  tgt output 1: b b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000066	 -0.000068	diff=1.23551e-06
  0.000000	 -0.000000	diff=6.70383e-17
  0.000000	  0.000000	diff=6.25073e-09
  0.000000	 -0.000000	diff=2.05464e-20
-14.691952	-16.033722	diff=1.34177
 -0.000000	 -0.000000	diff=2.8183e-12
  0.000000	  0.000000	diff=7.01945e-13
  0.000000	 -0.000000	diff=9.95455e-17
  0.000023	  0.000022	diff=1.38571e-07
  0.000000	  0.000000	diff=2.22679e-17
 -0.000000	 -0.000000	diff=6.80102e-10
  0.000000	  0.000000	diff=6.82483e-21
  5.453171	  5.325870	diff=0.1273
  0.000000	  0.000000	diff=7.7027e-14
  0.000000	  0.000000	diff=6.96601e-13
  0.000000	  0.000000	diff=3.30581e-17
 -0.000002	 -0.000002	diff=1.45275e-08
  0.000000	  0.000000	diff=9.9016e-18
  0.000000	  0.000000	diff=2.72716e-10
  0.000000	  0.000000	diff=9.16188e-22
  0.447922	  0.446871	diff=0.0010513
  0.000000	  0.000000	diff=7.46686e-13
  0.000000	 -0.000000	diff=2.05284e-16
  0.000000	  0.000000	diff=1.47226e-17
  0.000000	 -0.000000	diff=9.32086e-19
  0.000000	 -0.000000	diff=1.01159e-33
  0.000000	 -0.000000	diff=1.64359e-21
  0.000000	 -0.000000	diff=7.5977e-34
  0.000000	 -0.000000	diff=3.25292e-13
  0.000000	 -0.000000	diff=4.82839e-25
  0.000000	  0.000000	diff=1.29126e-27
  0.000000	 -0.000000	diff=4.03375e-35
  local_diff=1.47012
# W_src{2}, [8 4]
 -0.087629	 -0.087317	diff=0.000312402
 -0.104552	 -0.104604	diff=5.24196e-05
  0.029759	  0.029728	diff=3.03116e-05
  0.040328	  0.040536	diff=0.000207567
 -0.720122	 -0.723410	diff=0.00328795
  0.013484	  0.013918	diff=0.000433682
 -0.463490	 -0.464573	diff=0.00108315
  0.022380	  0.022321	diff=5.89542e-05
  0.000000	  0.000000	diff=7.66826e-14
  0.000000	  0.000000	diff=5.97559e-13
 -0.000000	 -0.000000	diff=8.38812e-13
  0.000000	  0.000000	diff=7.55735e-14
  0.000000	  0.000000	diff=4.49839e-13
  0.000000	  0.000000	diff=1.46438e-13
  0.000000	  0.000000	diff=8.93708e-13
  0.000000	 -0.000000	diff=8.63541e-15
  0.024858	  0.024878	diff=2.03362e-05
 -0.196038	 -0.196240	diff=0.000202649
  0.038230	  0.038193	diff=3.70278e-05
 -0.026891	 -0.026900	diff=8.44295e-06
  0.078416	  0.078366	diff=5.03526e-05
 -0.007762	 -0.007782	diff=2.0232e-05
 -0.728100	 -0.730933	diff=0.00283308
 -0.003156	 -0.003150	diff=5.82747e-06
 -0.001545	 -0.001509	diff=3.61265e-05
  0.455685	  0.454594	diff=0.00109117
 -0.150903	 -0.151331	diff=0.000428279
  0.061089	  0.061037	diff=5.215e-05
 -0.168743	 -0.169003	diff=0.000260461
  0.121077	  0.120904	diff=0.000172329
  2.218184	  2.199777	diff=0.0184066
  0.007275	  0.007306	diff=3.12184e-05
  local_diff=0.0291228
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=1.04429e-10
  0.000005	  0.000005	diff=8.0949e-08
  0.003005	  0.002956	diff=4.92661e-05
  0.000000	 -0.000000	diff=2.19007e-20
  0.000000	  0.000000	diff=7.84294e-13
  0.000000	 -0.000000	diff=5.67905e-14
 -0.000000	 -0.000000	diff=7.09801e-13
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=9.80774e-36
 -0.000005	 -0.000005	diff=7.54523e-08
 -0.002779	 -0.002822	diff=4.39453e-05
  0.000000	  0.000000	diff=2.09187e-20
  0.000000	 -0.000000	diff=3.3634e-16
  0.000000	  0.000000	diff=5.33333e-14
  0.000000	  0.000000	diff=2.55581e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=4.98477e-13
  0.000000	  0.000000	diff=5.57429e-10
  0.000001	  0.000001	diff=4.93297e-12
  0.000000	 -0.000000	diff=1.68054e-21
  0.000000	  0.000000	diff=4.498e-13
  0.000000	 -0.000000	diff=6.06712e-17
  0.000000	  0.000000	diff=1.28342e-12
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=4.0685e-13
  0.000001	  0.000001	diff=1.23393e-09
 -0.000202	 -0.000202	diff=2.28108e-07
  0.000000	  0.000000	diff=3.57699e-23
  0.000000	  0.000000	diff=4.21261e-13
  0.000000	  0.000000	diff=4.15796e-15
  0.000000	 -0.000000	diff=2.0997e-15
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=5.66111e-22
  0.000004	  0.000004	diff=1.41145e-08
 -0.000682	 -0.000685	diff=2.60529e-06
  0.000000	  0.000000	diff=9.12719e-29
  0.000000	 -0.000000	diff=8.15624e-17
  0.000000	  0.000000	diff=1.38973e-14
  0.000000	 -0.000000	diff=6.26762e-65
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=7.61545e-19
  0.000000	  0.000000	diff=6.39282e-13
 -0.000000	 -0.000000	diff=2.02637e-13
  0.000000	  0.000000	diff=1.92039e-35
  0.000000	  0.000000	diff=3.08722e-21
  0.000000	  0.000000	diff=2.9388e-21
  0.000000	  0.000000	diff=7.89678e-31
  0.000000	  0.000000	diff=0
  local_diff=9.62172e-05
# W_tgt{2}, [8 4]
 -0.046571	 -0.046756	diff=0.000185392
  0.881217	  0.875604	diff=0.00561245
 -0.000032	 -0.000032	diff=1.52442e-07
 -0.021230	 -0.021128	diff=0.000101761
 -0.004326	 -0.004304	diff=2.16419e-05
  0.013983	  0.014047	diff=6.3315e-05
  0.021521	  0.021319	diff=0.0002016
  1.452357	  1.441073	diff=0.0112842
 -0.000000	 -0.000000	diff=8.80809e-13
  0.000001	  0.000001	diff=5.55874e-13
 -0.000000	 -0.000000	diff=4.47878e-13
 -0.000000	 -0.000000	diff=4.08594e-13
 -0.000000	 -0.000000	diff=9.85969e-13
  0.000000	  0.000000	diff=1.68992e-13
  0.000000	  0.000000	diff=6.34265e-13
  0.000000	  0.000000	diff=1.02086e-12
  0.114045	  0.114065	diff=2.00065e-05
 -0.048150	 -0.048257	diff=0.000106946
 -0.036371	 -0.036377	diff=6.0762e-06
 -0.007892	 -0.007883	diff=9.73686e-06
  0.034123	  0.033886	diff=0.000237215
 -0.003309	 -0.003318	diff=8.69243e-06
  0.223443	  0.223405	diff=3.74834e-05
  0.397509	  0.396443	diff=0.00106574
 -0.064313	 -0.064486	diff=0.000172565
 -0.082138	 -0.082165	diff=2.62452e-05
 -0.006463	 -0.006485	diff=2.25767e-05
  0.105459	  0.105311	diff=0.000148844
 -0.086875	 -0.086932	diff=5.6762e-05
 -0.007790	 -0.007790	diff=1.55305e-07
 -0.071641	 -0.071809	diff=0.000168241
  0.806076	  0.786040	diff=0.0200362
  local_diff=0.0395939
# W_emb_src, [2 4]
  0.000000	 -0.000000	diff=1.90784e-13
  0.000000	  0.000000	diff=1.1783e-14
-13.291020	-14.364067	diff=1.07305
-37.328793	-49.613001	diff=12.2842
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=13.3573
# W_emb_tgt, [2 4]
 -0.000000	 -0.000000	diff=1.06581e-09
  0.000000	  0.000000	diff=8.12824e-16
  0.001543	  0.001530	diff=1.28808e-05
 -0.001116	 -0.001123	diff=6.93643e-06
 -0.000000	 -0.000000	diff=1.03979e-09
 -0.000000	 -0.000000	diff=1.02557e-11
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.98194e-05
# W_soft, [4 2]
 -0.026639	 -0.026984	diff=0.000344792
 -0.058752	 -0.059116	diff=0.000363627
 -0.041811	 -0.042142	diff=0.000330914
  0.128625	  0.128242	diff=0.000382858
 -0.299412	 -0.299570	diff=0.000157991
 -0.097376	 -0.097538	diff=0.000162138
  0.438334	  0.438039	diff=0.000295356
 -0.040634	 -0.040931	diff=0.000296965
  local_diff=0.00233464
# Num params=168, abs_diff=14.8985
Elapsed time is 1.366456 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 176, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 176
  src input 1: <s_sos> y x x
  src mask: 0  1  1  1
  tgt input 1: <t_sos> a b <t_eos> <t_eos>
  tgt output 1: a b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000464	 -0.000472	diff=8.61332e-06
  0.000000	  0.000000	diff=2.61763e-21
  0.000010	  0.000010	diff=1.83826e-07
  0.000000	 -0.000000	diff=8.82923e-22
-11.893649	-12.236986	diff=0.343336
 -0.000000	 -0.000000	diff=8.84882e-12
  0.000000	  0.000000	diff=2.59582e-12
  0.000000	  0.000000	diff=1.62658e-16
  0.000158	  0.000157	diff=9.66033e-07
  0.000000	 -0.000000	diff=8.69487e-22
 -0.000003	 -0.000003	diff=1.99536e-08
  0.000000	  0.000000	diff=2.93278e-22
  4.103522	  4.064710	diff=0.0388124
 -0.000000	 -0.000000	diff=1.48336e-11
  0.000000	  0.000000	diff=5.76573e-12
  0.000000	 -0.000000	diff=1.26038e-26
 -0.000097	 -0.000097	diff=3.69771e-07
  0.000000	  0.000000	diff=5.39728e-22
  0.000002	  0.000002	diff=7.74063e-09
  0.000000	 -0.000000	diff=1.8205e-22
 -2.508330	 -2.523140	diff=0.0148097
  0.000000	  0.000000	diff=3.68473e-13
 -0.000000	 -0.000000	diff=1.50602e-12
  0.000000	  0.000000	diff=7.82373e-27
  0.000000	  0.000000	diff=1.28684e-18
  0.000000	 -0.000000	diff=9.21854e-36
  0.000000	 -0.000000	diff=2.67967e-20
  0.000000	  0.000000	diff=3.10942e-36
  0.000000	  0.000000	diff=3.33531e-14
  0.000000	 -0.000000	diff=4.42369e-31
  0.000000	 -0.000000	diff=2.89106e-29
  0.000000	 -0.000000	diff=1.33629e-40
  local_diff=0.396969
# W_src{2}, [8 4]
 -2.257346	 -2.261037	diff=0.00369125
 -0.108689	 -0.108325	diff=0.000364135
  0.029459	  0.029320	diff=0.000139694
  4.761785	  4.787153	diff=0.0253677
 -0.036283	 -0.036503	diff=0.00022046
  3.429074	  3.413095	diff=0.015979
 -0.000001	 -0.000001	diff=7.058e-09
 -0.000637	 -0.000633	diff=4.34008e-06
  0.000000	  0.000000	diff=8.28768e-13
  0.000000	  0.000000	diff=2.0727e-15
  0.000000	 -0.000000	diff=8.09105e-14
 -0.000000	 -0.000000	diff=1.69673e-12
  0.000000	  0.000000	diff=5.34658e-14
  0.000000	  0.000000	diff=1.72227e-13
  0.000000	  0.000000	diff=2.22743e-18
  0.000000	 -0.000000	diff=7.81408e-20
  0.082313	  0.082296	diff=1.74706e-05
  0.001993	  0.001993	diff=1.51363e-07
 -0.001563	 -0.001563	diff=3.88657e-07
 -0.251724	 -0.251653	diff=7.02628e-05
  0.001107	  0.001107	diff=4.92238e-07
 -0.066867	 -0.066873	diff=5.82103e-06
  0.000000	  0.000000	diff=2.05596e-11
  0.000013	  0.000013	diff=1.81556e-09
 -1.301395	 -1.305244	diff=0.00384952
 -0.000547	 -0.000545	diff=1.90288e-06
  0.021807	  0.021731	diff=7.58263e-05
  3.495431	  3.509070	diff=0.0136389
 -0.014347	 -0.014397	diff=4.99969e-05
 -0.046349	 -0.046188	diff=0.000161494
 -0.000001	 -0.000001	diff=4.15504e-09
  0.000000	  0.000000	diff=8.29555e-11
  local_diff=0.0636388
# W_tgt{1}, [8 6]
 -0.000037	 -0.000036	diff=5.99814e-07
 -0.000024	 -0.000024	diff=3.93476e-07
 -2.447394	 -2.437417	diff=0.00997785
  0.000000	 -0.000000	diff=9.30807e-18
 -0.000000	 -0.000000	diff=1.57283e-09
  0.000000	  0.000000	diff=5.52077e-13
 -0.000000	 -0.000000	diff=2.19896e-12
  0.000000	  0.000000	diff=1.74626e-19
  0.000000	  0.000000	diff=1.75801e-14
  0.000023	  0.000023	diff=3.66757e-07
  2.198258	  2.203680	diff=0.0054229
  0.000000	  0.000000	diff=8.89072e-18
  0.000000	  0.000000	diff=2.77382e-13
  0.000000	 -0.000000	diff=5.27567e-13
  0.000000	  0.000000	diff=5.25512e-13
  0.000000	 -0.000000	diff=1.66796e-19
  0.000003	  0.000003	diff=5.44091e-09
 -0.000015	 -0.000015	diff=7.05567e-08
  0.600620	  0.600996	diff=0.000376262
  0.000000	 -0.000000	diff=1.70786e-18
  0.000000	  0.000000	diff=1.29016e-11
  0.000000	 -0.000000	diff=3.93803e-14
  0.000000	  0.000000	diff=7.70395e-14
  0.000000	 -0.000000	diff=4.59126e-20
 -0.000003	 -0.000003	diff=3.30779e-09
 -0.000013	 -0.000013	diff=6.87561e-08
  0.576537	  0.576898	diff=0.000361295
  0.000000	 -0.000000	diff=2.36729e-18
 -0.000000	 -0.000000	diff=7.94542e-12
  0.000000	  0.000000	diff=3.28065e-14
 -0.000000	 -0.000000	diff=1.44361e-12
  0.000000	 -0.000000	diff=4.43036e-20
  0.000000	  0.000000	diff=1.43834e-16
 -0.000014	 -0.000014	diff=5.36194e-08
  0.548564	  0.548929	diff=0.000364744
  0.000000	 -0.000000	diff=9.04885e-28
  0.000000	  0.000000	diff=1.52419e-13
  0.000000	 -0.000000	diff=1.22369e-13
  0.000000	  0.000000	diff=1.57369e-14
  0.000000	 -0.000000	diff=4.04498e-20
  0.000000	 -0.000000	diff=2.48054e-20
 -0.000000	 -0.000000	diff=9.25279e-13
  0.000000	  0.000000	diff=3.73032e-13
  0.000000	 -0.000000	diff=1.20193e-34
  0.000000	  0.000000	diff=1.26782e-18
  0.000000	 -0.000000	diff=2.83143e-20
  0.000000	  0.000000	diff=7.41802e-21
  0.000000	 -0.000000	diff=1.90671e-26
  local_diff=0.0165046
# W_tgt{2}, [8 4]
  0.004784	  0.004790	diff=6.6787e-06
 16.179911	 16.279662	diff=0.099751
 -0.000001	 -0.000001	diff=6.69853e-09
  1.153088	  1.148677	diff=0.00441045
 -0.008691	 -0.008647	diff=4.36824e-05
  0.065309	  0.065625	diff=0.000316516
  0.002102	  0.002082	diff=2.05206e-05
 95.196767	 96.853600	diff=1.65683
  0.000000	  0.000000	diff=6.15077e-13
 -0.000001	 -0.000001	diff=2.11263e-12
  0.000000	 -0.000000	diff=2.1704e-13
  0.000000	  0.000000	diff=2.17321e-12
  0.000000	  0.000000	diff=2.40675e-12
 -0.000000	 -0.000000	diff=3.55896e-13
  0.000000	  0.000000	diff=1.61603e-12
 -0.000001	 -0.000001	diff=3.05964e-12
  0.119868	  0.119729	diff=0.000139371
  0.046233	  0.046268	diff=3.47516e-05
 -0.024363	 -0.024323	diff=4.02556e-05
  0.259138	  0.260284	diff=0.00114566
  0.194493	  0.194772	diff=0.000279223
  0.013685	  0.013720	diff=3.45766e-05
  0.171685	  0.171755	diff=6.95443e-05
 23.723966	 23.788197	diff=0.0642305
 -0.154124	 -0.153731	diff=0.000392547
  0.923247	  0.923699	diff=0.000452058
 -0.023109	 -0.023041	diff=6.79998e-05
  1.417607	  1.414297	diff=0.00330982
  0.028403	  0.028375	diff=2.76973e-05
  0.010398	  0.010497	diff=9.84774e-05
  0.040354	  0.040197	diff=0.000156756
 20.763472	 20.097545	diff=0.665927
  local_diff=2.49779
# W_emb_src, [2 4]
 -0.000066	 -0.000068	diff=1.10602e-06
  0.000000	  0.000000	diff=1.42631e-11
-10.687412	-10.963551	diff=0.276139
-34.702646	-37.866017	diff=3.16337
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=3.43951
# W_emb_tgt, [2 4]
  0.000000	 -0.000000	diff=4.14489e-16
  0.000000	  0.000000	diff=4.77964e-17
 -1.203013	 -1.201508	diff=0.001505
  0.873859	  0.874693	diff=0.000834337
  0.032401	  0.032680	diff=0.000279035
 -0.000000	 -0.000000	diff=1.22359e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.00261837
# W_h, [2 4]
  1.500935	  1.501130	diff=0.000195008
  1.086579	  1.088985	diff=0.00240587
  7.443393	  7.443210	diff=0.000182303
  1.727474	  1.717788	diff=0.00968578
  0.841541	  0.840017	diff=0.00152402
 -1.568343	 -1.566960	diff=0.00138355
  3.407274	  3.410407	diff=0.00313315
  7.450865	  7.452402	diff=0.0015374
  local_diff=0.0200471
# W_soft, [4 2]
 -3.183737	 -3.186035	diff=0.002298
 -0.189030	 -0.189130	diff=9.99028e-05
  6.317097	  6.316243	diff=0.000854239
 -2.939284	 -2.941078	diff=0.00179316
 -4.117624	 -4.120890	diff=0.00326571
  2.304761	  2.304685	diff=7.62058e-05
  3.172491	  3.172279	diff=0.000211598
 -1.352975	 -1.356075	diff=0.00309958
  local_diff=0.0116984
# Num params=176, abs_diff=6.44878
Elapsed time is 2.107544 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 2, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 176, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_h=8 W_soft=8
# assert = 0
# attnFunc = 2
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 176
  src input 1: <s_sos> y x x
  src mask: 0  1  1  1
  tgt input 1: <t_sos> a b <t_eos> <t_eos>
  tgt output 1: a b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000059	  0.000060	diff=1.10026e-06
  0.000000	 -0.000000	diff=2.65812e-22
 -0.000001	 -0.000001	diff=2.34834e-08
  0.000000	  0.000000	diff=8.96576e-23
  1.541849	  1.562940	diff=0.0210911
  0.000000	  0.000000	diff=9.79184e-13
 -0.000000	 -0.000000	diff=1.33596e-12
  0.000000	  0.000000	diff=1.75053e-18
 -0.000020	 -0.000020	diff=1.234e-07
  0.000000	  0.000000	diff=8.82938e-23
  0.000000	  0.000000	diff=2.54849e-09
  0.000000	 -0.000000	diff=2.97813e-23
 -0.521488	 -0.519241	diff=0.00224652
  0.000000	  0.000000	diff=9.52874e-13
 -0.000000	 -0.000000	diff=7.38103e-13
  0.000000	  0.000000	diff=1.27988e-27
  0.000012	  0.000012	diff=4.72359e-08
  0.000000	 -0.000000	diff=5.48077e-23
 -0.000000	 -0.000000	diff=9.88665e-10
  0.000000	  0.000000	diff=1.84865e-23
  0.321436	  0.322315	diff=0.000879162
 -0.000000	 -0.000000	diff=1.02899e-12
  0.000000	  0.000000	diff=1.27075e-12
  0.000000	 -0.000000	diff=7.94476e-28
  0.000000	 -0.000000	diff=1.19077e-19
  0.000000	  0.000000	diff=9.36121e-37
  0.000000	  0.000000	diff=2.47962e-21
  0.000000	 -0.000000	diff=3.15754e-37
  0.000000	 -0.000000	diff=3.08631e-15
  0.000000	  0.000000	diff=1.1235e-31
  0.000000	  0.000000	diff=2.67523e-30
  0.000000	  0.000000	diff=1.35697e-41
  local_diff=0.024218
# W_src{2}, [8 4]
 -0.883609	 -0.878183	diff=0.0054259
  0.015601	  0.015568	diff=3.35177e-05
 -0.002750	 -0.002737	diff=1.277e-05
 -0.485580	 -0.495089	diff=0.00950949
 -0.038386	 -0.038709	diff=0.000322571
 -0.145243	 -0.145953	diff=0.000709403
 -0.000001	 -0.000001	diff=4.06052e-09
  0.000175	  0.000174	diff=1.18681e-06
 -0.000000	 -0.000000	diff=1.03515e-12
  0.000000	 -0.000000	diff=1.62675e-16
  0.000000	  0.000000	diff=6.48593e-15
  0.000000	  0.000000	diff=1.35108e-12
  0.000000	 -0.000000	diff=4.34189e-15
 -0.000000	 -0.000000	diff=1.40703e-12
  0.000000	 -0.000000	diff=1.78183e-19
  0.000000	  0.000000	diff=1.90302e-20
 -0.019962	 -0.019960	diff=1.81595e-06
 -0.000661	 -0.000661	diff=3.32712e-08
  0.000119	  0.000119	diff=3.08525e-08
  0.026050	  0.026023	diff=2.63088e-05
 -0.001504	 -0.001503	diff=5.97416e-08
  0.008504	  0.008504	diff=3.17812e-07
  0.000000	  0.000000	diff=2.52263e-13
 -0.000004	 -0.000004	diff=5.097e-10
  0.104850	  0.104644	diff=0.000206416
  0.000057	  0.000057	diff=1.96864e-07
 -0.001748	 -0.001742	diff=5.9333e-06
 -0.357758	 -0.362869	diff=0.00511112
  0.001188	  0.001192	diff=4.0738e-06
  0.003775	  0.003761	diff=1.38029e-05
  0.000000	  0.000000	diff=3.33182e-10
  0.000000	  0.000000	diff=8.33068e-12
  local_diff=0.021385
# W_tgt{1}, [8 6]
 -0.000068	 -0.000067	diff=1.11006e-06
  0.000102	  0.000104	diff=1.68463e-06
 -2.300308	 -2.294993	diff=0.00531447
  0.000000	 -0.000000	diff=1.13766e-17
 -0.000000	 -0.000000	diff=1.74944e-12
  0.000000	  0.000000	diff=4.91939e-13
 -0.000000	 -0.000000	diff=1.79422e-12
  0.000000	  0.000000	diff=1.74616e-19
  0.000000	  0.000000	diff=6.75412e-14
 -0.000101	 -0.000099	diff=1.57024e-06
  2.184892	  2.190111	diff=0.00521895
  0.000000	  0.000000	diff=1.08665e-17
  0.000000	  0.000000	diff=1.14076e-12
 -0.000000	 -0.000000	diff=9.5109e-13
  0.000000	  0.000000	diff=1.78487e-12
  0.000000	 -0.000000	diff=1.66786e-19
 -0.000005	 -0.000005	diff=6.13612e-09
 -0.000017	 -0.000017	diff=7.075e-08
  0.600548	  0.600924	diff=0.000376818
  0.000000	 -0.000000	diff=2.86584e-18
  0.000000	  0.000000	diff=1.35256e-12
  0.000000	 -0.000000	diff=2.65928e-14
  0.000000	  0.000000	diff=6.11204e-13
  0.000000	 -0.000000	diff=4.59101e-20
 -0.000020	 -0.000020	diff=9.82291e-08
 -0.000016	 -0.000016	diff=6.6592e-08
  0.578240	  0.578597	diff=0.000356888
  0.000000	 -0.000000	diff=3.35019e-18
  0.000000	  0.000000	diff=4.16335e-13
  0.000000	  0.000000	diff=4.22171e-14
 -0.000000	 -0.000000	diff=2.48394e-12
  0.000000	 -0.000000	diff=4.43025e-20
  0.000000	  0.000000	diff=2.26636e-18
 -0.000014	 -0.000014	diff=5.35351e-08
  0.531051	  0.531349	diff=0.000298295
  0.000000	 -0.000000	diff=1.7043e-27
  0.000000	  0.000000	diff=1.26795e-12
 -0.000000	 -0.000000	diff=1.31009e-12
  0.000000	  0.000000	diff=1.57329e-14
  0.000000	 -0.000000	diff=4.04474e-20
  0.000000	 -0.000000	diff=4.59071e-20
 -0.000000	 -0.000000	diff=5.11668e-13
  0.000000	  0.000000	diff=2.70067e-13
  0.000000	 -0.000000	diff=2.15051e-34
  0.000000	  0.000000	diff=1.26514e-18
  0.000000	 -0.000000	diff=2.64153e-20
  0.000000	  0.000000	diff=7.40202e-21
  0.000000	 -0.000000	diff=1.90297e-26
  local_diff=0.0115701
# W_tgt{2}, [8 4]
  0.010464	  0.010477	diff=1.37226e-05
  9.189496	  9.129099	diff=0.0603976
 -0.000001	 -0.000001	diff=4.76525e-09
  0.822913	  0.819799	diff=0.00311424
 -0.001551	 -0.001542	diff=9.11911e-06
  0.055129	  0.055387	diff=0.000258618
  0.001424	  0.001410	diff=1.39192e-05
 57.822594	 58.280671	diff=0.458077
  0.000000	  0.000000	diff=1.49597e-12
 -0.000000	 -0.000000	diff=1.04524e-12
 -0.000000	 -0.000000	diff=1.26745e-12
  0.000000	  0.000000	diff=2.05621e-12
  0.000000	  0.000000	diff=6.67073e-13
  0.000000	  0.000000	diff=1.35519e-12
  0.000000	  0.000000	diff=1.7439e-12
  0.000004	  0.000004	diff=3.11319e-13
  0.134006	  0.133616	diff=0.000389588
 -0.157696	 -0.157452	diff=0.000244114
 -0.033972	 -0.033878	diff=9.34141e-05
  0.001528	  0.001365	diff=0.000163278
  0.144998	  0.145109	diff=0.000110983
 -0.012904	 -0.012914	diff=9.75799e-06
  0.137810	  0.137902	diff=9.21814e-05
 -0.365614	 -0.495354	diff=0.12974
 -0.147745	 -0.147798	diff=5.26644e-05
  0.427898	  0.428326	diff=0.00042881
  0.003565	  0.003551	diff=1.38017e-05
  0.206966	  0.207922	diff=0.000955988
 -0.000015	 -0.000067	diff=5.14988e-05
 -0.099646	 -0.099738	diff=9.18849e-05
  0.073443	  0.073344	diff=9.80207e-05
  9.437111	  9.473260	diff=0.0361488
  local_diff=0.690569
# W_emb_src, [2 4]
 -0.000013	 -0.000013	diff=2.16719e-07
 -0.000000	 -0.000000	diff=6.73713e-13
  1.383425	  1.400316	diff=0.0168911
  4.627104	  4.837148	diff=0.210044
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.226935
# W_emb_tgt, [2 4]
  0.000000	 -0.000000	diff=2.10596e-14
  0.000000	 -0.000000	diff=1.10953e-16
 -1.197598	 -1.196129	diff=0.00146916
  0.868427	  0.869230	diff=0.000802783
  0.000504	  0.000509	diff=4.33384e-06
 -0.000000	 -0.000000	diff=1.35832e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.00227627
# W_h, [2 4]
  0.056302	  0.055623	diff=0.00067878
  0.205340	  0.204400	diff=0.000940052
 11.721814	 11.707993	diff=0.0138215
 -2.401489	 -2.403706	diff=0.00221653
  0.855528	  0.852334	diff=0.00319462
 -0.848436	 -0.852592	diff=0.00415577
  2.651677	  2.653916	diff=0.00223888
  1.959060	  1.955290	diff=0.00377073
  local_diff=0.0310168
# W_soft, [4 2]
 -2.189332	 -2.192252	diff=0.00292025
  0.642464	  0.642413	diff=5.0633e-05
  3.858354	  3.857581	diff=0.000773544
 -2.305439	 -2.307741	diff=0.0023021
 -5.984839	 -5.989206	diff=0.00436656
  3.439439	  3.439388	diff=5.04506e-05
  2.510455	  2.510333	diff=0.000121976
  0.043725	  0.039484	diff=0.00424084
  local_diff=0.0148264
# Num params=176, abs_diff=1.0228
Elapsed time is 2.516524 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 4, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_pos=4 v_pos=2 W_h=8 W_soft=8
# assert = 0
# attnFunc = 4
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# distSigma = 0.5
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <t_sos> a b <t_eos> <t_eos>
  tgt output 1: a b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000691	 -0.000704	diff=1.28421e-05
  0.000000	 -0.000000	diff=7.4783e-16
  0.000004	  0.000003	diff=6.42767e-08
  0.000000	  0.000000	diff=4.84745e-21
-151.109770	-144.470486	diff=6.63928
 -0.000000	 -0.000000	diff=3.21438e-11
  0.000000	  0.000000	diff=1.20627e-13
  0.000000	  0.000000	diff=5.21231e-14
  0.000235	  0.000234	diff=1.44031e-06
  0.000975	  0.000981	diff=6.1976e-06
 -0.000001	 -0.000001	diff=6.97688e-09
 -0.000974	 -0.000980	diff=5.82789e-06
 47.227685	 47.999733	diff=0.772049
 31.465351	 27.375813	diff=4.08954
  0.000000	  0.000000	diff=1.09273e-13
  0.000000	  0.000000	diff=1.39875e-12
 -0.000031	 -0.000031	diff=1.37364e-07
 -0.000155	 -0.000155	diff=5.85797e-07
  0.000001	  0.000001	diff=2.70625e-09
  0.000610	  0.000608	diff=2.25974e-06
  1.098487	  1.102971	diff=0.00448446
 -0.002596	 -0.002586	diff=9.91715e-06
  0.000000	 -0.000000	diff=2.16118e-15
  0.000000	 -0.000000	diff=9.40517e-15
  0.000000	  0.000000	diff=5.53837e-19
  0.000024	  0.000024	diff=1.40686e-08
  0.000000	 -0.000000	diff=1.138e-20
 -0.000094	 -0.000094	diff=5.42783e-08
  0.000000	 -0.000000	diff=6.31103e-13
  0.000401	  0.000401	diff=2.38165e-07
  0.000000	  0.000000	diff=5.99853e-24
  0.000000	 -0.000000	diff=4.93864e-17
  local_diff=11.5054
# W_src{2}, [8 4]
 -1.331977	 -1.338500	diff=0.00652313
  2.140308	  2.141563	diff=0.00125525
  0.060493	  0.060422	diff=7.0261e-05
  0.193698	  0.194516	diff=0.000817567
 -1.939253	 -1.982079	diff=0.042826
  0.586078	  0.502024	diff=0.0840548
  0.008455	  0.009314	diff=0.000859721
  1.765672	  1.764595	diff=0.001077
 -0.013543	 -0.013547	diff=3.51724e-06
 -0.308984	 -0.309511	diff=0.000526836
  0.000008	  0.000008	diff=1.65845e-12
  0.000103	  0.000103	diff=1.89286e-11
 -0.015762	 -0.015758	diff=3.72268e-06
 -0.312721	 -0.313232	diff=0.00051137
 -0.180680	 -0.181427	diff=0.000747047
  1.546072	  1.533095	diff=0.012977
  0.363484	  0.363419	diff=6.47906e-05
  0.055015	  0.054944	diff=7.13051e-05
  0.050140	  0.050131	diff=9.37233e-06
 -0.017856	 -0.017825	diff=3.10191e-05
 -0.197766	 -0.198977	diff=0.00121108
  0.131067	  0.130856	diff=0.000211593
 -0.563972	 -0.563744	diff=0.00022799
 -0.180945	 -0.181214	diff=0.000268195
 -0.845948	 -0.845728	diff=0.00022038
 -0.054591	 -0.054698	diff=0.000106853
 -0.807105	 -0.808535	diff=0.00143024
  0.054203	  0.054350	diff=0.000146307
 -1.734183	 -1.772260	diff=0.0380767
  1.940472	  1.877979	diff=0.0624932
  6.875142	  6.920511	diff=0.0453687
  0.348543	  0.347561	diff=0.000981499
  local_diff=0.303172
# W_tgt{1}, [8 6]
 -0.000012	 -0.000011	diff=1.88665e-07
  0.401324	  0.408522	diff=0.00719792
 -0.004019	 -0.003926	diff=9.25711e-05
  0.000000	 -0.000000	diff=1.25613e-18
 -0.000000	 -0.000000	diff=6.58276e-13
  0.000000	  0.000000	diff=5.88791e-13
 -0.000000	 -0.000000	diff=6.41792e-12
  0.000000	  0.000000	diff=1.84208e-33
  0.000000	  0.000000	diff=1.19177e-12
 -0.543429	 -0.539276	diff=0.00415305
  0.002962	  0.003009	diff=4.67472e-05
 -0.000000	 -0.000000	diff=8.26869e-13
  0.000000	 -0.000000	diff=7.57933e-41
 -0.002398	 -0.002436	diff=3.78977e-05
  0.000000	  0.000000	diff=5.01637e-12
  0.500667	  0.532052	diff=0.0313847
 -0.000003	 -0.000003	diff=1.15088e-08
  0.021471	  0.021475	diff=4.38342e-06
 -0.000476	 -0.000474	diff=1.59383e-06
 -0.000000	 -0.000000	diff=9.73785e-15
  0.000000	  0.000000	diff=1.33968e-12
 -0.000642	 -0.000645	diff=2.27238e-06
  0.000000	  0.000000	diff=4.86329e-13
 -0.000103	 -0.000103	diff=9.22449e-10
 -0.000003	 -0.000003	diff=1.4242e-08
 -0.090848	 -0.090675	diff=0.000173048
  0.000497	  0.000498	diff=1.15605e-06
 -0.000000	 -0.000000	diff=5.25796e-13
  0.000000	  0.000000	diff=1.08363e-13
 -0.000408	 -0.000409	diff=9.15203e-07
  0.000000	  0.000000	diff=7.41497e-13
 -0.000037	 -0.000037	diff=3.66947e-11
  0.000000	 -0.000000	diff=4.24586e-18
 -0.059338	 -0.059116	diff=0.000222677
  0.000783	  0.000786	diff=2.98426e-06
  0.000000	 -0.000000	diff=2.55771e-30
  0.000000	  0.000000	diff=1.02208e-18
 -0.000000	 -0.000000	diff=6.21647e-13
  0.000000	  0.000000	diff=2.49303e-35
  0.000000	 -0.000000	diff=2.53201e-20
  0.000000	 -0.000000	diff=7.76449e-17
  0.000000	  0.000000	diff=8.99945e-13
  0.000000	  0.000000	diff=1.19346e-14
  0.000000	  0.000000	diff=1.08339e-22
  0.000000	  0.000000	diff=4.16162e-24
  0.000000	  0.000000	diff=4.94894e-14
  0.000000	  0.000000	diff=1.79121e-27
  0.000000	  0.000000	diff=3.18015e-15
  local_diff=0.0433221
# W_tgt{2}, [8 4]
 -0.184749	 -0.185411	diff=0.000661374
  8.285122	  8.313131	diff=0.0280089
  0.000039	  0.000039	diff=1.86581e-07
  0.398171	  0.396074	diff=0.00209772
  0.070553	  0.070219	diff=0.000334109
  0.051351	  0.051588	diff=0.000236889
 -0.052123	 -0.051649	diff=0.000474021
 46.574357	 46.922372	diff=0.348015
 -0.008450	 -0.008418	diff=3.20631e-05
 -0.109246	 -0.109000	diff=0.000246585
 -0.002729	 -0.002718	diff=1.16777e-05
 -0.000774	 -0.000777	diff=3.43316e-06
 -0.012474	 -0.012529	diff=5.4668e-05
 -0.287266	 -0.288495	diff=0.00122915
 -0.147793	 -0.148492	diff=0.000699523
  0.015388	  0.015389	diff=9.01466e-07
 -2.457873	 -2.458961	diff=0.00108784
 -0.550222	 -0.549275	diff=0.000947019
 -0.061618	 -0.072632	diff=0.011014
  2.340193	  2.345122	diff=0.00492942
 -0.881269	 -0.881747	diff=0.000478103
  0.181123	  0.180930	diff=0.000193287
 -1.984690	 -1.982036	diff=0.00265418
 15.904250	 15.997359	diff=0.0931096
  4.795021	  4.796240	diff=0.00121864
  1.512925	  1.518702	diff=0.00577651
  1.075892	  1.067800	diff=0.00809154
 -4.788505	 -4.761335	diff=0.0271707
  1.143992	  1.142797	diff=0.00119513
 -0.528393	 -0.528692	diff=0.00029933
  0.888519	  0.890106	diff=0.001587
-18.426282	-17.733374	diff=0.692908
  local_diff=1.23477
# W_emb_src, [2 4]
  0.030095	  0.030582	diff=0.000487386
 -1.711874	 -1.727757	diff=0.0158831
-134.816533	-129.457261	diff=5.35927
-499.230681	-447.140542	diff=52.0901
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=57.4658
# W_emb_tgt, [2 4]
  0.000094	  0.000094	diff=3.84802e-07
 -0.000000	 -0.000000	diff=4.59125e-09
 -0.972865	 -0.933755	diff=0.0391098
 -0.289230	 -0.287224	diff=0.00200526
  0.000126	  0.000127	diff=1.08219e-06
 -0.000000	 -0.000000	diff=1.83525e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.0411165
# W_pos, [2 2]
  0.023199	  0.023187	diff=1.14839e-05
  0.007580	  0.007563	diff=1.69341e-05
  0.259985	  0.259800	diff=0.000184574
  0.195364	  0.195074	diff=0.000290398
  local_diff=0.00050339
# v_pos, [1 2]
 -1.712580	 -1.715420	diff=0.00283985
 -5.257470	 -5.285094	diff=0.0276242
  local_diff=0.030464
# W_h, [2 4]
 -0.785446	 -0.784352	diff=0.00109423
 -0.413761	 -0.413865	diff=0.000103948
 -0.044467	 -0.038967	diff=0.00549954
  1.608609	  1.608976	diff=0.000367467
  2.282318	  2.281567	diff=0.000751496
 -0.693438	 -0.696929	diff=0.00349108
 -2.887088	 -2.884786	diff=0.00230191
  2.027630	  2.028981	diff=0.00135128
  local_diff=0.014961
# W_soft, [4 2]
  6.196457	  6.193507	diff=0.00295003
 -3.103327	 -3.110026	diff=0.00669926
 -1.474215	 -1.478185	diff=0.00397068
 -1.599004	 -1.605296	diff=0.00629191
 -3.020241	 -3.024151	diff=0.00391006
  0.472871	  0.464744	diff=0.00812697
  5.316537	  5.312942	diff=0.00359505
 -2.745333	 -2.753535	diff=0.00820215
  local_diff=0.0437461
# Num params=182, abs_diff=70.6832
Elapsed time is 2.931442 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 180, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 180
  src input 1: <s_sos> <s_sos> x y
  src mask: 0  0  1  1
  tgt input 1: <t_sos> a <t_eos> <t_eos> <t_eos>
  tgt output 1: a <t_eos> <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  0  0  0
# W_src{1}, [8 4]
  0.000272	  0.000277	diff=5.05772e-06
  0.000000	 -0.000000	diff=3.4251e-17
 -0.000004	 -0.000004	diff=6.58746e-08
  0.000000	  0.000000	diff=2.19323e-22
 28.877635	 30.470375	diff=1.59274
 -0.000000	 -0.000000	diff=2.13215e-12
  0.000000	 -0.000000	diff=4.66456e-16
  0.000000	  0.000000	diff=7.60972e-17
 -0.000093	 -0.000092	diff=5.67206e-07
 -0.002219	 -0.002232	diff=1.36859e-05
  0.000001	  0.000001	diff=7.14995e-09
  0.001515	  0.001524	diff=9.06127e-06
-10.286185	-10.121054	diff=0.165131
-29.300876	-33.968820	diff=4.66794
  0.000000	  0.000000	diff=1.64229e-14
 -0.000000	 -0.000000	diff=1.41433e-12
  0.000035	  0.000035	diff=1.32223e-07
  0.000241	  0.000240	diff=9.11483e-07
 -0.000001	 -0.000001	diff=2.77259e-09
 -0.000950	 -0.000946	diff=3.51345e-06
  0.970722	  0.974169	diff=0.00344687
  0.002610	  0.002600	diff=1.00322e-05
  0.000000	 -0.000000	diff=7.83748e-16
  0.000000	 -0.000000	diff=5.41261e-18
  0.000000	 -0.000000	diff=5.57811e-19
 -0.000037	 -0.000037	diff=2.18933e-08
  0.000000	  0.000000	diff=2.89329e-20
  0.000147	  0.000147	diff=8.43934e-08
  0.000000	 -0.000000	diff=1.45491e-14
 -0.000365	 -0.000365	diff=2.31493e-07
  0.000000	 -0.000000	diff=3.6141e-24
  0.000000	  0.000000	diff=3.27183e-16
  local_diff=6.42931
# W_src{2}, [8 4]
  0.079399	  0.077762	diff=0.00163694
 -0.537340	 -0.536585	diff=0.000755308
  0.002015	  0.002015	diff=1.63384e-07
 -0.000332	 -0.000332	diff=3.6005e-08
  0.135593	  0.136673	diff=0.00107974
 -1.261247	 -1.257943	diff=0.00330419
 -0.069338	 -0.069384	diff=4.61056e-05
 -0.444869	 -0.443821	diff=0.00104746
 -0.020101	 -0.020105	diff=4.36972e-06
  0.429614	  0.428825	diff=0.000789434
 -0.000015	 -0.000015	diff=1.02505e-10
 -0.000108	 -0.000108	diff=1.87148e-09
 -0.007261	 -0.007260	diff=8.83952e-07
  0.376264	  0.375598	diff=0.000666187
 -0.270239	 -0.271220	diff=0.000980508
 -2.104512	 -2.123865	diff=0.0193527
 -0.022657	 -0.022651	diff=6.30317e-06
 -0.084217	 -0.084238	diff=2.13258e-05
  0.006894	  0.006894	diff=1.5498e-07
 -0.041438	 -0.041446	diff=7.78414e-06
  0.010008	  0.010010	diff=2.2572e-06
 -0.178472	 -0.178505	diff=3.29757e-05
  0.038769	  0.038825	diff=5.55058e-05
  0.417128	  0.416577	diff=0.000551533
  0.047141	  0.047173	diff=3.16414e-05
  0.141619	  0.141368	diff=0.000250798
 -0.048940	 -0.048903	diff=3.66871e-05
  0.055891	  0.055835	diff=5.59803e-05
 -0.016822	 -0.016814	diff=7.2641e-06
  0.417073	  0.416694	diff=0.000378566
  0.185653	  0.194260	diff=0.00860698
 -0.696864	 -0.699163	diff=0.00229863
  local_diff=0.0420084
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=2.83389e-26
  0.000862	  0.000877	diff=1.41749e-05
 -0.000000	 -0.000000	diff=2.22662e-10
  0.000000	 -0.000000	diff=5.76058e-20
  0.000000	 -0.000000	diff=9.30008e-16
  0.000000	  0.000000	diff=4.97603e-15
  0.000000	  0.000000	diff=3.40819e-11
  0.000000	  0.000000	diff=6.73807e-16
  0.000000	 -0.000000	diff=8.90871e-19
 -0.182132	 -0.186787	diff=0.00465445
  0.000000	  0.000000	diff=4.84992e-10
 -0.000000	 -0.000000	diff=1.10593e-11
  0.000000	  0.000000	diff=8.88323e-16
 -0.024311	 -0.024724	diff=0.000413104
 -0.000000	 -0.000000	diff=2.95702e-11
 -1.202783	 -1.269947	diff=0.0671636
  0.000000	  0.000000	diff=2.24456e-19
  0.006620	  0.006614	diff=6.41606e-06
 -0.000000	 -0.000000	diff=1.518e-12
  0.000000	  0.000000	diff=1.67194e-12
  0.000000	  0.000000	diff=2.44039e-16
  0.000880	  0.000880	diff=4.45593e-07
  0.000000	  0.000000	diff=6.86964e-12
  0.000148	  0.000148	diff=9.77302e-10
  0.000000	  0.000000	diff=2.68265e-19
  0.039768	  0.039534	diff=0.000234988
 -0.000000	 -0.000000	diff=1.83004e-12
  0.000000	  0.000000	diff=2.28988e-12
  0.000000	  0.000000	diff=1.59886e-16
  0.005398	  0.005377	diff=2.07129e-05
 -0.000000	 -0.000000	diff=1.06231e-11
 -0.000112	 -0.000112	diff=1.19898e-09
  0.000000	  0.000000	diff=1.60584e-32
  0.000000	  0.000000	diff=5.96088e-17
 -0.000000	 -0.000000	diff=9.66344e-13
  0.000000	 -0.000000	diff=2.77305e-38
  0.000000	 -0.000000	diff=1.58264e-21
  0.000000	  0.000000	diff=1.01774e-12
  0.000000	 -0.000000	diff=3.7712e-37
  0.000000	  0.000000	diff=4.27282e-20
  0.000000	  0.000000	diff=9.59092e-29
  0.000000	  0.000000	diff=1.30517e-13
  0.000000	 -0.000000	diff=5.40176e-18
  0.000000	 -0.000000	diff=1.22396e-18
  0.000000	 -0.000000	diff=2.26532e-31
  0.000000	  0.000000	diff=2.04576e-13
  0.000000	 -0.000000	diff=1.53219e-25
  0.000000	 -0.000000	diff=6.9449e-15
  local_diff=0.0725079
# W_tgt{2}, [8 4]
  0.358813	  0.359194	diff=0.000381329
  2.646589	  2.661496	diff=0.0149076
 -0.000474	 -0.000472	diff=2.24873e-06
  0.029444	  0.029330	diff=0.000114076
  0.001327	  0.001321	diff=5.87214e-06
  0.007583	  0.007625	diff=4.24172e-05
  0.776093	  0.772201	diff=0.00389198
 10.498538	 10.787996	diff=0.289458
  0.054189	  0.054021	diff=0.000168608
 -0.175402	 -0.175984	diff=0.000581829
 -0.016031	 -0.016016	diff=1.5243e-05
  0.000159	  0.000159	diff=4.16773e-07
  0.002322	  0.002329	diff=7.08704e-06
 -0.038786	 -0.038919	diff=0.000132286
 -0.035050	 -0.034892	diff=0.000158215
  0.000178	  0.000177	diff=9.06711e-07
  0.159696	  0.160480	diff=0.000783897
  0.410899	  0.410931	diff=3.28084e-05
  0.073048	  0.073234	diff=0.000185179
 -0.756099	 -0.754737	diff=0.00136146
 -0.429719	 -0.429478	diff=0.000240508
 -0.035291	 -0.035210	diff=8.12994e-05
 -0.378790	 -0.379096	diff=0.00030571
 -2.924295	 -2.898432	diff=0.0258624
 -0.358793	 -0.357605	diff=0.00118826
 -0.411822	 -0.412153	diff=0.000331536
  0.062151	  0.062417	diff=0.000266042
  1.520363	  1.526847	diff=0.00648408
 -2.168526	 -2.170774	diff=0.0022481
  0.402123	  0.402584	diff=0.000461504
 -0.390703	 -0.390635	diff=6.7147e-05
  3.483084	  3.539612	diff=0.0565284
  local_diff=0.406297
# W_emb_src, [2 4]
 -0.000004	 -0.000004	diff=5.97369e-08
  2.161132	  2.143848	diff=0.0172844
 26.025272	 27.297700	diff=1.27243
 77.746366	 94.289514	diff=16.5431
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=17.8329
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=1.88422e-12
 -0.000000	 -0.000000	diff=5.17882e-09
 -0.002076	 -0.002000	diff=7.64719e-05
 -0.272903	 -0.276486	diff=0.00358277
  0.000000	  0.000000	diff=9.26243e-12
 -0.000000	 -0.000000	diff=4.55234e-12
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.00365925
# W_a, [2 2]
 -0.004601	 -0.004561	diff=4.03499e-05
 -1.271075	 -1.271824	diff=0.000749732
 -0.009396	 -0.009445	diff=4.81219e-05
  0.773715	  0.772468	diff=0.0012462
  local_diff=0.00208441
# W_h, [2 4]
 -1.401553	 -1.401332	diff=0.000221425
 -0.226812	 -0.226780	diff=3.1104e-05
  1.691212	  1.687487	diff=0.00372525
  3.221858	  3.224075	diff=0.00221715
  0.523272	  0.517361	diff=0.00591073
 -2.967049	 -2.964788	diff=0.00226089
  1.987179	  1.986935	diff=0.0002433
 -1.232449	 -1.256040	diff=0.0235911
  local_diff=0.0382009
# W_soft, [4 2]
 -3.851457	 -3.857460	diff=0.00600372
  9.821180	  9.820617	diff=0.000562501
 -0.255695	 -0.256713	diff=0.0010184
 -5.700092	 -5.706444	diff=0.00635162
 -0.105013	 -0.108736	diff=0.00372278
  9.543991	  9.543179	diff=0.000811271
 -2.038852	 -2.042035	diff=0.00318255
 -7.386475	 -7.392409	diff=0.0059342
  local_diff=0.027587
# Num params=180, abs_diff=24.8545
Elapsed time is 2.077492 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 3)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 v_a=2 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 3
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <t_sos> a b <t_eos> <t_eos>
  tgt output 1: a b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000670	 -0.000683	diff=1.24521e-05
  0.000000	 -0.000000	diff=1.03563e-15
  0.000003	  0.000003	diff=5.93445e-08
  0.000000	  0.000000	diff=6.67673e-21
-116.666910	-145.420480	diff=28.7536
 -0.000000	 -0.000000	diff=4.48409e-11
  0.000000	  0.000000	diff=8.80112e-14
  0.000000	  0.000000	diff=3.64798e-14
  0.000228	  0.000227	diff=1.39658e-06
  0.001109	  0.001116	diff=7.01299e-06
 -0.000001	 -0.000001	diff=6.44055e-09
 -0.001221	 -0.001228	diff=7.30295e-06
 50.239733	 48.312631	diff=1.9271
 29.870956	 26.627128	diff=3.24383
  0.000000	  0.000000	diff=9.20397e-14
  0.000000	  0.000000	diff=1.82388e-12
 -0.000027	 -0.000027	diff=1.30623e-07
 -0.000194	 -0.000194	diff=7.34219e-07
  0.000001	  0.000001	diff=2.49982e-09
  0.000765	  0.000762	diff=2.83168e-06
  1.953435	  1.958392	diff=0.00495621
 -0.003134	 -0.003122	diff=1.1966e-05
  0.000000	 -0.000000	diff=1.82642e-15
  0.000000	 -0.000000	diff=6.34543e-15
  0.000000	  0.000000	diff=7.11411e-19
  0.000030	  0.000030	diff=1.76349e-08
  0.000000	 -0.000000	diff=1.45112e-20
 -0.000118	 -0.000118	diff=6.80144e-08
  0.000000	 -0.000000	diff=3.66722e-13
  0.000484	  0.000485	diff=2.87371e-07
  0.000000	  0.000000	diff=6.59464e-24
  0.000000	 -0.000000	diff=5.95743e-17
  local_diff=33.9295
# W_src{2}, [8 4]
 -1.233228	 -1.238343	diff=0.0051142
  1.974767	  1.967155	diff=0.00761199
  0.076013	  0.075954	diff=5.97049e-05
  0.235729	  0.236742	diff=0.00101319
 -2.803747	 -2.874915	diff=0.0711676
  1.902121	  1.783650	diff=0.118471
 -0.026326	 -0.025746	diff=0.000580432
  1.642859	  1.635642	diff=0.00721656
 -0.004863	 -0.004864	diff=9.99398e-07
 -0.308353	 -0.308816	diff=0.000463656
  0.000014	  0.000014	diff=7.02874e-13
  0.000121	  0.000121	diff=3.73046e-11
 -0.015977	 -0.015973	diff=3.62434e-06
 -0.294228	 -0.294672	diff=0.000444071
 -0.064074	 -0.064285	diff=0.000211213
  1.541045	  1.529626	diff=0.0114193
  0.287154	  0.287126	diff=2.86796e-05
  0.049790	  0.049748	diff=4.24709e-05
  0.068889	  0.068875	diff=1.44011e-05
 -0.021379	 -0.021340	diff=3.89988e-05
  0.025047	  0.023865	diff=0.00118247
  0.173787	  0.173651	diff=0.000136424
 -0.817147	 -0.817026	diff=0.000120652
 -0.227186	 -0.227407	diff=0.000220489
 -0.743876	 -0.743254	diff=0.000622304
 -0.050479	 -0.050605	diff=0.000126528
 -1.124673	 -1.127234	diff=0.00256152
  0.066061	  0.066243	diff=0.000181425
 -1.684030	 -1.732268	diff=0.0482378
  0.879120	  0.789705	diff=0.0894156
  9.688521	  9.720343	diff=0.0318223
  0.437014	  0.436209	diff=0.000805282
  local_diff=0.399335
# W_tgt{1}, [8 6]
  0.000010	  0.000010	diff=1.65997e-07
 -0.838583	 -1.366358	diff=0.527775
  0.000568	  0.000553	diff=1.55221e-05
  0.000000	 -0.000000	diff=2.00868e-18
 -0.000000	 -0.000000	diff=1.19683e-12
  0.000000	  0.000000	diff=1.00941e-12
 -0.000000	 -0.000000	diff=5.4304e-12
  0.000000	 -0.000000	diff=2.05735e-33
  0.000000	  0.000000	diff=2.31807e-13
  1.636776	  1.149155	diff=0.487621
 -0.000351	 -0.000357	diff=5.57085e-06
 -0.000000	 -0.000000	diff=6.25475e-13
  0.000000	 -0.000000	diff=1.68502e-38
 -0.003290	 -0.003342	diff=5.20448e-05
  0.000000	  0.000000	diff=5.4943e-12
  0.500831	  0.532228	diff=0.0313975
  0.000001	  0.000001	diff=3.62731e-09
 -0.252124	 -0.268157	diff=0.0160326
  0.000052	  0.000052	diff=2.16453e-07
 -0.000000	 -0.000000	diff=2.02915e-13
  0.000000	  0.000000	diff=1.63075e-12
 -0.000731	 -0.000733	diff=2.23594e-06
  0.000000	  0.000000	diff=7.63957e-13
 -0.000100	 -0.000100	diff=4.50515e-09
  0.000003	  0.000003	diff=1.50487e-08
  0.386125	  0.348005	diff=0.03812
 -0.000112	 -0.000113	diff=4.72614e-07
  0.000000	 -0.000000	diff=1.53482e-12
  0.000000	  0.000000	diff=1.65102e-12
 -0.000426	 -0.000426	diff=7.56803e-07
  0.000000	  0.000000	diff=2.89413e-12
 -0.000036	 -0.000036	diff=1.7676e-09
  0.000000	  0.000000	diff=4.69409e-18
  0.345039	  0.316574	diff=0.0284645
 -0.000099	 -0.000100	diff=3.80523e-07
  0.000000	  0.000000	diff=1.83341e-29
  0.000000	  0.000000	diff=3.22731e-19
  0.000000	  0.000000	diff=1.06326e-13
  0.000000	  0.000000	diff=9.37695e-35
  0.000000	 -0.000000	diff=5.24717e-20
  0.000000	  0.000000	diff=4.99954e-17
  0.000000	  0.000000	diff=3.9865e-13
  0.000000	 -0.000000	diff=2.94343e-14
  0.000000	  0.000000	diff=3.23024e-22
  0.000000	  0.000000	diff=2.68269e-24
  0.000000	  0.000000	diff=8.97343e-14
  0.000000	 -0.000000	diff=3.87671e-28
  0.000000	  0.000000	diff=3.07069e-15
  local_diff=1.12949
# W_tgt{2}, [8 4]
 -0.079339	 -0.079558	diff=0.000218955
 10.150990	  9.465504	diff=0.685487
  0.000020	  0.000020	diff=9.68993e-08
  0.098861	  0.098552	diff=0.000308541
  0.045504	  0.045256	diff=0.000247706
  0.078270	  0.078616	diff=0.000346209
 -0.024635	 -0.024323	diff=0.000312092
 43.602824	 36.361461	diff=7.24136
 -0.008629	 -0.008596	diff=3.24766e-05
 -0.112379	 -0.112154	diff=0.000224747
 -0.001933	 -0.001925	diff=8.25387e-06
 -0.001935	 -0.001938	diff=3.57202e-06
 -0.009063	 -0.009102	diff=3.8877e-05
 -0.289933	 -0.291227	diff=0.00129395
 -0.101632	 -0.102163	diff=0.000531127
 -0.050784	 -0.051506	diff=0.000722357
 -2.084400	 -2.092212	diff=0.00781117
 -0.454174	 -0.454507	diff=0.000332507
 -0.877925	 -0.892417	diff=0.0144918
  2.097232	  2.086664	diff=0.0105671
 -1.568049	 -1.569094	diff=0.00104569
  0.127389	  0.127020	diff=0.000368842
 -2.293679	 -2.295255	diff=0.00157564
 17.313858	 16.669631	diff=0.644227
  4.908544	  4.881384	diff=0.0271603
  1.127563	  1.123748	diff=0.00381463
  1.635114	  1.621548	diff=0.0135662
 -4.055958	 -4.116956	diff=0.0609986
  1.086702	  1.086275	diff=0.000426576
 -0.454664	 -0.455848	diff=0.00118445
  0.877420	  0.878070	diff=0.000649868
-17.185214	-18.764095	diff=1.57888
  local_diff=10.2982
# W_emb_src, [2 4]
  0.023109	  0.023477	diff=0.00036795
 -1.667685	 -1.680516	diff=0.0128314
-107.752619	-130.301103	diff=22.5485
-240.843402	-450.054194	diff=209.211
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=231.772
# W_emb_tgt, [2 4]
 -0.000022	 -0.000022	diff=8.86757e-08
 -0.000000	 -0.000000	diff=1.60396e-09
  5.888552	  3.117726	diff=2.77083
  0.977649	  0.781882	diff=0.195767
 -0.000029	 -0.000029	diff=2.49206e-07
 -0.000000	 -0.000000	diff=3.40389e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=2.96659
# W_a, [2 2]
  0.013562	  0.013606	diff=4.4126e-05
 -0.019078	 -0.019049	diff=2.89e-05
  0.003309	  0.003319	diff=1.00035e-05
 -0.061403	 -0.061452	diff=4.98492e-05
  local_diff=0.000132879
# v_a, [1 2]
  1.152139	  1.145114	diff=0.00702573
 -1.314995	 -1.323868	diff=0.00887351
  local_diff=0.0158992
# W_h, [2 4]
 -0.558595	 -0.563894	diff=0.00529916
 -0.394915	 -0.395054	diff=0.000138346
  1.378354	  1.345824	diff=0.0325302
  1.123957	  1.121384	diff=0.00257283
  2.922812	  2.922132	diff=0.000679237
 -0.489326	 -0.492207	diff=0.00288164
 -1.793488	 -1.870760	diff=0.0772724
  1.916430	  1.909342	diff=0.00708849
  local_diff=0.128462
# W_soft, [4 2]
  6.914407	  6.911868	diff=0.00253851
 -2.837429	 -2.844524	diff=0.00709471
 -1.432047	 -1.435385	diff=0.00333813
 -2.625296	 -2.631960	diff=0.0066636
 -2.306634	 -2.311376	diff=0.00474266
 -0.043865	 -0.054289	diff=0.010424
  4.474193	  4.470923	diff=0.00327081
 -2.094216	 -2.105258	diff=0.0110415
  local_diff=0.0491139
# Num params=182, abs_diff=280.689
Elapsed time is 2.399475 seconds.
[?1l>