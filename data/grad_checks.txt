# Script dir = /Users/lmthang/nmt.matlab/scripts
cd /Users/lmthang/nmt.matlab/scripts/../code

## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 104, individual sizes:  W_src{1}=32 W_tgt{1}=48 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 1
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 104
  src input 1: y y x y
  src mask: 1  1  1  1
  tgt input 1: <t_sos> a b a
  tgt output 1: a b a <t_eos>
  tgt mask: 1  1  1  1
# W_src{1}, [8 4]
 -0.000013	 -0.000013	diff=1.00581e-10
 -0.000002	 -0.000002	diff=1.58468e-11
 -0.000010	 -0.000010	diff=1.1217e-09
 -0.000001	 -0.000001	diff=1.23089e-10
 -0.000000	 -0.000000	diff=1.04141e-12
  0.000000	  0.000000	diff=9.07881e-13
 -0.003613	 -0.003613	diff=8.10743e-08
  0.000713	  0.000713	diff=9.21717e-09
  0.000015	  0.000015	diff=1.37375e-10
  0.000003	  0.000003	diff=2.07755e-11
  0.000011	  0.000011	diff=1.43185e-09
  0.000001	  0.000001	diff=1.86931e-10
  0.000000	  0.000000	diff=2.33636e-12
 -0.000000	 -0.000000	diff=1.13417e-12
  0.004176	  0.004176	diff=1.0838e-07
 -0.000891	 -0.000891	diff=1.45165e-08
  0.000001	  0.000001	diff=3.86068e-12
  0.000000	  0.000000	diff=5.75087e-13
  0.000000	  0.000000	diff=3.83232e-12
  0.000000	  0.000000	diff=7.18741e-13
 -0.000000	 -0.000000	diff=3.80584e-13
 -0.000000	 -0.000000	diff=1.08735e-12
  0.000155	  0.000154	diff=2.82143e-07
 -0.000021	 -0.000021	diff=1.65579e-10
 -0.000000	 -0.000000	diff=1.37378e-13
 -0.000000	 -0.000000	diff=4.1579e-13
 -0.000000	 -0.000000	diff=8.26237e-13
 -0.000000	 -0.000000	diff=9.4915e-13
  0.000000	  0.000000	diff=2.77459e-13
  0.000000	  0.000000	diff=5.61059e-13
 -0.000120	 -0.000120	diff=1.68958e-09
  0.000016	  0.000016	diff=3.36779e-08
  local_diff=5.34021e-07
# W_tgt{1}, [8 6]
 -0.000023	 -0.000023	diff=8.22795e-11
  0.000002	  0.000002	diff=4.21865e-11
  0.000027	  0.000027	diff=1.70418e-09
 -0.000000	 -0.000000	diff=4.36351e-10
  0.000018	  0.000018	diff=8.6079e-11
  0.000001	  0.000001	diff=1.0676e-11
  0.019842	  0.019842	diff=1.67844e-07
 -0.001313	 -0.001313	diff=3.03045e-08
  0.000041	  0.000041	diff=2.24695e-11
  0.000002	  0.000002	diff=4.93694e-11
  0.000000	  0.000000	diff=1.03452e-08
  0.000005	  0.000005	diff=1.76185e-10
  0.000055	  0.000055	diff=2.0443e-11
  0.000005	  0.000005	diff=6.52866e-11
 -0.011633	 -0.011633	diff=3.68551e-07
 -0.001429	 -0.001429	diff=8.41353e-09
  0.000000	  0.000000	diff=3.61114e-12
 -0.000000	 -0.000000	diff=5.59428e-13
 -0.000001	 -0.000001	diff=1.66645e-12
  0.000000	  0.000000	diff=5.90792e-13
 -0.000000	 -0.000000	diff=5.34451e-13
 -0.000000	 -0.000000	diff=1.84839e-13
 -0.000167	 -0.000167	diff=8.2321e-07
 -0.000041	 -0.000041	diff=1.27712e-09
 -0.000000	 -0.000000	diff=3.83453e-13
  0.000000	  0.000000	diff=3.47029e-13
  0.000000	  0.000000	diff=2.38324e-13
 -0.000000	 -0.000000	diff=4.6071e-13
  0.000000	  0.000000	diff=2.05234e-13
  0.000000	  0.000000	diff=1.718e-13
  0.000055	  0.000055	diff=4.22464e-09
  0.000031	  0.000031	diff=2.84871e-08
  0.000001	  0.000001	diff=9.52438e-13
  0.000000	  0.000000	diff=3.51754e-13
  0.000000	  0.000000	diff=7.37492e-12
  0.000000	  0.000000	diff=3.04127e-13
  0.000002	  0.000002	diff=1.7391e-13
  0.000000	  0.000000	diff=5.4158e-13
  0.000041	  0.000042	diff=1.62139e-06
 -0.000089	 -0.000089	diff=2.78163e-09
 -0.000001	 -0.000001	diff=5.47438e-13
 -0.000000	 -0.000000	diff=4.30218e-13
 -0.000000	 -0.000000	diff=5.80738e-13
 -0.000000	 -0.000000	diff=4.95699e-13
 -0.000001	 -0.000001	diff=2.21791e-13
 -0.000000	 -0.000000	diff=8.2266e-13
 -0.000100	 -0.000100	diff=1.49232e-08
  0.000069	  0.000068	diff=1.43545e-08
  local_diff=3.09882e-06
# W_emb_src, [2 4]
 -0.001162	 -0.001162	diff=2.73404e-07
  0.001998	  0.001997	diff=7.75039e-07
 -0.001487	 -0.001487	diff=3.43119e-07
  0.002311	  0.002310	diff=8.76973e-07
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=2.26853e-06
# W_emb_tgt, [2 4]
 -0.009062	 -0.009061	diff=8.53796e-07
 -0.003136	 -0.003135	diff=3.85396e-07
 -0.004123	 -0.004123	diff=8.56602e-07
 -0.001353	 -0.001353	diff=2.27634e-07
  0.004611	  0.004612	diff=4.17262e-07
  0.001362	  0.001362	diff=2.80845e-07
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=3.02154e-06
# W_soft, [4 2]
 -0.014903	 -0.014903	diff=9.79672e-08
 -0.003292	 -0.003292	diff=9.79819e-08
  0.005365	  0.005365	diff=9.79731e-08
  0.012831	  0.012831	diff=9.79869e-08
  0.010052	  0.010052	diff=5.11384e-08
  0.001880	  0.001880	diff=5.11442e-08
 -0.001340	 -0.001340	diff=5.11415e-08
 -0.010593	 -0.010593	diff=5.11469e-08
  local_diff=5.9648e-07
# Num params=104, abs_diff=9.5194e-06
Elapsed time is 0.657349 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s_sos> x y y
  src mask: 0  1  1  1
  tgt input 1: <t_sos> b b <t_eos> <t_eos>
  tgt output 1: b b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=2.37356e-13
  0.000000	  0.000000	diff=5.07596e-13
 -0.000000	 -0.000000	diff=3.89347e-13
  0.000000	  0.000000	diff=2.09694e-13
  0.000000	  0.000000	diff=6.7354e-13
 -0.000000	 -0.000000	diff=3.01608e-13
 -0.000098	 -0.000098	diff=1.71358e-10
 -0.000027	 -0.000027	diff=2.02507e-10
 -0.000000	 -0.000000	diff=4.03735e-13
  0.000000	  0.000000	diff=4.93459e-13
 -0.000000	 -0.000000	diff=1.05589e-12
  0.000000	  0.000000	diff=1.31381e-12
 -0.000000	 -0.000000	diff=5.29186e-13
 -0.000000	 -0.000000	diff=6.33429e-14
 -0.000071	 -0.000071	diff=2.73825e-10
 -0.000016	 -0.000016	diff=2.06476e-10
 -0.000000	 -0.000000	diff=3.1992e-13
  0.000000	  0.000000	diff=3.49978e-14
 -0.000000	 -0.000000	diff=3.31659e-13
  0.000000	  0.000000	diff=5.91489e-13
 -0.000000	 -0.000000	diff=7.90748e-13
 -0.000000	 -0.000000	diff=2.27064e-14
 -0.000000	 -0.000000	diff=1.57994e-10
 -0.000000	 -0.000000	diff=1.19818e-13
  0.000000	  0.000000	diff=3.78066e-14
 -0.000000	 -0.000000	diff=3.79243e-13
  0.000000	  0.000000	diff=3.76031e-13
 -0.000000	 -0.000000	diff=5.89753e-13
  0.000000	  0.000000	diff=5.50325e-13
  0.000000	  0.000000	diff=3.55559e-13
  0.000001	  0.000001	diff=2.3666e-12
  0.000000	  0.000000	diff=4.45165e-10
  local_diff=1.47037e-09
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=7.25711e-14
 -0.000000	 -0.000000	diff=9.41711e-14
 -0.000000	 -0.000000	diff=2.72845e-13
 -0.000000	 -0.000000	diff=4.41692e-14
  0.000000	  0.000000	diff=4.86349e-13
 -0.000000	 -0.000000	diff=4.3558e-13
  0.000000	  0.000000	diff=8.2258e-13
 -0.000001	 -0.000001	diff=3.2864e-12
  0.000000	  0.000000	diff=3.94709e-14
  0.000000	  0.000000	diff=1.44032e-13
  0.000000	  0.000000	diff=2.51421e-13
  0.000000	  0.000000	diff=1.28913e-12
 -0.000000	 -0.000000	diff=4.95312e-13
  0.000000	  0.000000	diff=3.3129e-13
  0.000010	  0.000010	diff=7.19492e-13
 -0.000035	 -0.000035	diff=8.99509e-12
 -0.000000	 -0.000000	diff=4.46887e-13
 -0.000000	 -0.000000	diff=2.6235e-13
 -0.000000	 -0.000000	diff=5.15374e-13
 -0.000000	 -0.000000	diff=8.96287e-14
  0.000000	  0.000000	diff=1.77944e-13
  0.000000	 -0.000000	diff=1.78689e-13
 -0.000000	 -0.000000	diff=2.93359e-11
  0.000000	  0.000000	diff=3.58466e-14
  0.000000	  0.000000	diff=9.04837e-13
  0.000000	  0.000000	diff=9.27368e-13
  0.000000	  0.000000	diff=3.49249e-13
  0.000000	  0.000000	diff=3.77428e-13
  0.000000	 -0.000000	diff=2.36505e-13
  0.000000	  0.000000	diff=2.4404e-13
  0.000000	  0.000000	diff=2.02618e-13
 -0.000000	 -0.000000	diff=4.59638e-10
  local_diff=5.11703e-10
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=3.35442e-13
  0.000000	  0.000000	diff=3.94848e-13
 -0.000000	 -0.000000	diff=8.35513e-13
  0.000000	  0.000000	diff=3.19567e-12
 -0.000000	 -0.000000	diff=3.12538e-13
  0.000000	  0.000000	diff=2.25089e-13
  0.000018	  0.000018	diff=1.56162e-10
 -0.000180	 -0.000180	diff=6.4791e-10
  0.000000	  0.000000	diff=5.97299e-13
 -0.000000	 -0.000000	diff=1.17176e-12
  0.000000	  0.000000	diff=7.39324e-13
 -0.000000	 -0.000000	diff=6.04085e-12
  0.000000	  0.000000	diff=3.74592e-13
 -0.000001	 -0.000001	diff=1.50315e-12
 -0.000019	 -0.000019	diff=5.46561e-10
  0.000267	  0.000267	diff=1.72464e-09
 -0.000000	 -0.000000	diff=7.72659e-13
  0.000000	  0.000000	diff=5.256e-13
  0.000000	  0.000000	diff=1.40037e-13
  0.000000	  0.000000	diff=6.0965e-13
 -0.000000	 -0.000000	diff=1.20597e-13
  0.000000	  0.000000	diff=1.34371e-13
 -0.000000	 -0.000000	diff=8.68219e-14
 -0.000000	 -0.000000	diff=3.16904e-13
 -0.000000	 -0.000000	diff=2.54767e-13
  0.000000	  0.000000	diff=1.13838e-13
  0.000000	  0.000000	diff=3.30865e-13
 -0.000000	 -0.000000	diff=3.9686e-13
 -0.000000	 -0.000000	diff=1.03145e-13
  0.000000	  0.000000	diff=4.09281e-13
 -0.000000	 -0.000000	diff=8.13412e-13
  0.000000	  0.000000	diff=2.02349e-12
  0.000000	  0.000000	diff=4.83992e-13
 -0.000000	 -0.000000	diff=3.21717e-13
  0.000000	  0.000000	diff=3.58882e-13
  0.000000	  0.000000	diff=1.14669e-13
  0.000000	  0.000000	diff=5.65705e-13
 -0.000000	 -0.000000	diff=8.01985e-14
  0.000000	  0.000000	diff=7.736e-10
  0.000000	  0.000000	diff=1.464e-11
  0.000000	  0.000000	diff=3.80087e-14
 -0.000000	 -0.000000	diff=3.63436e-13
 -0.000000	 -0.000000	diff=1.01133e-12
 -0.000000	 -0.000000	diff=7.74789e-14
  0.000000	  0.000000	diff=8.27628e-13
 -0.000000	 -0.000000	diff=5.33543e-13
  0.000001	  0.000001	diff=4.38372e-11
  0.000002	  0.000002	diff=3.02569e-09
  local_diff=6.96069e-09
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=1.92292e-13
 -0.000000	 -0.000000	diff=6.25853e-14
 -0.000000	 -0.000000	diff=2.1148e-13
 -0.000000	 -0.000000	diff=5.64859e-13
  0.000000	  0.000000	diff=8.46261e-14
 -0.000000	 -0.000000	diff=5.17635e-13
  0.000012	  0.000012	diff=2.91316e-10
 -0.000062	 -0.000062	diff=4.91028e-11
  0.000000	  0.000000	diff=3.36282e-13
 -0.000000	 -0.000000	diff=6.32542e-13
  0.000000	  0.000000	diff=4.91868e-13
 -0.000000	 -0.000000	diff=1.5889e-13
  0.000000	  0.000000	diff=6.1663e-13
 -0.000000	 -0.000000	diff=1.73656e-14
  0.000019	  0.000019	diff=7.04199e-09
 -0.000193	 -0.000193	diff=7.89954e-10
  0.000000	  0.000000	diff=8.50074e-14
  0.000000	  0.000000	diff=3.42618e-13
 -0.000000	 -0.000000	diff=1.87641e-13
 -0.000000	 -0.000000	diff=6.48417e-14
 -0.000000	 -0.000000	diff=4.69917e-13
  0.000000	  0.000000	diff=1.03154e-12
  0.000000	  0.000000	diff=1.33143e-09
  0.000000	  0.000000	diff=2.00005e-11
  0.000000	  0.000000	diff=2.25047e-13
  0.000000	  0.000000	diff=1.90105e-13
  0.000000	  0.000000	diff=3.55687e-13
  0.000000	  0.000000	diff=4.70236e-13
  0.000000	  0.000000	diff=5.76478e-13
  0.000000	  0.000000	diff=3.9976e-13
  0.000002	  0.000002	diff=3.88208e-12
 -0.000000	 -0.000000	diff=4.67449e-09
  local_diff=1.42105e-08
# W_emb_src, [2 4]
  0.000077	  0.000077	diff=2.28501e-08
 -0.000079	 -0.000079	diff=6.2331e-08
  0.000060	  0.000060	diff=2.10513e-08
 -0.000053	 -0.000053	diff=5.22341e-08
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.58466e-07
# W_emb_tgt, [2 4]
  0.000078	  0.000078	diff=1.34663e-08
  0.000007	  0.000007	diff=5.13426e-09
 -0.000015	 -0.000015	diff=2.08447e-08
  0.000013	  0.000013	diff=8.10949e-09
  0.000152	  0.000152	diff=3.17758e-08
 -0.000016	 -0.000016	diff=8.84772e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=8.81784e-08
# W_soft, [4 2]
 -0.000066	 -0.000066	diff=2.39247e-12
 -0.000008	 -0.000008	diff=2.44774e-12
  0.000061	  0.000061	diff=3.34885e-12
  0.000013	  0.000013	diff=2.46908e-12
 -0.000231	 -0.000231	diff=3.58424e-11
 -0.000009	 -0.000009	diff=3.57434e-11
  0.000264	  0.000264	diff=3.59311e-11
 -0.000024	 -0.000024	diff=3.53022e-11
  local_diff=1.53477e-10
# Num params=168, abs_diff=2.69951e-07
Elapsed time is 1.380867 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s_sos> x y y
  src mask: 0  1  1  1
  tgt input 1: <t_sos> b b <t_eos> <t_eos>
  tgt output 1: b b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=4.50022e-13
  0.000000	  0.000000	diff=3.70299e-13
  0.000000	  0.000000	diff=3.80875e-13
  0.000000	  0.000000	diff=3.99373e-14
  0.000000	  0.000000	diff=7.13939e-13
 -0.000000	 -0.000000	diff=4.4373e-13
 -0.000126	 -0.000126	diff=4.99498e-10
 -0.000035	 -0.000035	diff=2.83971e-10
 -0.000000	 -0.000000	diff=2.37622e-13
  0.000000	  0.000000	diff=6.06675e-13
 -0.000000	 -0.000000	diff=1.68961e-12
  0.000000	  0.000000	diff=1.35066e-12
 -0.000000	 -0.000000	diff=2.34582e-13
 -0.000000	 -0.000000	diff=5.55439e-13
 -0.000076	 -0.000076	diff=6.82937e-10
 -0.000023	 -0.000023	diff=2.56518e-10
 -0.000000	 -0.000000	diff=8.42783e-14
  0.000000	  0.000000	diff=1.12563e-13
 -0.000000	 -0.000000	diff=3.91041e-13
  0.000000	  0.000000	diff=4.03977e-13
 -0.000000	 -0.000000	diff=8.34396e-14
 -0.000000	 -0.000000	diff=6.422e-13
  0.000000	  0.000000	diff=4.11999e-10
 -0.000000	 -0.000000	diff=1.54629e-12
  0.000000	  0.000000	diff=2.90295e-13
 -0.000000	 -0.000000	diff=1.29958e-13
  0.000000	  0.000000	diff=5.31788e-13
 -0.000000	 -0.000000	diff=4.09935e-13
  0.000000	  0.000000	diff=6.56176e-13
  0.000000	  0.000000	diff=5.51095e-13
  0.000001	  0.000001	diff=3.57575e-12
  0.000000	  0.000000	diff=3.295e-10
  local_diff=2.4809e-09
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=4.86688e-13
 -0.000000	 -0.000000	diff=4.25432e-14
 -0.000000	 -0.000000	diff=2.67191e-13
 -0.000000	 -0.000000	diff=2.14032e-13
  0.000000	  0.000000	diff=1.74025e-13
 -0.000000	 -0.000000	diff=1.94983e-13
  0.000002	  0.000002	diff=1.39909e-12
 -0.000010	 -0.000010	diff=5.38959e-12
  0.000000	  0.000000	diff=7.75021e-13
  0.000000	  0.000000	diff=9.37984e-13
  0.000000	  0.000000	diff=1.3982e-13
  0.000000	  0.000000	diff=5.72212e-13
 -0.000000	 -0.000000	diff=7.80079e-14
  0.000000	  0.000000	diff=6.22788e-13
  0.000013	  0.000013	diff=3.27014e-12
 -0.000037	 -0.000037	diff=1.3136e-11
 -0.000000	 -0.000000	diff=6.84717e-13
 -0.000000	 -0.000000	diff=6.95833e-13
 -0.000000	 -0.000000	diff=4.82485e-13
 -0.000000	 -0.000000	diff=4.3266e-13
  0.000000	  0.000000	diff=4.17671e-13
  0.000000	 -0.000000	diff=2.33146e-13
  0.000000	  0.000000	diff=1.56425e-10
  0.000000	  0.000000	diff=1.04659e-13
  0.000000	  0.000000	diff=1.3877e-13
  0.000000	  0.000000	diff=1.16207e-13
  0.000000	  0.000000	diff=3.19836e-13
  0.000000	  0.000000	diff=7.67281e-13
  0.000000	 -0.000000	diff=3.80023e-13
  0.000000	  0.000000	diff=3.94946e-13
  0.000000	  0.000000	diff=1.42127e-14
 -0.000000	 -0.000000	diff=1.61812e-10
  local_diff=3.5112e-10
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=2.49779e-13
  0.000000	  0.000000	diff=2.91339e-13
 -0.000000	 -0.000000	diff=7.47188e-13
  0.000000	  0.000000	diff=5.57496e-12
 -0.000000	 -0.000000	diff=1.09904e-12
  0.000001	  0.000001	diff=2.31986e-13
  0.000034	  0.000034	diff=1.85303e-10
 -0.000223	 -0.000223	diff=1.48637e-09
  0.000000	  0.000000	diff=2.14712e-13
 -0.000001	 -0.000001	diff=9.90151e-13
  0.000000	  0.000000	diff=1.84494e-12
 -0.000000	 -0.000000	diff=7.11377e-12
  0.000000	  0.000000	diff=2.77917e-13
 -0.000001	 -0.000001	diff=7.97686e-13
 -0.000025	 -0.000025	diff=5.78503e-10
  0.000209	  0.000209	diff=2.1592e-09
  0.000000	  0.000000	diff=1.70135e-13
  0.000000	  0.000000	diff=1.27117e-13
  0.000000	  0.000000	diff=3.66828e-13
  0.000000	  0.000000	diff=3.02834e-13
  0.000000	  0.000000	diff=6.78474e-13
  0.000000	  0.000000	diff=3.8408e-14
 -0.000000	 -0.000000	diff=9.91711e-14
 -0.000000	 -0.000000	diff=6.37686e-13
  0.000000	  0.000000	diff=1.04146e-12
 -0.000000	 -0.000000	diff=7.84685e-13
  0.000000	  0.000000	diff=1.16384e-15
  0.000000	  0.000000	diff=1.88798e-13
  0.000000	  0.000000	diff=7.66524e-13
  0.000000	  0.000000	diff=6.70968e-14
 -0.000000	 -0.000000	diff=5.60973e-13
  0.000000	  0.000000	diff=3.1706e-12
 -0.000000	 -0.000000	diff=3.26674e-13
 -0.000000	 -0.000000	diff=2.13518e-14
 -0.000000	 -0.000000	diff=1.64235e-13
  0.000000	  0.000000	diff=2.23502e-13
 -0.000000	 -0.000000	diff=1.60861e-13
 -0.000000	 -0.000000	diff=9.96673e-14
  0.000000	  0.000000	diff=2.02144e-09
  0.000001	  0.000001	diff=2.67663e-11
  0.000000	  0.000000	diff=6.95348e-13
 -0.000000	 -0.000000	diff=2.99291e-13
 -0.000000	 -0.000000	diff=2.26233e-13
 -0.000000	 -0.000000	diff=9.57078e-14
  0.000000	  0.000000	diff=3.11986e-13
 -0.000000	 -0.000000	diff=1.14376e-13
  0.000000	  0.000000	diff=6.38723e-11
  0.000003	  0.000003	diff=2.472e-09
  local_diff=9.02462e-09
# W_tgt{2}, [8 4]
  0.000000	  0.000000	diff=3.49132e-13
 -0.000000	 -0.000000	diff=5.41798e-13
 -0.000000	 -0.000000	diff=9.85302e-13
 -0.000000	 -0.000000	diff=9.17212e-13
  0.000000	  0.000000	diff=1.53024e-13
 -0.000000	 -0.000000	diff=7.73917e-13
  0.000026	  0.000026	diff=1.01983e-09
 -0.000135	 -0.000135	diff=2.68099e-10
  0.000000	  0.000000	diff=4.87922e-13
 -0.000000	 -0.000000	diff=9.34949e-13
  0.000000	  0.000000	diff=4.47553e-13
 -0.000000	 -0.000000	diff=3.93564e-13
  0.000000	  0.000000	diff=4.40486e-13
 -0.000000	 -0.000000	diff=1.83329e-13
  0.000042	  0.000042	diff=1.11818e-08
 -0.000238	 -0.000238	diff=5.86472e-10
  0.000000	  0.000000	diff=1.94164e-13
  0.000000	  0.000000	diff=3.98178e-13
 -0.000000	 -0.000000	diff=2.66335e-13
 -0.000000	 -0.000000	diff=6.16989e-13
 -0.000000	 -0.000000	diff=1.29279e-13
  0.000000	  0.000000	diff=2.0376e-13
  0.000000	  0.000000	diff=1.40829e-09
  0.000000	  0.000000	diff=1.78205e-11
  0.000000	  0.000000	diff=3.05454e-13
  0.000000	  0.000000	diff=1.76299e-13
  0.000000	  0.000000	diff=9.44136e-13
  0.000000	  0.000000	diff=1.49885e-13
  0.000000	  0.000000	diff=2.66131e-13
  0.000000	  0.000000	diff=2.68875e-13
  0.000002	  0.000002	diff=6.76649e-12
  0.000001	  0.000001	diff=6.27277e-09
  local_diff=2.07724e-08
# W_emb_src, [2 4]
  0.000086	  0.000086	diff=3.56917e-08
 -0.000080	 -0.000080	diff=8.6878e-08
  0.000092	  0.000092	diff=4.07016e-08
 -0.000076	 -0.000076	diff=8.65711e-08
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=2.49842e-07
# W_emb_tgt, [2 4]
  0.000114	  0.000114	diff=1.6979e-08
  0.000004	  0.000004	diff=5.50205e-09
 -0.000010	 -0.000010	diff=2.68157e-08
  0.000005	  0.000005	diff=3.08463e-09
  0.000168	  0.000168	diff=5.79362e-08
 -0.000017	 -0.000017	diff=1.19392e-08
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.22257e-07
# W_soft, [4 2]
 -0.000104	 -0.000104	diff=9.31198e-12
 -0.000010	 -0.000010	diff=8.68877e-12
  0.000089	  0.000089	diff=8.54213e-12
  0.000025	  0.000025	diff=8.98425e-12
 -0.000339	 -0.000339	diff=6.57343e-11
  0.000031	  0.000031	diff=6.5345e-11
  0.000300	  0.000300	diff=6.59517e-11
  0.000008	  0.000008	diff=6.58698e-11
  local_diff=2.98428e-10
# Num params=168, abs_diff=4.05027e-07
Elapsed time is 1.377720 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 176, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 176
  src input 1: <s_sos> y x x
  src mask: 0  1  1  1
  tgt input 1: <t_sos> a b <t_eos> <t_eos>
  tgt output 1: a b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000000	 -0.000000	diff=1.29809e-12
  0.000000	  0.000000	diff=4.72032e-13
 -0.000000	 -0.000000	diff=5.01385e-13
  0.000000	  0.000000	diff=1.28648e-13
 -0.000000	 -0.000000	diff=7.48433e-13
 -0.000000	 -0.000000	diff=3.34181e-13
 -0.000005	 -0.000005	diff=1.12547e-11
 -0.000004	 -0.000004	diff=2.08209e-11
 -0.000000	 -0.000000	diff=1.86629e-13
  0.000000	  0.000000	diff=4.22535e-13
 -0.000000	 -0.000000	diff=3.46412e-13
  0.000000	  0.000000	diff=1.0116e-13
 -0.000000	 -0.000000	diff=9.61329e-14
 -0.000000	 -0.000000	diff=1.93293e-13
 -0.000004	 -0.000004	diff=2.07449e-11
 -0.000003	 -0.000003	diff=2.1966e-11
  0.000000	  0.000000	diff=2.85154e-13
  0.000000	  0.000000	diff=6.73134e-13
 -0.000000	 -0.000000	diff=5.52306e-13
  0.000000	  0.000000	diff=1.90207e-13
 -0.000000	 -0.000000	diff=3.88981e-13
 -0.000000	 -0.000000	diff=1.41856e-13
 -0.000000	 -0.000000	diff=6.69672e-11
 -0.000000	 -0.000000	diff=5.26296e-13
 -0.000000	 -0.000000	diff=2.00413e-14
 -0.000000	 -0.000000	diff=3.23243e-13
  0.000000	  0.000000	diff=6.23967e-13
 -0.000000	 -0.000000	diff=4.73512e-13
  0.000000	  0.000000	diff=8.53138e-13
  0.000000	  0.000000	diff=4.36389e-13
  0.000000	  0.000000	diff=1.00471e-12
  0.000000	  0.000000	diff=1.21745e-10
  local_diff=2.74821e-10
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=3.69504e-13
 -0.000000	 -0.000000	diff=1.75906e-13
 -0.000000	 -0.000000	diff=9.09027e-13
 -0.000000	 -0.000000	diff=5.04915e-13
 -0.000000	 -0.000000	diff=6.28769e-13
  0.000000	  0.000000	diff=6.79184e-13
 -0.000000	 -0.000000	diff=3.19573e-13
  0.000000	  0.000000	diff=3.06244e-13
  0.000000	  0.000000	diff=1.55822e-13
  0.000000	  0.000000	diff=7.99431e-14
  0.000000	  0.000000	diff=1.77343e-13
  0.000000	  0.000000	diff=4.57342e-13
  0.000000	  0.000000	diff=1.18427e-13
 -0.000000	 -0.000000	diff=1.6696e-13
  0.000001	  0.000001	diff=1.39366e-13
 -0.000002	 -0.000002	diff=9.22467e-13
 -0.000000	 -0.000000	diff=6.70765e-13
 -0.000000	 -0.000000	diff=6.53141e-13
  0.000000	 -0.000000	diff=9.18343e-14
 -0.000000	 -0.000000	diff=1.04067e-13
 -0.000000	 -0.000000	diff=5.3851e-13
  0.000000	  0.000000	diff=9.77316e-13
 -0.000000	 -0.000000	diff=1.73396e-12
  0.000000	  0.000000	diff=3.48734e-13
 -0.000000	  0.000000	diff=7.63421e-13
  0.000000	  0.000000	diff=8.10613e-15
  0.000000	  0.000000	diff=1.26196e-13
  0.000000	  0.000000	diff=2.64636e-14
  0.000000	  0.000000	diff=2.37493e-13
 -0.000000	 -0.000000	diff=7.79489e-13
  0.000000	  0.000000	diff=3.67647e-13
 -0.000000	 -0.000000	diff=1.06692e-10
  local_diff=1.2023e-10
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=6.26856e-13
  0.000000	  0.000000	diff=3.32873e-13
 -0.000000	 -0.000000	diff=5.12257e-13
  0.000000	  0.000000	diff=4.05323e-13
 -0.000000	 -0.000000	diff=5.08563e-13
  0.000000	  0.000000	diff=3.03378e-13
  0.000001	  0.000001	diff=6.48329e-12
 -0.000007	 -0.000007	diff=6.10862e-11
  0.000000	  0.000000	diff=2.12075e-13
 -0.000000	 -0.000000	diff=4.1157e-13
 -0.000000	 -0.000000	diff=1.14227e-13
 -0.000000	 -0.000000	diff=4.62645e-14
  0.000000	  0.000000	diff=7.80676e-13
 -0.000000	 -0.000000	diff=1.7951e-14
 -0.000001	 -0.000001	diff=1.31194e-11
  0.000021	  0.000021	diff=1.45207e-10
  0.000000	  0.000000	diff=7.64479e-16
  0.000000	  0.000000	diff=4.51798e-14
  0.000000	 -0.000000	diff=2.67019e-15
  0.000000	  0.000000	diff=2.50182e-13
 -0.000000	 -0.000000	diff=7.09404e-13
  0.000000	  0.000000	diff=2.25508e-13
  0.000000	  0.000000	diff=5.73743e-13
 -0.000000	 -0.000000	diff=7.91033e-14
  0.000000	  0.000000	diff=5.01612e-15
  0.000000	 -0.000000	diff=9.69634e-14
 -0.000000	  0.000000	diff=7.12247e-13
 -0.000000	  0.000000	diff=1.05171e-12
 -0.000000	  0.000000	diff=7.14214e-13
  0.000000	  0.000000	diff=1.38291e-13
  0.000000	  0.000000	diff=7.39393e-13
 -0.000000	 -0.000000	diff=2.05944e-13
  0.000000	  0.000000	diff=1.49535e-13
  0.000000	  0.000000	diff=6.84271e-14
  0.000000	  0.000000	diff=2.28195e-13
  0.000000	  0.000000	diff=7.72973e-15
  0.000000	  0.000000	diff=1.08441e-12
  0.000000	  0.000000	diff=1.6758e-13
 -0.000000	 -0.000000	diff=1.24296e-11
 -0.000000	 -0.000000	diff=1.68175e-12
 -0.000000	 -0.000000	diff=8.56865e-13
 -0.000000	 -0.000000	diff=4.61473e-13
  0.000000	  0.000000	diff=3.89902e-13
 -0.000000	 -0.000000	diff=3.78733e-13
  0.000000	  0.000000	diff=4.05268e-13
 -0.000000	 -0.000000	diff=1.36078e-13
 -0.000000	 -0.000000	diff=1.18261e-12
  0.000000	  0.000000	diff=4.77178e-10
  local_diff=7.32525e-10
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=6.1669e-15
 -0.000000	 -0.000000	diff=1.25728e-13
  0.000000	  0.000000	diff=3.48778e-13
 -0.000000	 -0.000000	diff=7.52668e-13
 -0.000000	 -0.000000	diff=1.18867e-12
 -0.000000	 -0.000000	diff=4.35997e-13
 -0.000000	 -0.000000	diff=3.05642e-13
 -0.000005	 -0.000005	diff=4.6174e-12
 -0.000000	 -0.000000	diff=2.79035e-13
 -0.000000	 -0.000000	diff=7.23714e-13
 -0.000000	 -0.000000	diff=8.89231e-15
  0.000000	  0.000000	diff=5.15174e-13
 -0.000000	 -0.000000	diff=1.47692e-13
 -0.000000	 -0.000000	diff=1.30966e-13
 -0.000000	 -0.000000	diff=6.67823e-13
 -0.000009	 -0.000009	diff=6.59024e-11
  0.000000	 -0.000000	diff=3.72394e-15
  0.000000	  0.000000	diff=6.41518e-13
  0.000000	  0.000000	diff=1.22134e-13
 -0.000000	 -0.000000	diff=2.84323e-13
  0.000000	  0.000000	diff=5.98169e-13
  0.000000	  0.000000	diff=2.3277e-13
  0.000000	  0.000000	diff=7.97911e-13
  0.000000	  0.000000	diff=1.46235e-12
 -0.000000	  0.000000	diff=7.47401e-13
 -0.000000	 -0.000000	diff=4.0464e-14
  0.000000	 -0.000000	diff=9.38321e-14
  0.000000	  0.000000	diff=1.71244e-13
  0.000000	 -0.000000	diff=7.984e-14
  0.000000	  0.000000	diff=5.2857e-13
 -0.000000	 -0.000000	diff=2.51705e-13
  0.000000	  0.000000	diff=1.79486e-10
  local_diff=2.61699e-10
# W_emb_src, [2 4]
  0.000004	  0.000004	diff=1.45355e-09
 -0.000001	 -0.000001	diff=1.31822e-09
  0.000001	  0.000001	diff=7.73284e-10
  0.000001	  0.000001	diff=8.86695e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=4.43175e-09
# W_emb_tgt, [2 4]
  0.000002	  0.000002	diff=1.17525e-09
 -0.000001	 -0.000001	diff=3.12443e-10
  0.000005	  0.000005	diff=1.07371e-09
 -0.000001	 -0.000001	diff=3.14938e-10
  0.000008	  0.000008	diff=1.72009e-09
 -0.000001	 -0.000001	diff=3.94204e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=4.99063e-09
# W_h, [2 4]
  0.000005	  0.000005	diff=1.10838e-12
  0.000000	  0.000000	diff=4.51328e-14
 -0.000007	 -0.000007	diff=3.95799e-13
 -0.000001	 -0.000001	diff=9.31476e-13
  0.000001	  0.000001	diff=5.9363e-13
  0.000006	  0.000006	diff=2.50651e-12
  0.000010	  0.000010	diff=2.02189e-11
 -0.000001	 -0.000001	diff=9.41717e-12
  local_diff=3.5217e-11
# W_soft, [4 2]
  0.000000	  0.000000	diff=1.05994e-12
 -0.000007	 -0.000007	diff=1.15998e-13
  0.000008	  0.000008	diff=1.05759e-13
 -0.000001	 -0.000001	diff=1.27636e-13
  0.000000	  0.000000	diff=5.43184e-13
 -0.000008	 -0.000008	diff=4.9301e-13
  0.000010	  0.000010	diff=7.64531e-13
 -0.000001	 -0.000001	diff=3.30904e-13
  local_diff=3.54096e-12
# Num params=176, abs_diff=1.08504e-08
Elapsed time is 2.093677 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 4, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_pos=4 v_pos=2 W_h=8 W_soft=8
# assert = 0
# attnFunc = 4
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# distSigma = 0.5
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <t_sos> a b <t_eos> <t_eos>
  tgt output 1: a b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=1.19316e-12
  0.000000	  0.000000	diff=5.25514e-13
  0.000000	  0.000000	diff=8.61272e-13
  0.000000	  0.000000	diff=4.57537e-13
  0.000000	  0.000000	diff=3.04725e-13
 -0.000000	 -0.000000	diff=8.9215e-13
 -0.000004	 -0.000004	diff=1.27082e-11
 -0.000003	 -0.000003	diff=1.39994e-11
 -0.000000	 -0.000000	diff=7.42536e-13
  0.000000	  0.000000	diff=9.00655e-13
 -0.000000	 -0.000000	diff=1.26372e-12
  0.000000	  0.000000	diff=7.15008e-13
 -0.000000	 -0.000000	diff=1.13328e-12
 -0.000000	 -0.000000	diff=6.70307e-13
 -0.000001	 -0.000001	diff=1.72214e-11
 -0.000002	 -0.000002	diff=1.69843e-11
 -0.000000	 -0.000000	diff=1.52958e-12
  0.000000	  0.000000	diff=3.89761e-13
 -0.000000	 -0.000000	diff=1.20854e-12
  0.000000	  0.000000	diff=1.11941e-12
 -0.000000	 -0.000000	diff=4.56684e-13
 -0.000000	 -0.000000	diff=1.42192e-12
  0.000000	  0.000000	diff=6.32524e-11
 -0.000000	 -0.000000	diff=1.22958e-12
  0.000000	  0.000000	diff=8.00632e-13
 -0.000000	 -0.000000	diff=7.68008e-13
  0.000000	  0.000000	diff=2.74699e-13
 -0.000000	 -0.000000	diff=1.16799e-12
  0.000000	  0.000000	diff=7.70651e-13
  0.000000	  0.000000	diff=4.31078e-13
  0.000000	  0.000000	diff=6.18544e-13
  0.000000	  0.000000	diff=5.7544e-11
  local_diff=2.03557e-10
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=1.48009e-13
 -0.000000	 -0.000000	diff=4.90446e-13
 -0.000000	 -0.000000	diff=6.30948e-13
 -0.000000	 -0.000000	diff=9.33633e-13
  0.000000	  0.000000	diff=5.53051e-13
  0.000000	  0.000000	diff=7.00088e-13
  0.000000	  0.000000	diff=1.33487e-12
 -0.000001	 -0.000001	diff=5.2937e-13
  0.000000	  0.000000	diff=5.40374e-13
  0.000000	  0.000000	diff=1.26251e-12
  0.000000	  0.000000	diff=1.03616e-12
  0.000000	  0.000000	diff=8.57748e-13
 -0.000000	 -0.000000	diff=1.26854e-12
 -0.000000	 -0.000000	diff=9.12533e-13
  0.000002	  0.000002	diff=7.44372e-13
 -0.000001	 -0.000001	diff=2.83933e-13
 -0.000000	 -0.000000	diff=9.28133e-13
 -0.000000	 -0.000000	diff=3.9387e-14
 -0.000000	 -0.000000	diff=1.32097e-12
 -0.000000	 -0.000000	diff=7.22048e-13
  0.000000	  0.000000	diff=2.82249e-13
  0.000000	 -0.000000	diff=3.30039e-15
  0.000000	  0.000000	diff=3.00829e-11
 -0.000000	 -0.000000	diff=2.55928e-13
  0.000000	  0.000000	diff=6.18998e-13
  0.000000	  0.000000	diff=4.28151e-13
 -0.000000	  0.000000	diff=7.94945e-13
  0.000000	  0.000000	diff=9.11263e-13
 -0.000000	 -0.000000	diff=1.07348e-12
 -0.000000	  0.000000	diff=7.10919e-13
 -0.000000	 -0.000000	diff=7.76953e-13
 -0.000000	 -0.000000	diff=2.11587e-11
  local_diff=7.23349e-11
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=1.30361e-12
  0.000000	  0.000000	diff=3.03323e-13
  0.000000	  0.000000	diff=9.3205e-13
  0.000000	  0.000000	diff=2.75498e-13
  0.000000	  0.000000	diff=1.38828e-12
  0.000000	  0.000000	diff=4.41583e-13
 -0.000001	 -0.000001	diff=1.61674e-11
 -0.000020	 -0.000020	diff=1.03957e-10
 -0.000000	 -0.000000	diff=5.66989e-14
 -0.000000	 -0.000000	diff=7.00393e-13
 -0.000000	 -0.000000	diff=6.89462e-13
 -0.000000	 -0.000000	diff=2.24619e-12
 -0.000000	 -0.000000	diff=7.65289e-13
 -0.000000	 -0.000000	diff=8.27266e-13
  0.000001	  0.000001	diff=4.89858e-11
  0.000037	  0.000037	diff=2.54768e-10
  0.000000	 -0.000000	diff=9.3274e-17
 -0.000000	  0.000000	diff=7.23516e-13
  0.000000	 -0.000000	diff=2.13714e-14
 -0.000000	 -0.000000	diff=5.81188e-13
  0.000000	 -0.000000	diff=1.41293e-14
  0.000000	 -0.000000	diff=9.54344e-14
  0.000000	  0.000000	diff=1.94971e-13
  0.000000	  0.000000	diff=2.1505e-13
  0.000000	  0.000000	diff=2.75877e-14
  0.000000	  0.000000	diff=2.32869e-14
  0.000000	  0.000000	diff=4.40847e-14
  0.000000	  0.000000	diff=7.68421e-13
  0.000000	  0.000000	diff=6.59804e-14
  0.000000	  0.000000	diff=4.56802e-13
 -0.000000	 -0.000000	diff=2.96472e-13
 -0.000000	 -0.000000	diff=4.42677e-14
 -0.000000	 -0.000000	diff=1.17561e-12
  0.000000	  0.000000	diff=1.34363e-12
  0.000000	  0.000000	diff=4.27521e-13
 -0.000000	 -0.000000	diff=5.8053e-13
 -0.000000	 -0.000000	diff=8.09007e-14
  0.000000	  0.000000	diff=9.38381e-13
 -0.000000	 -0.000000	diff=3.27266e-11
  0.000000	  0.000000	diff=4.58267e-12
 -0.000000	 -0.000000	diff=1.08913e-12
 -0.000000	 -0.000000	diff=5.72859e-13
 -0.000000	 -0.000000	diff=1.51546e-12
 -0.000000	 -0.000000	diff=1.73423e-13
 -0.000000	 -0.000000	diff=8.24609e-13
 -0.000000	 -0.000000	diff=5.98038e-13
 -0.000000	 -0.000000	diff=1.03234e-12
  0.000001	  0.000001	diff=9.17243e-10
  local_diff=1.40229e-09
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=3.7589e-13
 -0.000000	 -0.000000	diff=8.17744e-13
 -0.000000	 -0.000000	diff=7.42787e-13
 -0.000000	 -0.000000	diff=3.31013e-13
 -0.000000	 -0.000000	diff=1.88675e-13
 -0.000000	 -0.000000	diff=4.34368e-13
 -0.000000	 -0.000000	diff=8.0626e-13
 -0.000001	 -0.000001	diff=2.94136e-12
  0.000000	  0.000000	diff=1.28743e-13
 -0.000000	 -0.000000	diff=3.80849e-13
  0.000000	  0.000000	diff=9.82502e-13
 -0.000000	 -0.000000	diff=6.55045e-13
  0.000000	  0.000000	diff=5.64755e-13
 -0.000000	 -0.000000	diff=1.22611e-12
  0.000009	  0.000009	diff=3.9389e-11
 -0.000022	 -0.000022	diff=1.35312e-10
 -0.000000	  0.000000	diff=1.43671e-12
  0.000000	  0.000000	diff=7.00665e-13
 -0.000000	 -0.000000	diff=1.00901e-12
 -0.000000	 -0.000000	diff=9.81917e-13
 -0.000000	 -0.000000	diff=7.74495e-13
  0.000000	  0.000000	diff=1.21975e-12
  0.000000	  0.000000	diff=7.06914e-11
  0.000000	  0.000000	diff=7.77738e-13
  0.000000	  0.000000	diff=2.55365e-13
  0.000000	  0.000000	diff=2.10134e-13
  0.000000	  0.000000	diff=4.26597e-13
  0.000000	  0.000000	diff=3.50347e-13
  0.000000	  0.000000	diff=1.82186e-13
  0.000000	  0.000000	diff=1.10487e-13
 -0.000000	 -0.000000	diff=5.07277e-13
  0.000000	  0.000000	diff=6.54767e-10
  local_diff=9.19678e-10
# W_emb_src, [2 4]
  0.000003	  0.000003	diff=6.79631e-10
  0.000002	  0.000002	diff=1.52156e-09
  0.000002	  0.000002	diff=6.26986e-10
  0.000004	  0.000004	diff=1.65591e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=4.48408e-09
# W_emb_tgt, [2 4]
  0.000020	  0.000020	diff=3.65399e-09
 -0.000000	 -0.000000	diff=5.42392e-10
  0.000009	  0.000009	diff=2.13843e-09
 -0.000001	 -0.000001	diff=4.59631e-10
  0.000018	  0.000018	diff=3.44125e-09
 -0.000001	 -0.000001	diff=5.352e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.07709e-08
# W_pos, [2 2]
  0.000000	 -0.000000	diff=8.47615e-16
  0.000000	 -0.000000	diff=1.07304e-15
  0.000000	 -0.000000	diff=3.10661e-16
  0.000000	 -0.000000	diff=3.93283e-16
  local_diff=2.6246e-15
# v_pos, [1 2]
  0.000000	  0.000000	diff=3.25878e-15
  0.000000	  0.000000	diff=1.346e-14
  local_diff=1.67188e-14
# W_h, [2 4]
  0.000000	  0.000000	diff=3.3926e-13
 -0.000001	 -0.000001	diff=9.56742e-13
  0.000000	  0.000000	diff=3.36891e-13
 -0.000000	 -0.000000	diff=4.52117e-14
 -0.000001	 -0.000001	diff=6.62112e-13
  0.000001	  0.000001	diff=2.73314e-12
 -0.000014	 -0.000014	diff=6.76858e-11
  0.000016	  0.000016	diff=1.28148e-10
  local_diff=2.00907e-10
# W_soft, [4 2]
  0.000008	  0.000008	diff=1.00863e-12
  0.000001	  0.000001	diff=1.74127e-13
 -0.000009	 -0.000009	diff=1.29469e-12
 -0.000000	 -0.000000	diff=2.4386e-15
 -0.000026	 -0.000026	diff=3.9336e-14
 -0.000007	 -0.000007	diff=3.23666e-13
  0.000029	  0.000029	diff=1.73664e-13
  0.000005	  0.000005	diff=5.21204e-13
  local_diff=3.53775e-12
# Num params=182, abs_diff=1.80573e-08
Elapsed time is 2.696456 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 180, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 180
  src input 1: <s_sos> <s_sos> x y
  src mask: 0  0  1  1
  tgt input 1: <t_sos> a <t_eos> <t_eos> <t_eos>
  tgt output 1: a <t_eos> <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  0  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=1.02977e-13
  0.000000	  0.000000	diff=3.15604e-13
  0.000000	  0.000000	diff=9.84375e-13
  0.000000	  0.000000	diff=6.26834e-13
  0.000000	  0.000000	diff=3.67135e-13
  0.000000	  0.000000	diff=5.20382e-13
 -0.000002	 -0.000002	diff=2.81562e-12
 -0.000002	 -0.000002	diff=6.85003e-12
  0.000000	  0.000000	diff=4.481e-13
  0.000000	  0.000000	diff=3.66103e-13
  0.000000	  0.000000	diff=1.4768e-13
  0.000000	  0.000000	diff=6.79298e-13
  0.000000	  0.000000	diff=5.55916e-13
 -0.000000	 -0.000000	diff=5.22302e-13
  0.000001	  0.000001	diff=2.36829e-12
 -0.000002	 -0.000002	diff=2.67085e-11
 -0.000000	 -0.000000	diff=2.72079e-13
  0.000000	  0.000000	diff=5.59495e-13
 -0.000000	 -0.000000	diff=2.61263e-13
  0.000000	  0.000000	diff=3.4899e-13
 -0.000000	 -0.000000	diff=3.98981e-13
 -0.000000	 -0.000000	diff=1.04214e-12
  0.000000	  0.000000	diff=4.39509e-11
 -0.000000	 -0.000000	diff=7.35832e-13
  0.000000	  0.000000	diff=9.30925e-13
 -0.000000	 -0.000000	diff=2.25924e-14
 -0.000000	 -0.000000	diff=5.42118e-13
 -0.000000	 -0.000000	diff=1.11924e-13
  0.000000	  0.000000	diff=1.02733e-12
  0.000000	  0.000000	diff=1.37109e-13
 -0.000000	 -0.000000	diff=4.08652e-13
  0.000000	  0.000000	diff=2.95884e-11
  local_diff=1.24718e-10
# W_src{2}, [8 4]
  0.000000	  0.000000	diff=1.03861e-13
 -0.000000	 -0.000000	diff=3.77864e-14
  0.000000	  0.000000	diff=5.40195e-13
 -0.000000	 -0.000000	diff=5.63711e-13
 -0.000000	 -0.000000	diff=5.6202e-13
 -0.000000	 -0.000000	diff=2.75769e-13
 -0.000001	 -0.000001	diff=1.19444e-13
 -0.000002	 -0.000002	diff=7.50517e-13
 -0.000000	 -0.000000	diff=3.60201e-13
  0.000000	  0.000000	diff=2.42941e-13
 -0.000000	 -0.000000	diff=2.09301e-13
  0.000000	  0.000000	diff=3.28011e-13
  0.000000	  0.000000	diff=1.44074e-13
  0.000000	  0.000000	diff=5.85443e-14
 -0.000003	 -0.000003	diff=7.00656e-14
 -0.000006	 -0.000006	diff=1.80958e-12
  0.000000	  0.000000	diff=1.08748e-12
 -0.000000	 -0.000000	diff=4.3926e-13
  0.000000	  0.000000	diff=1.1764e-12
  0.000000	 -0.000000	diff=1.58272e-13
  0.000000	 -0.000000	diff=1.44054e-12
  0.000000	 -0.000000	diff=3.83315e-13
 -0.000000	 -0.000000	diff=8.0368e-12
 -0.000000	 -0.000000	diff=4.39527e-13
  0.000000	 -0.000000	diff=3.836e-13
  0.000000	  0.000000	diff=5.83432e-14
  0.000000	 -0.000000	diff=3.05902e-13
  0.000000	  0.000000	diff=1.95773e-13
  0.000000	  0.000000	diff=1.39666e-12
  0.000000	  0.000000	diff=9.47488e-13
 -0.000000	 -0.000000	diff=3.23042e-13
  0.000000	  0.000000	diff=6.93895e-11
  local_diff=9.2338e-11
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=1.45554e-12
  0.000000	  0.000000	diff=8.04841e-14
  0.000000	  0.000000	diff=1.48225e-13
  0.000000	  0.000000	diff=6.45711e-13
  0.000000	  0.000000	diff=1.26888e-12
  0.000000	  0.000000	diff=5.42293e-13
 -0.000002	 -0.000002	diff=1.68896e-11
 -0.000025	 -0.000025	diff=8.60559e-11
 -0.000000	 -0.000000	diff=4.51956e-13
 -0.000000	 -0.000000	diff=7.27629e-13
 -0.000000	 -0.000000	diff=6.43595e-13
 -0.000000	 -0.000000	diff=2.88992e-12
 -0.000000	 -0.000000	diff=9.40351e-13
 -0.000000	 -0.000000	diff=2.41856e-13
  0.000005	  0.000005	diff=6.0157e-11
  0.000035	  0.000035	diff=8.18742e-11
  0.000000	 -0.000000	diff=7.37537e-13
  0.000000	  0.000000	diff=1.23765e-13
  0.000000	  0.000000	diff=4.72412e-14
  0.000000	  0.000000	diff=1.73071e-14
  0.000000	  0.000000	diff=6.98809e-13
  0.000000	  0.000000	diff=1.87228e-13
 -0.000000	 -0.000000	diff=2.57438e-13
 -0.000000	 -0.000000	diff=4.33974e-13
  0.000000	 -0.000000	diff=3.06119e-15
  0.000000	 -0.000000	diff=2.89033e-14
  0.000000	  0.000000	diff=1.41776e-12
  0.000000	 -0.000000	diff=8.24666e-13
  0.000000	  0.000000	diff=2.58243e-16
  0.000000	 -0.000000	diff=7.81117e-13
 -0.000000	 -0.000000	diff=4.98252e-13
  0.000000	  0.000000	diff=2.68078e-13
  0.000000	  0.000000	diff=8.18701e-13
  0.000000	  0.000000	diff=1.49504e-13
 -0.000000	 -0.000000	diff=5.59646e-13
 -0.000000	 -0.000000	diff=2.0631e-13
 -0.000000	 -0.000000	diff=4.66229e-13
  0.000000	  0.000000	diff=3.99123e-13
  0.000000	  0.000000	diff=7.67705e-11
  0.000000	  0.000000	diff=1.86573e-12
  0.000000	  0.000000	diff=5.47068e-13
 -0.000000	 -0.000000	diff=1.27456e-12
 -0.000000	 -0.000000	diff=5.6121e-14
 -0.000000	 -0.000000	diff=2.62384e-13
 -0.000000	 -0.000000	diff=2.22845e-13
 -0.000000	 -0.000000	diff=5.29232e-13
  0.000000	  0.000000	diff=4.51629e-13
  0.000001	  0.000001	diff=1.41778e-09
  local_diff=1.76369e-09
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=9.42829e-13
 -0.000000	 -0.000000	diff=1.11681e-13
  0.000000	  0.000000	diff=7.68942e-14
  0.000000	  0.000000	diff=3.8855e-13
 -0.000000	 -0.000000	diff=7.16532e-13
  0.000000	  0.000000	diff=7.78989e-14
 -0.000001	 -0.000001	diff=4.26598e-13
  0.000001	  0.000001	diff=2.92048e-12
 -0.000000	 -0.000000	diff=1.29253e-13
 -0.000000	 -0.000000	diff=4.61014e-14
 -0.000000	 -0.000000	diff=5.83721e-13
 -0.000000	 -0.000000	diff=4.6681e-13
 -0.000000	 -0.000000	diff=1.88715e-14
 -0.000000	 -0.000000	diff=4.00114e-13
 -0.000021	 -0.000021	diff=9.42734e-12
 -0.000024	 -0.000024	diff=2.0935e-10
  0.000000	  0.000000	diff=1.51765e-13
  0.000000	  0.000000	diff=5.36739e-13
  0.000000	  0.000000	diff=3.51479e-13
  0.000000	  0.000000	diff=1.92979e-13
  0.000000	  0.000000	diff=4.11475e-13
  0.000000	  0.000000	diff=1.09855e-12
  0.000000	  0.000000	diff=4.94754e-12
  0.000000	  0.000000	diff=1.45742e-14
  0.000000	  0.000000	diff=6.25299e-14
  0.000000	  0.000000	diff=2.16625e-13
  0.000000	  0.000000	diff=4.78359e-13
  0.000000	  0.000000	diff=6.02323e-13
  0.000000	  0.000000	diff=2.10076e-13
  0.000000	  0.000000	diff=5.82815e-13
  0.000000	  0.000000	diff=3.71257e-13
  0.000001	  0.000001	diff=1.18486e-09
  local_diff=1.42117e-09
# W_emb_src, [2 4]
  0.000000	  0.000000	diff=3.36709e-10
  0.000006	  0.000006	diff=4.55118e-09
  0.000002	  0.000002	diff=6.48948e-10
  0.000007	  0.000007	diff=5.62539e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.11622e-08
# W_emb_tgt, [2 4]
  0.000025	  0.000025	diff=6.50347e-09
 -0.000000	 -0.000000	diff=3.13787e-10
  0.000020	  0.000020	diff=7.63658e-10
  0.000000	  0.000000	diff=6.86142e-10
  0.000028	  0.000028	diff=2.16072e-09
  0.000001	  0.000001	diff=1.12469e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.15525e-08
# W_a, [2 2]
  0.000000	  0.000000	diff=3.27516e-17
  0.000000	 -0.000000	diff=3.82285e-17
  0.000000	  0.000000	diff=5.50711e-17
  0.000000	 -0.000000	diff=6.43517e-17
  local_diff=1.90403e-16
# W_h, [2 4]
 -0.000001	 -0.000001	diff=4.97137e-13
 -0.000000	 -0.000000	diff=5.27495e-13
 -0.000001	 -0.000001	diff=3.21824e-13
  0.000002	  0.000002	diff=3.69881e-13
  0.000002	  0.000002	diff=6.21023e-12
 -0.000005	 -0.000005	diff=7.5769e-13
  0.000035	  0.000035	diff=3.26743e-10
 -0.000031	 -0.000031	diff=7.19417e-11
  local_diff=4.07369e-10
# W_soft, [4 2]
 -0.000021	 -0.000021	diff=2.96595e-13
 -0.000003	 -0.000003	diff=7.89498e-13
  0.000024	  0.000024	diff=1.52917e-12
 -0.000000	 -0.000000	diff=2.2691e-13
 -0.000001	 -0.000001	diff=6.82123e-13
  0.000001	  0.000001	diff=7.68445e-13
 -0.000000	 -0.000000	diff=8.28854e-14
 -0.000000	 -0.000000	diff=1.30872e-12
  local_diff=5.68434e-12
# Num params=180, abs_diff=2.65297e-08
Elapsed time is 2.171386 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 3)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=0.1
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 v_a=2 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 3
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 0.1
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <t_sos> a b <t_eos> <t_eos>
  tgt output 1: a b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
  0.000000	  0.000000	diff=2.34752e-14
  0.000000	  0.000000	diff=7.24657e-13
  0.000000	  0.000000	diff=6.74503e-14
  0.000000	  0.000000	diff=7.59839e-14
  0.000000	  0.000000	diff=8.41034e-14
  0.000000	  0.000000	diff=3.83843e-13
 -0.000001	 -0.000001	diff=1.42328e-12
 -0.000003	 -0.000003	diff=1.57223e-11
  0.000000	  0.000000	diff=9.36896e-14
  0.000000	  0.000000	diff=7.68894e-13
 -0.000000	 -0.000000	diff=1.09873e-13
  0.000000	  0.000000	diff=4.21944e-13
 -0.000000	 -0.000000	diff=4.0158e-13
 -0.000000	 -0.000000	diff=9.79233e-13
  0.000001	  0.000001	diff=1.33972e-13
 -0.000002	 -0.000002	diff=1.93689e-11
 -0.000000	 -0.000000	diff=1.22373e-12
  0.000000	  0.000000	diff=7.76583e-13
 -0.000000	 -0.000000	diff=1.9098e-13
  0.000000	  0.000000	diff=9.14687e-13
 -0.000000	 -0.000000	diff=6.85445e-14
 -0.000000	 -0.000000	diff=1.80977e-13
  0.000000	  0.000000	diff=4.5106e-11
 -0.000000	 -0.000000	diff=6.15813e-13
  0.000000	  0.000000	diff=2.40158e-13
 -0.000000	 -0.000000	diff=9.90082e-14
  0.000000	  0.000000	diff=1.17784e-12
 -0.000000	 -0.000000	diff=2.09084e-13
  0.000000	  0.000000	diff=3.99725e-13
  0.000000	  0.000000	diff=4.18311e-13
  0.000000	  0.000000	diff=1.0365e-12
  0.000000	  0.000000	diff=6.51222e-11
  local_diff=1.58563e-10
# W_src{2}, [8 4]
 -0.000000	 -0.000000	diff=2.04954e-13
 -0.000000	 -0.000000	diff=3.00731e-13
 -0.000000	 -0.000000	diff=1.05049e-12
 -0.000000	 -0.000000	diff=2.03287e-13
  0.000000	  0.000000	diff=7.43494e-13
  0.000000	  0.000000	diff=1.46244e-14
  0.000000	  0.000000	diff=1.99363e-13
 -0.000001	 -0.000001	diff=4.36032e-13
  0.000000	  0.000000	diff=2.13637e-13
  0.000000	  0.000000	diff=1.54914e-13
 -0.000000	 -0.000000	diff=5.99288e-13
  0.000000	  0.000000	diff=2.17375e-13
 -0.000000	 -0.000000	diff=2.18026e-13
 -0.000000	 -0.000000	diff=1.02547e-13
  0.000001	  0.000001	diff=1.45059e-13
 -0.000000	 -0.000000	diff=1.8225e-12
 -0.000000	 -0.000000	diff=1.18837e-12
 -0.000000	 -0.000000	diff=3.12741e-13
  0.000000	  0.000000	diff=4.01729e-13
 -0.000000	 -0.000000	diff=9.58156e-13
  0.000000	  0.000000	diff=7.50114e-13
  0.000000	  0.000000	diff=5.47237e-13
  0.000000	  0.000000	diff=3.1027e-11
 -0.000000	 -0.000000	diff=5.46762e-13
  0.000000	  0.000000	diff=3.42134e-13
  0.000000	  0.000000	diff=6.60134e-13
 -0.000000	 -0.000000	diff=2.89704e-13
  0.000000	  0.000000	diff=5.94886e-13
 -0.000000	 -0.000000	diff=5.58726e-13
 -0.000000	 -0.000000	diff=6.73592e-13
 -0.000000	 -0.000000	diff=8.26022e-13
 -0.000000	 -0.000000	diff=9.87569e-12
  local_diff=5.61793e-11
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=1.12477e-13
  0.000000	  0.000000	diff=2.94612e-13
  0.000000	  0.000000	diff=2.22319e-13
  0.000000	  0.000000	diff=2.95628e-13
  0.000000	  0.000000	diff=6.85497e-13
  0.000000	  0.000000	diff=4.02195e-13
 -0.000001	 -0.000001	diff=1.68746e-11
 -0.000020	 -0.000020	diff=1.03174e-10
 -0.000000	 -0.000000	diff=6.45456e-13
 -0.000000	 -0.000000	diff=6.8529e-13
 -0.000000	 -0.000000	diff=2.27633e-14
 -0.000000	 -0.000000	diff=2.94165e-12
 -0.000000	 -0.000000	diff=7.53056e-13
 -0.000000	 -0.000000	diff=1.44247e-13
  0.000001	  0.000001	diff=4.82796e-11
  0.000037	  0.000037	diff=2.53507e-10
  0.000000	  0.000000	diff=7.17061e-16
  0.000000	  0.000000	diff=1.077e-14
  0.000000	 -0.000000	diff=2.11124e-14
  0.000000	 -0.000000	diff=1.14129e-13
  0.000000	 -0.000000	diff=1.31149e-14
  0.000000	 -0.000000	diff=9.13359e-14
  0.000000	  0.000000	diff=9.67332e-15
  0.000000	  0.000000	diff=1.02842e-12
  0.000000	  0.000000	diff=3.0903e-14
  0.000000	  0.000000	diff=6.78966e-13
  0.000000	  0.000000	diff=4.31662e-14
  0.000000	  0.000000	diff=1.34071e-13
  0.000000	  0.000000	diff=6.92145e-14
  0.000000	  0.000000	diff=2.28617e-13
 -0.000000	 -0.000000	diff=6.18858e-15
 -0.000000	 -0.000000	diff=1.21311e-12
 -0.000000	 -0.000000	diff=2.45467e-13
  0.000000	  0.000000	diff=7.77046e-14
  0.000000	  0.000000	diff=2.83007e-13
 -0.000000	 -0.000000	diff=1.30455e-13
 -0.000000	 -0.000000	diff=6.2968e-13
  0.000000	  0.000000	diff=2.27493e-13
 -0.000000	 -0.000000	diff=3.27386e-11
  0.000000	  0.000000	diff=3.60548e-12
 -0.000000	 -0.000000	diff=3.32002e-13
 -0.000000	 -0.000000	diff=5.70022e-13
 -0.000000	 -0.000000	diff=8.04958e-13
 -0.000000	 -0.000000	diff=5.35031e-13
 -0.000000	 -0.000000	diff=5.96465e-13
 -0.000000	 -0.000000	diff=1.15736e-13
 -0.000000	 -0.000000	diff=2.8985e-13
  0.000001	  0.000001	diff=9.1715e-10
  local_diff=1.39107e-09
# W_tgt{2}, [8 4]
 -0.000000	 -0.000000	diff=3.75736e-13
 -0.000000	 -0.000000	diff=1.07229e-13
 -0.000000	 -0.000000	diff=6.78159e-13
 -0.000000	 -0.000000	diff=3.80231e-13
 -0.000000	 -0.000000	diff=1.88354e-13
 -0.000000	 -0.000000	diff=4.34426e-13
 -0.000000	 -0.000000	diff=2.43519e-12
 -0.000001	 -0.000001	diff=1.69095e-12
  0.000000	  0.000000	diff=1.27911e-13
 -0.000000	 -0.000000	diff=3.31082e-13
  0.000000	  0.000000	diff=2.71845e-13
 -0.000000	 -0.000000	diff=7.68852e-13
  0.000000	  0.000000	diff=5.63742e-13
 -0.000000	 -0.000000	diff=5.14276e-13
  0.000009	  0.000009	diff=3.90126e-11
 -0.000022	 -0.000022	diff=1.37057e-10
  0.000000	  0.000000	diff=1.56297e-14
  0.000000	  0.000000	diff=9.83761e-15
 -0.000000	 -0.000000	diff=4.12079e-13
 -0.000000	 -0.000000	diff=2.71396e-13
 -0.000000	 -0.000000	diff=7.74497e-13
  0.000000	  0.000000	diff=2.01289e-13
  0.000000	  0.000000	diff=7.07502e-11
  0.000000	  0.000000	diff=4.08899e-13
 -0.000000	  0.000000	diff=9.65913e-13
  0.000000	  0.000000	diff=2.10248e-13
  0.000000	  0.000000	diff=2.83943e-13
  0.000000	  0.000000	diff=3.50428e-13
  0.000000	  0.000000	diff=1.82186e-13
  0.000000	  0.000000	diff=1.10638e-13
 -0.000000	 -0.000000	diff=2.77819e-13
  0.000000	  0.000000	diff=6.54759e-10
  local_diff=9.14921e-10
# W_emb_src, [2 4]
 -0.000001	 -0.000001	diff=7.72483e-10
  0.000006	  0.000006	diff=4.81842e-09
  0.000001	  0.000001	diff=1.91386e-10
  0.000006	  0.000006	diff=3.37585e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=9.15814e-09
# W_emb_tgt, [2 4]
  0.000020	  0.000020	diff=3.65451e-09
 -0.000000	 -0.000000	diff=5.42355e-10
  0.000009	  0.000009	diff=2.13743e-09
 -0.000001	 -0.000001	diff=4.58211e-10
  0.000018	  0.000018	diff=3.44188e-09
 -0.000001	 -0.000001	diff=5.34481e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.07689e-08
# W_a, [2 2]
  0.000000	 -0.000000	diff=7.22066e-25
  0.000000	 -0.000000	diff=2.18478e-24
  0.000000	 -0.000000	diff=1.39975e-24
  0.000000	 -0.000000	diff=7.22448e-24
  local_diff=1.15311e-23
# v_a, [1 2]
  0.000000	  0.000000	diff=1.45651e-12
 -0.000000	 -0.000000	diff=4.08018e-13
  local_diff=1.86453e-12
# W_h, [2 4]
  0.000000	  0.000000	diff=2.9641e-13
 -0.000001	 -0.000001	diff=3.17873e-13
  0.000001	  0.000001	diff=5.12031e-13
 -0.000000	 -0.000000	diff=3.14627e-13
 -0.000001	 -0.000001	diff=1.18023e-12
  0.000001	  0.000001	diff=3.09933e-12
 -0.000014	 -0.000014	diff=6.79475e-11
  0.000016	  0.000016	diff=1.2746e-10
  local_diff=2.01128e-10
# W_soft, [4 2]
  0.000008	  0.000008	diff=5.93487e-14
  0.000000	  0.000000	diff=5.49712e-13
 -0.000009	 -0.000009	diff=5.84191e-13
  0.000000	  0.000000	diff=3.46531e-13
 -0.000026	 -0.000026	diff=4.31667e-14
 -0.000008	 -0.000008	diff=5.18947e-13
  0.000029	  0.000029	diff=7.93649e-14
  0.000005	  0.000005	diff=1.55398e-13
  local_diff=2.33666e-12
# Num params=182, abs_diff=2.26531e-08
Elapsed time is 2.152395 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 104, individual sizes:  W_src{1}=32 W_tgt{1}=48 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 1
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 104
  src input 1: y y x y
  src mask: 1  1  1  1
  tgt input 1: <t_sos> a b a
  tgt output 1: a b a <t_eos>
  tgt mask: 1  1  1  1
# W_src{1}, [8 4]
 -0.000013	 -0.000013	diff=4.63718e-07
  0.000001	  0.000001	diff=3.65501e-08
 -0.000932	 -0.000900	diff=3.1885e-05
  0.000000	  0.000000	diff=5.99269e-12
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000012	  0.000012	diff=3.89478e-07
 -0.000001	 -0.000001	diff=3.07312e-08
  0.000818	  0.000845	diff=2.66832e-05
 -0.000000	 -0.000000	diff=3.9331e-12
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000001	  0.000001	diff=5.53295e-09
 -0.000000	 -0.000000	diff=2.5681e-11
  0.000099	  0.000099	diff=3.74947e-07
 -0.000000	 -0.000000	diff=2.84401e-12
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.000002	 -0.000002	diff=9.24172e-09
  0.000000	  0.000000	diff=2.51403e-11
 -0.000129	 -0.000129	diff=6.36201e-07
  0.000000	  0.000000	diff=2.67178e-12
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=6.05147e-05
# W_tgt{1}, [8 6]
 -0.063025	 -0.053372	diff=0.00965252
  0.000000	  0.000000	diff=1.28429e-08
  0.000000	 -0.000000	diff=1.50853e-15
 -0.000000	 -0.000000	diff=2.483e-12
-31.263908	-32.483123	diff=1.21921
 -0.010618	 -0.011040	diff=0.000421337
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.048896	  0.062674	diff=0.0137782
  0.000000	  0.000000	diff=1.72803e-08
  0.000000	  0.000000	diff=8.37179e-16
  0.000000	  0.000000	diff=9.17082e-13
 39.771604	 38.144140	diff=1.62746
  0.013573	  0.012957	diff=0.000615584
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.023973	  0.024038	diff=6.48058e-05
  0.000000	 -0.000000	diff=3.79277e-51
  0.000000	  0.000000	diff=4.41704e-17
  0.000000	 -0.000000	diff=2.09651e-15
 -0.685378	 -0.683481	diff=0.00189718
  0.000137	  0.000137	diff=1.83166e-07
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.019028	 -0.018988	diff=4.01812e-05
  0.000000	  0.000000	diff=2.58066e-51
  0.000000	 -0.000000	diff=4.51516e-20
  0.000000	  0.000000	diff=2.24548e-18
  0.554215	  0.555460	diff=0.00124536
  0.000000	  0.000000	diff=6.82596e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.023973	  0.024038	diff=6.48058e-05
  0.000000	  0.000000	diff=2.55251e-10
  0.000000	  0.000000	diff=4.41704e-17
  0.000000	 -0.000000	diff=2.09651e-15
 -0.685378	 -0.683481	diff=0.00189718
  0.000137	  0.000137	diff=1.83166e-07
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
 -0.019028	 -0.018988	diff=4.01812e-05
 -0.000000	 -0.000000	diff=2.87921e-10
  0.000000	 -0.000000	diff=4.51516e-20
  0.000000	  0.000000	diff=2.24548e-18
  0.554215	  0.555460	diff=0.00124536
  0.000000	  0.000000	diff=6.82596e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=2.87764
# W_emb_src, [2 4]
 -0.000003	 -0.000003	diff=1.14337e-07
 -0.000003	 -0.000003	diff=9.65271e-08
 -0.000990	 -0.000953	diff=3.72485e-05
 -0.000900	 -0.000869	diff=3.17681e-05
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=6.92275e-05
# W_emb_tgt, [2 4]
-27.956638	-28.915513	diff=0.958875
-24.302396	-25.019891	diff=0.717496
 -0.000005	 -0.000005	diff=1.23032e-07
 -0.000005	 -0.000005	diff=1.29694e-07
  0.000001	  0.000001	diff=2.66556e-08
 -0.000000	 -0.000000	diff=8.71782e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=1.67637
# W_soft, [4 2]
 -3.427182	 -3.427237	diff=5.54155e-05
 -2.145279	 -2.146908	diff=0.00162899
  0.126818	  0.126673	diff=0.000145468
  5.449159	  5.447473	diff=0.00168599
  2.285337	  2.285337	diff=3.86105e-08
  1.413201	  1.412786	diff=0.000414105
 -0.000600	 -0.000601	diff=1.90223e-06
 -3.697104	 -3.697522	diff=0.000418031
  local_diff=0.00434995
# Num params=104, abs_diff=4.55849
Elapsed time is 0.864124 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 1
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s_sos> x y y
  src mask: 0  1  1  1
  tgt input 1: <t_sos> b b <t_eos> <t_eos>
  tgt output 1: b b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000645	 -0.000655	diff=9.57798e-06
 -0.000000	 -0.000000	diff=9.14617e-13
  0.000020	  0.000019	diff=2.86991e-07
  0.000000	 -0.000000	diff=4.7598e-16
-12.880180	-12.036708	diff=0.843472
 -0.000000	 -0.000000	diff=4.27527e-10
  0.000000	  0.000000	diff=1.13196e-12
 -0.000000	 -0.000000	diff=6.82978e-13
  0.000219	  0.000218	diff=1.07071e-06
  0.000000	  0.000000	diff=1.68232e-13
 -0.000006	 -0.000006	diff=3.12514e-08
  0.000000	  0.000000	diff=1.58105e-16
  3.844936	  3.998194	diff=0.153258
  0.000000	  0.000000	diff=4.66287e-11
  0.000000	  0.000000	diff=1.98321e-12
  0.000000	  0.000000	diff=1.18925e-12
 -0.000042	 -0.000042	diff=2.38479e-07
  0.000000	  0.000000	diff=1.00509e-13
  0.000005	  0.000005	diff=1.92753e-08
  0.000000	  0.000000	diff=3.02454e-17
  0.427493	  0.429236	diff=0.00174272
  0.000000	  0.000000	diff=1.20405e-11
  0.000000	  0.000000	diff=1.87317e-13
  0.000000	  0.000000	diff=7.12328e-13
  0.000000	 -0.000000	diff=3.66484e-15
  0.000000	 -0.000000	diff=9.15927e-27
  0.000000	 -0.000000	diff=3.32337e-17
  0.000000	 -0.000000	diff=7.69988e-27
 -0.000000	 -0.000000	diff=2.56314e-13
  0.000000	 -0.000000	diff=7.75586e-20
  0.000000	  0.000000	diff=4.93975e-22
  0.000000	 -0.000000	diff=1.66729e-27
  local_diff=0.998483
# W_src{2}, [8 4]
  0.060915	  0.059955	diff=0.000960268
 -0.105433	 -0.105172	diff=0.00026134
  0.026054	  0.026043	diff=1.08659e-05
  0.097445	  0.097690	diff=0.000245299
 -0.717873	 -0.715295	diff=0.00257756
  0.304524	  0.303461	diff=0.00106279
 -0.417615	 -0.416720	diff=0.000895252
  0.014483	  0.014604	diff=0.000121373
  0.000000	  0.000000	diff=1.47533e-12
  0.000000	  0.000000	diff=6.74657e-13
 -0.000000	 -0.000000	diff=6.01845e-13
  0.000000	  0.000000	diff=1.12799e-13
  0.000000	  0.000000	diff=9.99918e-13
  0.000000	  0.000000	diff=7.96308e-13
  0.000000	  0.000000	diff=1.33443e-12
 -0.000000	  0.000000	diff=7.38353e-13
  0.060181	  0.060104	diff=7.68896e-05
 -0.157522	 -0.157616	diff=9.45347e-05
  0.042343	  0.042319	diff=2.43084e-05
 -0.038686	 -0.038684	diff=2.3279e-06
  0.060124	  0.060122	diff=1.77464e-06
 -0.051238	 -0.051260	diff=2.20286e-05
 -0.736389	 -0.733520	diff=0.00286856
 -0.002836	 -0.002831	diff=5.27755e-06
  0.043146	  0.043124	diff=2.16903e-05
  0.353888	  0.353337	diff=0.000551438
 -0.118440	 -0.118594	diff=0.000153526
  0.090253	  0.090250	diff=2.50515e-06
 -0.117548	 -0.117562	diff=1.49065e-05
  0.145487	  0.145627	diff=0.000140061
  1.845915	  1.865950	diff=0.0200348
  0.006550	  0.006578	diff=2.81229e-05
  local_diff=0.0301775
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=1.30654e-12
  0.000021	  0.000022	diff=2.78137e-07
  0.008457	  0.008348	diff=0.000109014
  0.000000	 -0.000000	diff=2.99343e-17
  0.000000	  0.000000	diff=8.27219e-13
 -0.000000	 -0.000000	diff=1.49694e-12
 -0.000000	 -0.000000	diff=1.06007e-10
  0.000000	  0.000000	diff=5.36662e-20
  0.000000	  0.000000	diff=1.0941e-13
 -0.000021	 -0.000021	diff=2.58047e-07
 -0.007876	 -0.007974	diff=9.78879e-05
  0.000000	  0.000000	diff=2.85921e-17
 -0.000000	 -0.000000	diff=6.30957e-13
  0.000000	  0.000000	diff=1.40573e-12
  0.000000	  0.000000	diff=9.3218e-11
  0.000000	 -0.000000	diff=5.12599e-20
  0.000000	  0.000000	diff=6.40149e-15
 -0.000012	 -0.000012	diff=1.54628e-08
  0.000010	  0.000010	diff=1.5639e-10
  0.000000	 -0.000000	diff=2.35214e-17
  0.000000	  0.000000	diff=1.87085e-15
 -0.000000	 -0.000000	diff=2.82549e-13
  0.000000	  0.000000	diff=8.78595e-13
  0.000000	 -0.000000	diff=6.99841e-21
  0.000000	  0.000000	diff=1.49288e-16
  0.000023	  0.000023	diff=1.60918e-08
 -0.000530	 -0.000531	diff=4.36512e-07
  0.000000	 -0.000000	diff=8.37201e-18
  0.000000	 -0.000000	diff=5.35507e-14
  0.000000	  0.000000	diff=8.84905e-13
 -0.000000	 -0.000000	diff=2.21974e-13
  0.000000	  0.000000	diff=3.42112e-21
  0.000000	  0.000000	diff=5.50464e-41
  0.000037	  0.000037	diff=1.40205e-07
 -0.002408	 -0.002417	diff=9.03936e-06
  0.000000	  0.000000	diff=1.60276e-23
  0.000000	 -0.000000	diff=2.43863e-13
  0.000000	  0.000000	diff=1.14525e-12
  0.000000	 -0.000000	diff=6.97213e-17
  0.000000	  0.000000	diff=5.16151e-61
  0.000000	 -0.000000	diff=1.17579e-28
  0.000000	  0.000000	diff=9.2265e-13
 -0.000000	 -0.000000	diff=6.92046e-13
  0.000000	  0.000000	diff=2.6898e-29
  0.000000	 -0.000000	diff=5.3467e-19
  0.000000	  0.000000	diff=4.92409e-17
  0.000000	 -0.000000	diff=1.58417e-22
  0.000000	  0.000000	diff=2.32445e-34
  local_diff=0.000217086
# W_tgt{2}, [8 4]
 -0.071362	 -0.071485	diff=0.00012359
  0.532100	  0.530731	diff=0.00136848
 -0.000101	 -0.000100	diff=3.81767e-07
 -0.000796	 -0.000776	diff=1.97807e-05
 -0.031510	 -0.031391	diff=0.000118883
  0.015004	  0.015053	diff=4.851e-05
  0.051053	  0.050694	diff=0.000358598
  3.638081	  3.595972	diff=0.0421091
 -0.000001	 -0.000001	diff=5.37918e-13
  0.000005	  0.000005	diff=6.04414e-13
 -0.000000	 -0.000000	diff=2.64499e-13
 -0.000000	 -0.000000	diff=1.00026e-12
 -0.000000	 -0.000000	diff=6.89229e-13
  0.000000	  0.000000	diff=1.19153e-13
  0.000002	  0.000002	diff=2.10882e-13
  0.000003	  0.000003	diff=7.21238e-12
  0.021535	  0.021699	diff=0.000164271
  0.069052	  0.069106	diff=5.32004e-05
 -0.028745	 -0.028754	diff=8.95531e-06
 -0.060642	 -0.060183	diff=0.000459439
  0.042561	  0.042483	diff=7.84445e-05
 -0.007008	 -0.007014	diff=5.64043e-06
  0.148883	  0.148898	diff=1.54763e-05
  0.428078	  0.418259	diff=0.00981886
  0.052168	  0.052767	diff=0.000599286
 -0.081964	 -0.081873	diff=9.04268e-05
  0.015287	  0.015313	diff=2.62133e-05
  0.322878	  0.325820	diff=0.00294157
 -0.051675	 -0.051693	diff=1.82975e-05
  0.023439	  0.023505	diff=6.56215e-05
 -0.066655	 -0.066689	diff=3.41197e-05
  1.828751	  1.858322	diff=0.0295713
  local_diff=0.0880985
# W_emb_src, [2 4]
 -0.000000	 -0.000000	diff=5.27539e-13
  0.000000	  0.000000	diff=2.27522e-12
-11.492646	-10.784612	diff=0.708034
-39.612802	-37.246982	diff=2.36582
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=3.07385
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=6.01745e-13
 -0.000000	 -0.000000	diff=4.59418e-13
  0.004332	  0.004304	diff=2.80815e-05
 -0.003162	 -0.003177	diff=1.53719e-05
 -0.000000	 -0.000000	diff=1.87861e-09
  0.000000	  0.000000	diff=1.00048e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=4.34562e-05
# W_soft, [4 2]
  0.163799	  0.163397	diff=0.000401677
 -0.361160	 -0.361564	diff=0.000404727
  0.006846	  0.006467	diff=0.000379625
  0.192091	  0.191701	diff=0.000389864
 -0.395371	 -0.395582	diff=0.000210191
 -0.150213	 -0.150430	diff=0.000217699
  0.520510	  0.520169	diff=0.000341006
  0.026195	  0.025843	diff=0.000352205
  local_diff=0.00269699
# Num params=168, abs_diff=4.19357
Elapsed time is 1.333852 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 168, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_soft=8
# assert = 0
# attnFunc = 0
# attnOpt = 0
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 0
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 168
  src input 1: <s_sos> x y y
  src mask: 0  1  1  1
  tgt input 1: <t_sos> b b <t_eos> <t_eos>
  tgt output 1: b b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000067	 -0.000068	diff=1.23979e-06
  0.000000	  0.000000	diff=4.43392e-14
  0.000000	  0.000000	diff=6.32961e-09
  0.000000	  0.000000	diff=1.58524e-16
-14.719207	-16.059530	diff=1.34032
 -0.000000	 -0.000000	diff=3.13726e-12
  0.000000	  0.000000	diff=8.59821e-15
  0.000000	  0.000000	diff=6.45012e-13
  0.000023	  0.000023	diff=1.39051e-07
  0.000000	 -0.000000	diff=1.4728e-14
 -0.000000	 -0.000000	diff=6.87464e-10
  0.000000	 -0.000000	diff=5.26565e-17
  5.461578	  5.334443	diff=0.127136
  0.000000	  0.000000	diff=7.61555e-13
  0.000000	  0.000000	diff=1.39333e-14
  0.000000	 -0.000000	diff=2.1767e-14
 -0.000002	 -0.000002	diff=1.4699e-08
  0.000000	 -0.000000	diff=6.52657e-15
  0.000000	  0.000000	diff=2.75589e-10
  0.000000	 -0.000000	diff=6.3286e-18
  0.449855	  0.448817	diff=0.00103736
  0.000000	  0.000000	diff=3.37162e-13
  0.000000	 -0.000000	diff=2.04339e-16
  0.000000	 -0.000000	diff=9.69317e-15
  0.000000	 -0.000000	diff=9.31368e-19
  0.000000	  0.000000	diff=7.69033e-30
  0.000000	 -0.000000	diff=1.65854e-21
  0.000000	  0.000000	diff=5.74242e-30
  0.000000	 -0.000000	diff=3.25273e-13
  0.000000	 -0.000000	diff=4.82839e-25
  0.000000	  0.000000	diff=1.29125e-27
  0.000000	  0.000000	diff=3.05427e-31
  local_diff=1.4685
# W_src{2}, [8 4]
 -0.087050	 -0.086739	diff=0.000311079
 -0.104555	 -0.104607	diff=5.24231e-05
  0.029830	  0.029799	diff=3.03083e-05
  0.040328	  0.040535	diff=0.000207567
 -0.723474	 -0.726745	diff=0.00327087
  0.013565	  0.013999	diff=0.000433388
 -0.464075	 -0.465157	diff=0.00108233
  0.022380	  0.022321	diff=5.89542e-05
  0.000000	  0.000000	diff=7.6751e-14
  0.000000	  0.000000	diff=1.15572e-13
 -0.000000	 -0.000000	diff=1.76551e-13
  0.000000	  0.000000	diff=7.59365e-14
  0.000000	  0.000000	diff=4.50201e-13
  0.000000	  0.000000	diff=1.48587e-13
  0.000000	  0.000000	diff=4.98398e-13
  0.000000	 -0.000000	diff=8.61398e-15
  0.024853	  0.024873	diff=2.0336e-05
 -0.196043	 -0.196245	diff=0.00020265
  0.038320	  0.038283	diff=3.70244e-05
 -0.026892	 -0.026901	diff=8.44311e-06
  0.078484	  0.078434	diff=5.0346e-05
 -0.007768	 -0.007788	diff=2.02332e-05
 -0.728843	 -0.731675	diff=0.00283175
 -0.003156	 -0.003150	diff=5.82749e-06
 -0.001543	 -0.001507	diff=3.61331e-05
  0.455753	  0.454661	diff=0.00109135
 -0.152166	 -0.152594	diff=0.000427629
  0.061099	  0.061046	diff=5.21822e-05
 -0.168752	 -0.169013	diff=0.000260484
  0.121133	  0.120961	diff=0.000172497
  2.228265	  2.210119	diff=0.0181459
  0.007276	  0.007307	diff=3.12223e-05
  local_diff=0.0288409
# W_tgt{1}, [8 6]
 -0.000000	 -0.000000	diff=6.2292e-09
  0.000015	  0.000016	diff=2.5298e-07
  0.060884	  0.060119	diff=0.00076484
  0.000000	  0.000000	diff=1.86329e-12
  0.000002	  0.000002	diff=2.64145e-08
 -0.000000	 -0.000000	diff=1.0273e-10
  0.000000	  0.000000	diff=2.44072e-13
  0.000000	  0.000000	diff=0
  0.000000	 -0.000000	diff=1.81289e-35
 -0.000015	 -0.000015	diff=2.38185e-07
  0.000000	 -0.000000	diff=1.44824e-14
  0.000000	  0.000000	diff=5.58153e-20
  0.000000	 -0.000000	diff=2.44671e-32
 -0.000000	 -0.000000	diff=8.16683e-09
 -0.000000	 -0.000000	diff=3.92424e-13
  0.000000	 -0.000000	diff=7.3573e-16
  0.000000	  0.000000	diff=1.01422e-11
  0.000001	  0.000001	diff=8.19778e-10
  0.000023	  0.000023	diff=2.11826e-10
  0.000000	  0.000000	diff=1.41327e-13
  0.000000	  0.000000	diff=2.13369e-13
  0.000000	  0.000000	diff=2.54746e-12
  0.000000	 -0.000000	diff=2.11583e-13
  0.000000	  0.000000	diff=1.11694e-17
  0.000000	 -0.000000	diff=5.03651e-13
  0.000000	  0.000000	diff=2.10087e-11
 -0.005170	 -0.005175	diff=5.67355e-06
  0.000000	  0.000000	diff=1.66012e-21
 -0.000000	 -0.000000	diff=1.91877e-10
 -0.000000	 -0.000000	diff=6.3643e-13
  0.000000	  0.000000	diff=1.59317e-15
  0.000000	  0.000000	diff=2.82346e-21
 -0.000000	 -0.000000	diff=1.31473e-14
  0.000000	  0.000000	diff=1.74292e-10
 -0.013961	 -0.014003	diff=4.15161e-05
  0.000000	  0.000000	diff=2.59621e-21
 -0.000000	 -0.000000	diff=1.40528e-09
  0.000000	  0.000000	diff=4.86693e-13
  0.000000	  0.000000	diff=2.80162e-65
  0.000000	 -0.000000	diff=2.44665e-19
  0.000000	  0.000000	diff=3.31683e-19
  0.000000	  0.000000	diff=4.92952e-17
 -0.000000	 -0.000000	diff=1.42868e-13
  0.000000	  0.000000	diff=6.672e-21
  0.000000	 -0.000000	diff=4.16656e-16
  0.000000	  0.000000	diff=6.1473e-19
  0.000000	  0.000000	diff=1.79699e-30
  0.000000	  0.000000	diff=7.94063e-28
  local_diff=0.000812564
# W_tgt{2}, [8 4]
 -0.046807	 -0.046992	diff=0.00018554
  0.899926	  0.894289	diff=0.00563694
 -0.000032	 -0.000032	diff=1.52434e-07
 -0.024813	 -0.024701	diff=0.000111815
 -0.004882	 -0.004857	diff=2.4318e-05
  0.014023	  0.014087	diff=6.35016e-05
  0.021521	  0.021319	diff=0.000201599
  1.452706	  1.442812	diff=0.00989439
 -0.000000	 -0.000000	diff=8.13848e-13
  0.000001	  0.000001	diff=1.73597e-13
  0.000000	  0.000000	diff=6.23192e-14
 -0.000000	 -0.000000	diff=2.83224e-13
 -0.000000	 -0.000000	diff=5.7713e-13
  0.000000	  0.000000	diff=3.69756e-13
  0.000000	  0.000000	diff=3.60351e-13
  0.000001	  0.000001	diff=6.53623e-14
  0.113675	  0.113696	diff=2.13061e-05
 -0.046499	 -0.046607	diff=0.00010751
 -0.036259	 -0.036266	diff=6.35102e-06
 -0.007899	 -0.007889	diff=9.69445e-06
  0.032595	  0.032362	diff=0.000232558
 -0.003303	 -0.003312	diff=8.68865e-06
  0.223440	  0.223403	diff=3.74709e-05
  0.406097	  0.405019	diff=0.00107796
 -0.064350	 -0.064522	diff=0.000172566
 -0.081778	 -0.081804	diff=2.56724e-05
 -0.006464	 -0.006486	diff=2.25768e-05
  0.104609	  0.104460	diff=0.000148211
 -0.086935	 -0.086992	diff=5.66762e-05
 -0.007792	 -0.007793	diff=1.58223e-07
 -0.071641	 -0.071809	diff=0.000168241
  0.784444	  0.764323	diff=0.0201207
  local_diff=0.0383346
# W_emb_src, [2 4]
  0.000000	 -0.000000	diff=1.9143e-13
  0.000000	  0.000000	diff=1.17505e-14
-13.315305	-14.387187	diff=1.07188
-37.421782	-49.692857	diff=12.2711
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=13.343
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=1.58251e-10
  0.000000	  0.000000	diff=1.26032e-09
  0.031711	  0.031501	diff=0.000209903
 -0.000010	 -0.000010	diff=9.55223e-08
  0.000084	  0.000085	diff=7.22911e-07
  0.000000	  0.000000	diff=5.10378e-13
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.000210723
# W_soft, [4 2]
 -0.026666	 -0.027010	diff=0.000344792
 -0.058779	 -0.059143	diff=0.000363627
 -0.041872	 -0.042203	diff=0.000330914
  0.128739	  0.128356	diff=0.000382858
 -0.299723	 -0.299879	diff=0.00015595
 -0.097695	 -0.097855	diff=0.00016007
  0.430156	  0.429869	diff=0.000287884
 -0.031845	 -0.032135	diff=0.000289784
  local_diff=0.00231588
# Num params=168, abs_diff=14.882
Elapsed time is 1.435990 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 176, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 176
  src input 1: <s_sos> y x x
  src mask: 0  1  1  1
  tgt input 1: <t_sos> a b <t_eos> <t_eos>
  tgt output 1: a b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000417	 -0.000425	diff=7.75021e-06
  0.000000	 -0.000000	diff=8.63376e-19
  0.000009	  0.000009	diff=1.65405e-07
  0.000000	  0.000000	diff=5.83317e-19
-10.688819	-11.010727	diff=0.321908
 -0.000000	 -0.000000	diff=8.9506e-12
  0.000000	  0.000000	diff=3.97478e-12
  0.000000	  0.000000	diff=2.29572e-21
  0.000142	  0.000141	diff=8.6923e-07
  0.000000	  0.000000	diff=2.86785e-19
 -0.000003	 -0.000003	diff=1.79527e-08
  0.000000	 -0.000000	diff=1.93758e-19
  3.693816	  3.657392	diff=0.0364232
 -0.000000	 -0.000000	diff=1.64674e-11
  0.000000	  0.000000	diff=7.13172e-12
  0.000000	  0.000000	diff=4.15715e-24
 -0.000087	 -0.000088	diff=3.32716e-07
  0.000000	 -0.000000	diff=1.7802e-19
  0.000002	  0.000002	diff=6.96235e-09
  0.000000	  0.000000	diff=1.20274e-19
 -2.256408	 -2.270301	diff=0.013893
  0.000000	  0.000000	diff=3.49128e-13
 -0.000000	 -0.000000	diff=1.50104e-12
  0.000000	 -0.000000	diff=2.58052e-24
  0.000000	  0.000000	diff=1.28664e-18
  0.000000	 -0.000000	diff=5.93891e-36
  0.000000	 -0.000000	diff=2.67926e-20
  0.000000	  0.000000	diff=8.98286e-37
  0.000000	  0.000000	diff=3.33479e-14
  0.000000	 -0.000000	diff=2.63248e-31
  0.000000	 -0.000000	diff=2.89061e-29
  0.000000	 -0.000000	diff=8.60886e-41
  local_diff=0.372233
# W_src{2}, [8 4]
 -1.813149	 -1.825307	diff=0.0121573
 -0.108651	 -0.108291	diff=0.000360102
  0.029615	  0.029474	diff=0.000140437
  4.759760	  4.785103	diff=0.025343
  0.033907	  0.033896	diff=1.08134e-05
  3.176557	  3.161237	diff=0.0153198
 -0.000001	 -0.000001	diff=1.00517e-08
 -0.000658	 -0.000654	diff=4.48241e-06
  0.000000	  0.000000	diff=8.31194e-13
  0.000000	  0.000000	diff=2.05941e-15
  0.000000	 -0.000000	diff=8.08868e-14
 -0.000000	 -0.000000	diff=2.70001e-13
  0.000000	  0.000000	diff=5.34378e-14
  0.000000	  0.000000	diff=1.72135e-13
  0.000000	  0.000000	diff=2.22651e-18
  0.000000	 -0.000000	diff=8.24413e-20
  0.087994	  0.087974	diff=2.06008e-05
  0.002102	  0.002102	diff=1.53838e-07
 -0.001560	 -0.001560	diff=3.88728e-07
 -0.251615	 -0.251545	diff=7.01937e-05
 -0.000032	 -0.000032	diff=4.03524e-07
 -0.061516	 -0.061522	diff=5.52107e-06
  0.000000	  0.000000	diff=2.17759e-11
  0.000013	  0.000013	diff=1.88065e-09
 -1.301019	 -1.304868	diff=0.00384914
 -0.000547	 -0.000545	diff=1.90206e-06
  0.021800	  0.021724	diff=7.58043e-05
  3.493928	  3.507554	diff=0.0136256
 -0.014342	 -0.014392	diff=4.9982e-05
 -0.046342	 -0.046181	diff=0.000161455
 -0.000001	 -0.000001	diff=4.15393e-09
  0.000000	  0.000000	diff=8.12736e-11
  local_diff=0.0711971
# W_tgt{1}, [8 6]
  0.000000	 -0.000000	diff=1.76276e-13
  0.000128	  0.000131	diff=2.113e-06
 -0.020619	 -0.020281	diff=0.00033833
  0.000000	 -0.000000	diff=6.34092e-19
  0.000000	 -0.000000	diff=4.45544e-19
  0.000000	  0.000000	diff=1.08054e-12
 -0.000000	 -0.000000	diff=3.07824e-12
  0.000000	  0.000000	diff=8.48812e-92
  0.000000	  0.000000	diff=2.12431e-11
 -0.027462	 -0.030471	diff=0.00300868
  0.019098	  0.019401	diff=0.000302727
 -0.000000	 -0.000000	diff=1.40156e-11
 -0.000000	 -0.000000	diff=7.4753e-12
 -0.003947	 -0.004052	diff=0.000104986
 -0.000000	 -0.000000	diff=4.53969e-09
  2.012779	  1.654475	diff=0.358304
 -0.000000	 -0.000000	diff=6.7009e-13
  0.001622	  0.001614	diff=7.61688e-06
 -0.000000	 -0.000000	diff=4.56066e-11
 -0.000000	 -0.000000	diff=4.26651e-13
 -0.000000	 -0.000000	diff=1.25478e-12
  0.000207	  0.000206	diff=2.64438e-07
  0.000000	  0.000000	diff=9.53485e-12
  0.027006	  0.026916	diff=8.94354e-05
 -0.000000	 -0.000000	diff=3.72173e-13
  0.006999	  0.006855	diff=0.000143943
 -0.004644	 -0.004627	diff=1.74548e-05
 -0.000000	 -0.000000	diff=1.57491e-13
 -0.000000	 -0.000000	diff=4.79931e-13
  0.000892	  0.000887	diff=4.97041e-06
  0.000000	  0.000000	diff=2.19891e-10
  0.017234	  0.017197	diff=3.64972e-05
 -0.000000	 -0.000000	diff=1.25189e-13
 -0.000040	 -0.000040	diff=1.58025e-07
  0.004673	  0.004691	diff=1.79246e-05
  0.000000	  0.000000	diff=3.63931e-13
  0.000000	 -0.000000	diff=1.13629e-14
 -0.000000	 -0.000000	diff=4.10669e-10
  0.000000	  0.000000	diff=3.37463e-17
  0.000000	  0.000000	diff=1.13925e-09
  0.000000	  0.000000	diff=8.97245e-13
  0.000006	  0.000006	diff=3.6637e-09
  0.000001	  0.000001	diff=5.70024e-10
  0.000000	 -0.000000	diff=1.61224e-13
  0.000000	  0.000000	diff=1.73336e-15
  0.000000	  0.000000	diff=9.34631e-12
  0.000000	 -0.000000	diff=1.63666e-17
 -0.000000	 -0.000000	diff=2.63946e-11
  local_diff=0.362379
# W_tgt{2}, [8 4]
 -0.005609	 -0.005548	diff=6.12318e-05
 15.601504	 15.645669	diff=0.0441653
  0.000045	  0.000045	diff=2.10182e-07
  0.542629	  0.540448	diff=0.00218169
 -0.035162	 -0.034977	diff=0.000184637
  0.014483	  0.013987	diff=0.000495926
  0.001460	  0.001447	diff=1.27022e-05
 58.954702	 59.866335	diff=0.911632
 -0.011191	 -0.011138	diff=5.30032e-05
  0.000820	  0.000821	diff=8.17233e-08
 -0.000029	 -0.000029	diff=9.05399e-08
  0.000130	  0.000129	diff=4.99191e-07
 -0.011941	 -0.011886	diff=5.52257e-05
  0.004172	  0.004052	diff=0.000120223
 -0.000571	 -0.000566	diff=5.28759e-06
 -0.000738	 -0.000737	diff=1.03973e-06
  0.055186	  0.055013	diff=0.000172813
 -0.199543	 -0.199931	diff=0.000387869
 -0.011285	 -0.011251	diff=3.38641e-05
  0.237925	  0.239097	diff=0.00117201
  0.062794	  0.062800	diff=5.63728e-06
  0.008301	  0.008309	diff=7.73758e-06
  0.043058	  0.042678	diff=0.000380009
 20.094337	 20.122419	diff=0.0280819
 -0.176576	 -0.176200	diff=0.000375698
  0.721573	  0.721825	diff=0.000252575
 -0.018177	 -0.018111	diff=6.55712e-05
  1.320871	  1.317796	diff=0.00307505
 -0.001880	 -0.001908	diff=2.85862e-05
  0.004889	  0.004989	diff=0.0001001
  0.015874	  0.015775	diff=9.85287e-05
 16.337336	 15.641600	diff=0.695736
  local_diff=1.68894
# W_emb_src, [2 4]
 -0.000066	 -0.000068	diff=1.10601e-06
  0.000000	  0.000000	diff=1.41778e-11
 -9.605973	 -9.864895	diff=0.258922
-31.109855	-34.071531	diff=2.96168
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=3.2206
# W_emb_tgt, [2 4]
  0.000000	 -0.000000	diff=5.77495e-15
 -0.000001	 -0.000001	diff=1.77457e-08
 -0.010975	 -0.010872	diff=0.000102879
  0.164485	  0.158929	diff=0.00555612
  0.000001	  0.000001	diff=1.08213e-08
 -0.000001	 -0.000001	diff=4.45282e-09
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.00565903
# W_h, [2 4]
  1.481862	  1.481040	diff=0.000821426
  1.005735	  1.007247	diff=0.00151167
  7.182414	  7.179102	diff=0.0033123
  0.754340	  0.742068	diff=0.0122719
  3.660822	  3.580372	diff=0.08045
  1.307084	  1.263106	diff=0.0439777
  2.304253	  2.305433	diff=0.00118011
  6.071239	  6.071374	diff=0.000134804
  local_diff=0.14366
# W_soft, [4 2]
 -3.986266	 -3.989139	diff=0.0028725
  0.720294	  0.720191	diff=0.000103346
  3.904612	  3.903758	diff=0.000854314
 -0.632447	 -0.634810	diff=0.00236214
 -4.939213	 -4.943083	diff=0.00387017
  3.191459	  3.191370	diff=8.97239e-05
  1.158195	  1.157970	diff=0.000224802
  0.597443	  0.593744	diff=0.00369893
  local_diff=0.0140759
# Num params=176, abs_diff=5.87875
Elapsed time is 2.763112 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 4, 'attnOpt', 1)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_pos=4 v_pos=2 W_h=8 W_soft=8
# assert = 0
# attnFunc = 4
# attnOpt = 1
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# distSigma = 0.5
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <t_sos> a b <t_eos> <t_eos>
  tgt output 1: a b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000295	 -0.000301	diff=5.48626e-06
  0.000000	  0.000000	diff=3.20238e-09
  0.000004	  0.000004	diff=6.72291e-08
  0.000000	 -0.000000	diff=3.37935e-21
-65.832249	-45.917943	diff=19.9143
 -0.000000	 -0.000000	diff=3.23969e-11
  0.000000	  0.000000	diff=7.52404e-14
  0.000000	  0.000000	diff=7.20985e-11
  0.000101	  0.000100	diff=6.15315e-07
 -0.000426	 -0.000429	diff=2.70981e-06
 -0.000001	 -0.000001	diff=7.29601e-09
 -0.000974	 -0.000980	diff=5.82778e-06
 13.856624	 15.252444	diff=1.39582
 29.523318	 24.203522	diff=5.3198
  0.000000	  0.000000	diff=1.09206e-13
 -0.000000	 -0.000000	diff=9.88426e-12
 -0.000033	 -0.000033	diff=1.43303e-07
 -0.000155	 -0.000155	diff=5.85787e-07
  0.000001	  0.000001	diff=2.83099e-09
  0.000610	  0.000608	diff=2.25969e-06
  1.065368	  1.069469	diff=0.00410074
 -0.002381	 -0.002372	diff=9.06182e-06
  0.000000	 -0.000000	diff=2.12519e-15
  0.000000	  0.000000	diff=1.03734e-12
  0.000000	  0.000000	diff=5.66691e-19
  0.000024	  0.000024	diff=1.40708e-08
  0.000000	 -0.000000	diff=1.18006e-20
 -0.000094	 -0.000094	diff=5.42753e-08
  0.000000	  0.000000	diff=1.47308e-14
  0.000368	  0.000368	diff=2.1763e-07
  0.000000	  0.000000	diff=2.66579e-27
  0.000000	  0.000000	diff=1.24852e-16
  local_diff=26.634
# W_src{2}, [8 4]
 -0.693846	 -0.700801	diff=0.00695479
  0.259314	  0.259559	diff=0.000244785
  0.060128	  0.060060	diff=6.85309e-05
  0.193660	  0.194477	diff=0.000817591
 -2.450907	 -2.454155	diff=0.00324807
  1.471314	  1.471395	diff=8.10194e-05
 -0.309191	 -0.308930	diff=0.000261266
  0.228672	  0.228542	diff=0.000129062
  0.010205	  0.010190	diff=1.5049e-05
 -0.298153	 -0.298954	diff=0.000800595
  0.000011	  0.000011	diff=3.91384e-12
  0.000096	  0.000096	diff=7.9898e-11
 -0.001343	 -0.001347	diff=4.25871e-06
 -0.295095	 -0.295839	diff=0.000743609
  0.140384	  0.137766	diff=0.00261816
  1.500928	  1.481183	diff=0.0197457
  0.364428	  0.364365	diff=6.33365e-05
  0.032760	  0.032748	diff=1.21845e-05
  0.049679	  0.049669	diff=9.30762e-06
 -0.017033	 -0.017004	diff=2.9221e-05
  0.050207	  0.050203	diff=4.09021e-06
  0.171611	  0.171503	diff=0.00010775
 -0.569016	 -0.568789	diff=0.000227507
 -0.192158	 -0.192603	diff=0.0004456
 -0.848576	 -0.848359	diff=0.000217422
 -0.044314	 -0.044424	diff=0.000109644
 -0.806002	 -0.807431	diff=0.00142918
  0.052380	  0.052521	diff=0.000141377
 -0.011992	 -0.012028	diff=3.65486e-05
 -0.262693	 -0.263143	diff=0.000450512
  6.884831	  6.930197	diff=0.0453662
  0.371064	  0.369429	diff=0.0016345
  local_diff=0.0860168
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=9.90429e-13
  1.785661	  1.801989	diff=0.016328
 -0.001260	 -0.001240	diff=2.0601e-05
  0.000000	 -0.000000	diff=2.37984e-18
  0.000000	  0.000000	diff=3.73194e-45
  0.000000	  0.000000	diff=3.14296e-12
 -0.000000	 -0.000000	diff=2.1237e-12
  0.000000	 -0.000000	diff=4.24957e-17
 -0.000000	 -0.000000	diff=5.38783e-13
 -1.735780	 -1.721192	diff=0.0145878
  0.001166	  0.001184	diff=1.84027e-05
  0.000000	  0.000000	diff=2.27313e-18
  0.000000	 -0.000000	diff=8.42241e-39
 -0.000000	 -0.000000	diff=1.89024e-10
  0.000000	  0.000000	diff=1.93547e-12
  0.000000	  0.000000	diff=3.87552e-17
 -0.000127	 -0.000127	diff=7.89192e-07
  0.811418	  0.845533	diff=0.0341144
  0.073130	  0.074823	diff=0.00169233
 -0.000037	 -0.000036	diff=2.06733e-07
  0.000602	  0.000605	diff=2.25564e-06
  0.367604	  0.387939	diff=0.0203354
  0.000185	  0.000186	diff=7.57711e-07
 -0.000000	 -0.000000	diff=5.2444e-12
 -0.000118	 -0.000118	diff=6.72907e-07
  0.087442	  0.116877	diff=0.0294355
 -0.117261	 -0.113357	diff=0.00390419
 -0.000016	 -0.000016	diff=2.06149e-07
 -0.000903	 -0.000898	diff=5.00235e-06
  0.352498	  0.371320	diff=0.0188219
  0.000172	  0.000173	diff=6.5308e-07
 -0.000000	 -0.000000	diff=3.9372e-12
 -0.011240	 -0.011229	diff=1.15126e-05
  0.044856	  0.086094	diff=0.0412387
 -0.093977	 -0.091509	diff=0.00246761
 -0.366369	 -0.346305	diff=0.0200643
  0.166146	  0.170853	diff=0.00470732
  0.029883	  0.029224	diff=0.000658642
  0.004986	  0.004996	diff=9.38693e-06
 -0.206328	 -0.199956	diff=0.00637236
  0.000026	  0.000026	diff=5.63073e-08
  0.001973	  0.001946	diff=2.79732e-05
  0.010783	  0.010818	diff=3.53644e-05
  0.000012	  0.000012	diff=3.12562e-08
  0.000084	  0.000084	diff=4.40889e-08
  0.257611	  0.269543	diff=0.0119313
 -0.000007	 -0.000007	diff=1.15476e-09
  0.000000	  0.000000	diff=2.47595e-12
  local_diff=0.226794
# W_tgt{2}, [8 4]
  0.334744	  0.481372	diff=0.146629
 -0.039668	  0.038652	diff=0.0783197
 -0.007213	 -0.007188	diff=2.50507e-05
  0.163312	  0.162380	diff=0.00093198
  0.012933	  0.012835	diff=9.76707e-05
 -0.116344	 -0.114940	diff=0.00140415
 -0.208550	 -0.207164	diff=0.00138569
  5.278429	  8.186417	diff=2.90799
 -0.111843	 -0.109577	diff=0.00226658
  0.011780	  0.011773	diff=6.67449e-06
  0.000385	  0.000386	diff=1.10585e-07
  0.002211	  0.002213	diff=1.70557e-06
 -0.000681	 -0.000683	diff=1.61445e-06
  0.006938	  0.006947	diff=8.75117e-06
 -0.000375	 -0.000375	diff=1.10403e-07
  0.054505	  0.054521	diff=1.56105e-05
 -0.046825	 -0.010663	diff=0.0361618
 -0.548776	 -0.549524	diff=0.000747638
 -0.315841	 -0.316644	diff=0.000803146
  0.237950	  0.237768	diff=0.000182533
 -0.771617	 -0.772007	diff=0.000390394
 -0.118394	 -0.118465	diff=7.11446e-05
 -0.503322	 -0.503171	diff=0.000150453
  3.987222	  4.035937	diff=0.0487149
  0.873207	  0.870084	diff=0.00312216
 -0.030862	 -0.029736	diff=0.00112621
  0.335196	  0.334258	diff=0.000937621
  0.090177	  0.088499	diff=0.00167762
  0.690906	  0.686951	diff=0.00395559
  0.023078	  0.023459	diff=0.000381341
  0.334246	  0.334114	diff=0.000131548
  2.624292	  2.450614	diff=0.173678
  local_diff=3.41131
# W_emb_src, [2 4]
  0.000081	  0.000082	diff=1.33515e-06
 -1.507716	 -1.527585	diff=0.0198692
-56.761916	-41.136640	diff=15.6253
-326.235165	-142.070912	diff=184.164
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=199.809
# W_emb_tgt, [2 4]
 -0.000000	 -0.000000	diff=2.20623e-11
  0.000000	  0.000000	diff=3.93648e-11
 -4.193958	 -4.112105	diff=0.0818536
 -1.097525	 -1.091621	diff=0.00590361
  0.000000	  0.000000	diff=2.95613e-10
 -0.000000	 -0.000000	diff=1.58037e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.0877572
# W_pos, [2 2]
  0.092907	  0.093382	diff=0.000474925
  0.061063	  0.061108	diff=4.50831e-05
  0.068308	  0.068313	diff=4.58939e-06
  0.061723	  0.061684	diff=3.88748e-05
  local_diff=0.000563472
# v_pos, [1 2]
 -0.586990	 -0.584265	diff=0.00272495
 -2.038008	 -2.003835	diff=0.0341721
  local_diff=0.036897
# W_h, [2 4]
 -1.511691	 -1.509873	diff=0.00181797
  0.677159	  0.680533	diff=0.003374
  1.644364	  1.653655	diff=0.00929103
 -0.801119	 -0.782667	diff=0.0184523
  1.561771	  1.561715	diff=5.58935e-05
 -0.072421	 -0.028641	diff=0.04378
 -0.976677	 -0.975315	diff=0.00136243
  0.102608	  0.111295	diff=0.00868647
  local_diff=0.08682
# W_soft, [4 2]
  5.510857	  5.507985	diff=0.00287231
 -1.792821	 -1.801720	diff=0.00889952
 -0.958318	 -0.961724	diff=0.00340552
 -2.735817	 -2.744540	diff=0.00872315
 -1.500612	 -1.504354	diff=0.00374206
 -0.163399	 -0.172924	diff=0.00952439
  4.606341	  4.603320	diff=0.00302133
 -2.916310	 -2.926043	diff=0.00973229
  local_diff=0.0499206
# Num params=182, abs_diff=230.43
Elapsed time is 2.872647 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 2)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 180, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 2
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 180
  src input 1: <s_sos> <s_sos> x y
  src mask: 0  0  1  1
  tgt input 1: <t_sos> a <t_eos> <t_eos> <t_eos>
  tgt output 1: a <t_eos> <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  0  0  0
# W_src{1}, [8 4]
  0.000272	  0.000277	diff=5.06224e-06
  0.000000	 -0.000000	diff=3.43072e-17
 -0.000004	 -0.000004	diff=6.59726e-08
  0.000000	  0.000000	diff=2.19682e-22
 28.883205	 30.476065	diff=1.59286
 -0.000000	 -0.000000	diff=8.36084e-13
  0.000000	 -0.000000	diff=4.67443e-16
  0.000000	  0.000000	diff=7.60136e-17
 -0.000093	 -0.000092	diff=5.677e-07
 -0.003277	 -0.003297	diff=2.03299e-05
  0.000001	  0.000001	diff=7.16052e-09
  0.001515	  0.001524	diff=9.06129e-06
-10.288089	-10.122944	diff=0.165145
-25.621868	-29.342167	diff=3.7203
  0.000000	  0.000000	diff=1.99741e-14
 -0.000000	 -0.000000	diff=1.64387e-12
  0.000035	  0.000035	diff=1.32418e-07
  0.000241	  0.000240	diff=9.11488e-07
 -0.000001	 -0.000001	diff=2.77439e-09
 -0.000950	 -0.000946	diff=3.51346e-06
  0.972150	  0.975610	diff=0.00346004
  0.003800	  0.003785	diff=1.45302e-05
  0.000000	 -0.000000	diff=7.84899e-16
  0.000000	 -0.000000	diff=5.40431e-18
  0.000000	 -0.000000	diff=5.58831e-19
 -0.000037	 -0.000037	diff=2.18885e-08
  0.000000	  0.000000	diff=4.42399e-20
  0.000147	  0.000147	diff=8.43913e-08
  0.000000	 -0.000000	diff=1.44717e-14
 -0.000528	 -0.000528	diff=3.31557e-07
  0.000000	  0.000000	diff=1.25549e-29
  0.000000	  0.000000	diff=4.76525e-16
  local_diff=5.48182
# W_src{2}, [8 4]
  0.079207	  0.077571	diff=0.00163591
 -0.537364	 -0.536608	diff=0.000755379
  0.002018	  0.002018	diff=1.62115e-07
 -0.000332	 -0.000332	diff=3.60013e-08
  0.135552	  0.136629	diff=0.00107754
 -1.262863	 -1.259544	diff=0.00331928
 -0.069363	 -0.069409	diff=4.6167e-05
 -0.444869	 -0.443822	diff=0.00104746
 -0.017928	 -0.017930	diff=2.34739e-06
  0.371694	  0.371057	diff=0.000637144
 -0.000011	 -0.000011	diff=1.27504e-10
 -0.000163	 -0.000163	diff=2.56075e-09
 -0.006630	 -0.006628	diff=1.52886e-06
  0.333140	  0.332601	diff=0.00053938
 -0.241129	 -0.241722	diff=0.000592936
 -1.821799	 -1.837371	diff=0.0155725
 -0.019479	 -0.019473	diff=5.92104e-06
 -0.075768	 -0.075784	diff=1.60852e-05
  0.006178	  0.006178	diff=1.22781e-07
 -0.037166	 -0.037171	diff=5.71643e-06
  0.010695	  0.010697	diff=2.21233e-06
 -0.155805	 -0.155814	diff=8.96887e-06
  0.030905	  0.030963	diff=5.80521e-05
  0.351456	  0.351018	diff=0.000437385
  0.041350	  0.041381	diff=3.079e-05
  0.085687	  0.085458	diff=0.000229146
 -0.047954	 -0.047918	diff=3.63697e-05
  0.027855	  0.027813	diff=4.20044e-05
 -0.018211	 -0.018204	diff=7.10191e-06
  0.319890	  0.319580	diff=0.000309954
  0.202231	  0.210827	diff=0.00859557
 -0.503485	 -0.505230	diff=0.00174527
  local_diff=0.0367585
# W_tgt{1}, [8 6]
  0.000000	  0.000000	diff=1.05102e-17
  0.004810	  0.004887	diff=7.70082e-05
 -0.000000	 -0.000000	diff=1.82492e-10
 -0.000000	 -0.000000	diff=5.95375e-09
  0.000000	 -0.000000	diff=8.56431e-15
 -0.000000	 -0.000000	diff=9.35597e-10
  0.000000	  0.000000	diff=2.15652e-10
 -0.000000	  0.000000	diff=3.19931e-12
  0.000000	 -0.000000	diff=3.65785e-31
 -0.004739	 -0.004667	diff=7.16789e-05
  0.000000	  0.000000	diff=4.08479e-10
  0.000000	  0.000000	diff=4.10837e-19
  0.000000	  0.000000	diff=8.18031e-15
  0.000000	 -0.000000	diff=1.86702e-14
 -0.000000	 -0.000000	diff=1.88924e-10
  0.000000	 -0.000000	diff=3.41122e-13
  0.000000	  0.000000	diff=3.16166e-18
 -0.000332	 -0.000332	diff=3.74864e-07
 -0.000000	 -0.000000	diff=4.76543e-13
 -0.000000	 -0.000000	diff=5.43512e-10
  0.000000	  0.000000	diff=2.81265e-15
  0.000000	  0.000000	diff=4.29332e-11
  0.000000	  0.000000	diff=3.73196e-11
  0.000000	 -0.000000	diff=1.10996e-13
  0.000000	  0.000000	diff=3.77874e-18
 -0.001712	 -0.001702	diff=9.81328e-06
 -0.000000	 -0.000000	diff=6.67506e-13
 -0.000000	 -0.000000	diff=7.78981e-10
  0.000000	  0.000000	diff=1.85391e-15
  0.000000	  0.000000	diff=1.82238e-11
 -0.000000	 -0.000000	diff=5.91326e-11
  0.000000	 -0.000000	diff=9.81633e-14
  0.000000	  0.000000	diff=6.42331e-28
  0.000000	 -0.000000	diff=5.81779e-24
 -0.000000	 -0.000000	diff=8.25708e-13
  0.000000	  0.000000	diff=2.56145e-22
  0.000000	 -0.000000	diff=1.21953e-34
  0.000000	  0.000000	diff=2.89195e-15
  0.000000	 -0.000000	diff=1.63515e-37
  0.000000	 -0.000000	diff=3.22361e-22
  0.000000	  0.000000	diff=3.73894e-29
  0.000000	  0.000000	diff=9.06386e-21
  0.000000	 -0.000000	diff=8.91204e-19
  0.000000	 -0.000000	diff=1.19667e-18
  0.000000	  0.000000	diff=1.47199e-38
  0.000000	  0.000000	diff=1.10112e-20
  0.000000	  0.000000	diff=1.02341e-29
  0.000000	  0.000000	diff=8.66732e-30
  local_diff=0.000158885
# W_tgt{2}, [8 4]
  0.357365	  0.357746	diff=0.000381023
  2.645935	  2.660832	diff=0.0148978
 -0.000470	 -0.000467	diff=2.22554e-06
  0.029441	  0.029327	diff=0.000114047
  0.001377	  0.001371	diff=6.1002e-06
  0.007711	  0.007754	diff=4.28322e-05
  0.773355	  0.769464	diff=0.0038911
 10.493143	 10.782561	diff=0.289418
 -0.000092	 -0.000092	diff=1.17656e-09
 -0.000092	 -0.000092	diff=4.45994e-09
 -0.000001	 -0.000001	diff=1.7197e-11
  0.000005	  0.000005	diff=5.76231e-11
  0.000006	  0.000006	diff=7.86181e-11
 -0.000023	 -0.000023	diff=2.64127e-10
  0.002226	  0.002226	diff=3.26405e-08
 -0.000043	 -0.000043	diff=1.37761e-10
  0.225014	  0.225718	diff=0.000704596
  0.404226	  0.404261	diff=3.49193e-05
  0.052094	  0.052269	diff=0.000175166
 -0.757498	 -0.756140	diff=0.00135807
 -0.378937	 -0.378706	diff=0.000231338
 -0.046685	 -0.046603	diff=8.20642e-05
 -0.393799	 -0.393911	diff=0.000112124
 -2.696061	 -2.668222	diff=0.0278383
 -0.326875	 -0.325678	diff=0.00119673
 -0.421587	 -0.421928	diff=0.000340423
  0.054916	  0.055184	diff=0.000268396
  1.536283	  1.542757	diff=0.00647399
 -2.036506	 -2.038147	diff=0.00164156
  0.392653	  0.393108	diff=0.000454797
 -0.364980	 -0.364854	diff=0.00012549
  3.448578	  3.505414	diff=0.0568365
  local_diff=0.406628
# W_emb_src, [2 4]
 -0.000004	 -0.000004	diff=5.97398e-08
  1.866035	  1.851825	diff=0.0142105
 26.030273	 27.302798	diff=1.27252
 77.773492	 94.317076	diff=16.5436
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=17.8303
# W_emb_tgt, [2 4]
  0.000000	  0.000000	diff=1.44674e-09
 -0.000000	 -0.000000	diff=2.43583e-12
 -0.011563	 -0.011148	diff=0.000414572
 -0.002990	 -0.002961	diff=2.87533e-05
  0.000000	  0.000000	diff=1.20997e-11
 -0.000000	 -0.000000	diff=4.27696e-12
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.000443327
# W_a, [2 2]
 -0.004721	 -0.004680	diff=4.07531e-05
 -1.254132	 -1.254877	diff=0.000745548
 -0.015406	 -0.015455	diff=4.85679e-05
  0.690386	  0.689181	diff=0.00120428
  local_diff=0.00203915
# W_h, [2 4]
 -1.408648	 -1.408411	diff=0.000237302
 -0.206574	 -0.206544	diff=3.01564e-05
  1.746481	  1.742977	diff=0.0035039
  3.143445	  3.145787	diff=0.00234195
  0.490966	  0.485882	diff=0.00508377
 -3.077260	 -3.074909	diff=0.00235113
  2.034908	  2.034710	diff=0.000198736
  1.239457	  1.238674	diff=0.000782835
  local_diff=0.0145298
# W_soft, [4 2]
 -3.344625	 -3.349193	diff=0.00456765
  9.821286	  9.820724	diff=0.00056256
 -0.268849	 -0.269902	diff=0.00105339
 -6.196670	 -6.201628	diff=0.00495854
  0.167489	  0.164506	diff=0.0029831
  9.543944	  9.543133	diff=0.000811295
 -2.059847	 -2.063128	diff=0.00328104
 -7.639216	 -7.644510	diff=0.0052939
  local_diff=0.0235115
# Num params=180, abs_diff=23.7962
Elapsed time is 2.018828 seconds.
[?1l>
## trainLSTM('', '', '', '', '', '', '', '../output/gradcheck', 'isGradCheck', 1, 'initRange', 10, 'isResume', 0, 'feedInput', 1, 'numLayers', 2, 'dropout', 0.8, 'isReverse', 1, 'attnFunc', 1, 'attnOpt', 3)
[?1h=
                                                                   < M A T L A B (R) >
                                                         Copyright 1984-2013 The MathWorks, Inc.
                                                            R2013a (8.1.0.604) 64-bit (maci64)
                                                                    February 15, 2013

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

  Student License -- for use in conjunction with courses offered at a
  degree-granting institution.  Professional and commercial use prohibited.

## Bilingual setting
# Init LSTM parameters using dataType=double, initRange=10
  Model size = 182, individual sizes:  W_src{1}=32 W_src{2}=32 W_tgt{1}=48 W_tgt{2}=32 W_emb_src=8 W_emb_tgt=8 W_a=4 v_a=2 W_h=8 W_soft=8
# assert = 0
# attnFunc = 1
# attnOpt = 3
# batchSize = 10
# dataType = double
# debug = 0
# decode = 1
# dropout = 0.8
# epochFraction = 1
# epochIter = 0
# feedInput = 1
# finetuneEpoch = 5
# finetuneRate = 0.5
# gpuDevice = 0
# initRange = 10
# isBi = 1
# isClip = 1
# isGradCheck = 1
# isProfile = 0
# isResume = 0
# isReverse = 1
# learningRate = 1
# loadModel = 
# logFreq = 10
# lstmOpt = 0
# lstmSize = 2
# maxGradNorm = 5
# maxLenRatio = 1.5
# maxSentLen = 7
# minLenRatio = 0.5
# numEpoches = 10
# numLayers = 2
# onlyCPU = 0
# outDir = ../output/gradcheck
# posWin = 1
# saveHDF = 0
# seed = 0
# shuffle = 1
# sortBatch = 1
# srcLang = 
# srcVocabFile = 
# testPrefix = 
# tgtLang = 
# tgtVocabFile = 
# trainPrefix = 
# validPrefix = 
# chunkSize = 12800
# baseIndex = 0
# clipForward = 50
# clipBackward = 1000
# nonlinear_gate_f = sigmoid
# nonlinear_gate_f_prime = sigmoidPrime
# nonlinear_f = tanh
# nonlinear_f_prime = tanhPrime
# beamSize = 12
# stackSize = 100
# unkPenalty = 0
# forceDecoder = 0
# isGPU = 0
# batchId = 1
# maxRelDist = 2
# logId = 3
# srcSos = 3
# srcEos = 4
# srcVocabSize = 4
# nullPosId = 0
# tgtSos = 3
# tgtEos = 4
# tgtVocabSize = 4
# modelFile = ../output/gradcheck/model.mat
# modelRecentFile = ../output/gradcheck/modelRecent.mat
# softmaxSize = 2
# lr = 1
# epoch = 1
# bestCostValid = 100000
# testPerplexity = 100000
# curTestPerpWord = 100000
# startIter = 0
# iter = 0
# epochBatchCount = 0
# finetuneCount = 0
# modelSize = 182
  src input 1: x x x x
  src mask: 1  1  1  1
  tgt input 1: <t_sos> a b <t_eos> <t_eos>
  tgt output 1: a b <t_eos> <t_eos> <t_eos>
  tgt mask: 1  1  1  0  0
# W_src{1}, [8 4]
 -0.000101	 -0.000103	diff=1.87075e-06
  0.000000	  0.000000	diff=7.17333e-09
  0.000003	  0.000003	diff=5.93543e-08
  0.000000	  0.000000	diff=1.36153e-20
-95.294114	-94.843200	diff=0.450914
 -0.000000	 -0.000000	diff=4.06806e-11
  0.000000	  0.000000	diff=6.33886e-14
  0.000000	  0.000000	diff=1.46622e-10
  0.000034	  0.000034	diff=2.0982e-07
 -0.000321	 -0.000323	diff=2.06853e-06
 -0.000001	 -0.000001	diff=6.44337e-09
 -0.001221	 -0.001228	diff=7.30285e-06
 31.375155	 31.503758	diff=0.128603
 33.488917	 29.358373	diff=4.13054
  0.000000	  0.000000	diff=9.20392e-14
 -0.000000	 -0.000000	diff=1.631e-11
 -0.000027	 -0.000027	diff=1.30644e-07
 -0.000194	 -0.000194	diff=7.34206e-07
  0.000001	  0.000001	diff=2.49983e-09
  0.000765	  0.000762	diff=2.83163e-06
  1.958730	  1.963665	diff=0.00493464
 -0.002177	 -0.002168	diff=8.29812e-06
  0.000000	 -0.000000	diff=1.8263e-15
  0.000000	  0.000000	diff=2.4156e-13
  0.000000	  0.000000	diff=7.19186e-19
  0.000030	  0.000030	diff=1.76339e-08
  0.000000	 -0.000000	diff=1.49761e-20
 -0.000118	 -0.000118	diff=6.80153e-08
  0.000000	  0.000000	diff=1.85713e-14
  0.000336	  0.000337	diff=1.99285e-07
  0.000000	  0.000000	diff=2.303e-27
  0.000000	  0.000000	diff=1.07029e-16
  local_diff=4.71502
# W_src{2}, [8 4]
 -0.750064	 -0.754838	diff=0.00477368
  1.016640	  1.017219	diff=0.000578505
  0.075885	  0.075826	diff=5.90958e-05
  0.235593	  0.236606	diff=0.00101255
 -3.276354	 -3.281355	diff=0.00500084
  1.988893	  1.985664	diff=0.00322902
 -0.265070	 -0.264778	diff=0.0002915
  0.858973	  0.858344	diff=0.000629387
  0.004881	  0.004877	diff=3.81318e-06
 -0.351459	 -0.352080	diff=0.000621176
  0.000028	  0.000028	diff=5.88412e-12
  0.000088	  0.000088	diff=5.70296e-11
 -0.012155	 -0.012153	diff=1.75718e-06
 -0.327165	 -0.327739	diff=0.000574443
  0.068224	  0.067598	diff=0.000626502
  1.759693	  1.744379	diff=0.0153143
  0.296520	  0.296491	diff=2.95336e-05
  0.047703	  0.047696	diff=7.38618e-06
  0.066793	  0.066778	diff=1.42539e-05
 -0.016511	 -0.016473	diff=3.83529e-05
  0.068107	  0.068101	diff=6.3664e-06
  0.218336	  0.218257	diff=7.93999e-05
 -0.841687	 -0.841562	diff=0.000124635
 -0.280751	 -0.281082	diff=0.000330654
 -0.762188	 -0.761571	diff=0.000616764
 -0.062484	 -0.062612	diff=0.000127231
 -1.120573	 -1.123134	diff=0.00256067
  0.056595	  0.056774	diff=0.000179838
 -0.036050	 -0.036086	diff=3.62623e-05
 -0.357805	 -0.358203	diff=0.000397954
  9.735552	  9.767388	diff=0.0318364
  0.540352	  0.539142	diff=0.00120982
  local_diff=0.0703121
# W_tgt{1}, [8 6]
  0.000000	 -0.000000	diff=2.49433e-15
 -0.054318	 -0.052178	diff=0.00213988
 -0.000008	 -0.000008	diff=1.36895e-07
  0.000000	 -0.000000	diff=3.49922e-18
  0.000000	  0.000000	diff=8.251e-46
  0.000000	  0.000000	diff=1.17792e-12
 -0.000000	 -0.000000	diff=3.78204e-13
  0.000000	  0.000000	diff=1.36122e-18
  0.000000	  0.000000	diff=2.38249e-15
  0.047969	  0.049838	diff=0.00186927
  0.000008	  0.000008	diff=1.35477e-07
  0.000000	  0.000000	diff=3.34232e-18
  0.000000	  0.000000	diff=6.30218e-35
  0.000000	  0.000000	diff=2.04959e-10
  0.000000	  0.000000	diff=1.16213e-12
  0.000000	  0.000000	diff=7.61318e-19
 -0.015872	 -0.015973	diff=0.000100655
  0.670630	  0.666410	diff=0.00422067
  1.474112	  1.489339	diff=0.015227
  0.000705	  0.000703	diff=2.06122e-06
  0.109918	  0.110426	diff=0.000508391
 -3.455075	 -3.419008	diff=0.0360662
  0.005593	  0.005643	diff=5.07339e-05
 -0.000002	 -0.000002	diff=2.56249e-08
 -0.012120	 -0.012175	diff=5.43276e-05
  0.539777	  0.537648	diff=0.00212931
 -1.037774	 -1.030444	diff=0.00733064
 -0.001015	 -0.001016	diff=7.41815e-07
 -0.073832	 -0.073605	diff=0.000227084
 -2.360754	 -2.345359	diff=0.0153953
  0.004215	  0.004244	diff=2.87127e-05
 -0.000001	 -0.000001	diff=1.31661e-08
 -0.669408	 -0.666941	diff=0.00246734
  0.946555	  0.946398	diff=0.00015711
 -2.165799	 -2.135614	diff=0.0301851
 -0.777650	 -0.776989	diff=0.000661074
  0.406437	  0.406389	diff=4.78595e-05
 -2.591235	 -2.564184	diff=0.027051
  0.291241	  0.292128	diff=0.000886923
 -0.447576	 -0.447949	diff=0.000373562
  0.004887	  0.004871	diff=1.61823e-05
  0.136304	  0.136028	diff=0.000276452
  0.157114	  0.157330	diff=0.000216315
  0.000353	  0.000354	diff=8.61857e-07
  0.010449	  0.010454	diff=4.56886e-06
  3.628626	  3.691649	diff=0.0630231
 -0.000221	 -0.000221	diff=7.80667e-08
  0.000001	  0.000001	diff=8.41922e-09
  local_diff=0.210719
# W_tgt{2}, [8 4]
  8.494684	  8.985383	diff=0.4907
  6.179603	  6.192508	diff=0.012905
 -0.112556	 -0.112242	diff=0.000314339
  0.090456	  0.089872	diff=0.000584056
  0.000794	  0.000647	diff=0.000146304
 -0.655878	 -0.655541	diff=0.000336663
 -0.681690	 -0.679139	diff=0.00255051
 24.154853	 24.748232	diff=0.593379
 -0.989626	 -0.983875	diff=0.00575124
  0.067416	  0.067418	diff=1.57681e-06
  0.006879	  0.006881	diff=1.54958e-06
 -0.010318	 -0.010303	diff=1.48064e-05
 -0.005202	 -0.005218	diff=1.59567e-05
 -0.028526	 -0.028164	diff=0.000361592
 -0.006357	 -0.006359	diff=2.4435e-06
 -0.094758	 -0.094664	diff=9.39138e-05
  4.524625	  4.677943	diff=0.153318
 -0.569370	 -0.569236	diff=0.000134624
 -0.687226	 -0.688073	diff=0.000846681
  0.824548	  0.826077	diff=0.00152902
 -1.307933	 -1.307910	diff=2.32437e-05
 -0.156638	 -0.156810	diff=0.000172099
 -0.966378	 -0.964446	diff=0.00193212
 10.130082	 10.159178	diff=0.0290961
  1.917010	  1.916654	diff=0.00035584
  0.417504	  0.419682	diff=0.00217812
  0.801766	  0.800848	diff=0.000917739
 -1.320295	 -1.312750	diff=0.00754418
  0.943196	  0.941933	diff=0.00126286
  0.235513	  0.235293	diff=0.000220456
  0.535323	  0.535507	diff=0.000184103
 -6.823694	 -6.679595	diff=0.144099
  local_diff=1.45097
# W_emb_src, [2 4]
  0.000005	  0.000005	diff=8.24945e-08
 -1.836916	 -1.852927	diff=0.0160109
-85.365779	-84.966169	diff=0.399609
-297.657204	-293.456999	diff=4.20021
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=4.61583
# W_emb_tgt, [2 4]
 -0.000000	 -0.000000	diff=1.00732e-11
 -0.000000	 -0.000000	diff=2.63642e-11
  0.108673	  0.119046	diff=0.010373
  0.030867	  0.031625	diff=0.000758197
  0.000000	  0.000000	diff=6.37593e-10
 -0.000000	 -0.000000	diff=3.39385e-10
  0.000000	  0.000000	diff=0
  0.000000	  0.000000	diff=0
  local_diff=0.0111312
# W_a, [2 2]
  0.022171	  0.022642	diff=0.000470579
 -0.197344	 -0.196958	diff=0.000386375
 -0.008175	 -0.008180	diff=5.41642e-06
 -0.042423	 -0.042473	diff=4.97812e-05
  local_diff=0.000912152
# v_a, [1 2]
  0.910934	  0.913519	diff=0.00258447
 -2.714058	 -2.713844	diff=0.000214556
  local_diff=0.00279903
# W_h, [2 4]
  0.130139	  0.130787	diff=0.000648153
 -0.832062	 -0.831459	diff=0.000603363
 -0.296298	 -0.295301	diff=0.000996755
  2.285211	  2.286888	diff=0.00167692
  1.576224	  1.580116	diff=0.00389136
 -6.814995	 -6.735038	diff=0.0799569
 -0.828555	 -0.825923	diff=0.00263141
  1.464849	  1.465929	diff=0.00107953
  local_diff=0.0914844
# W_soft, [4 2]
  7.175324	  7.172881	diff=0.00244324
 -1.759878	 -1.770534	diff=0.0106561
 -0.736914	 -0.739895	diff=0.00298072
 -4.652072	 -4.662452	diff=0.0103797
 -0.879300	 -0.882546	diff=0.00324528
 -0.573407	 -0.584769	diff=0.0113625
  3.509876	  3.507175	diff=0.00270026
 -2.028308	 -2.039860	diff=0.0115521
  local_diff=0.0553199
# Num params=182, abs_diff=11.2245
Elapsed time is 2.271586 seconds.
[?1l>